all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

load TPCH...
[2, 3, 4, 6, 7, 9] [1, 0] [8 5]
[0, 1, 2, 5, 7, 9] [4, 3] [6 8]
[0, 1, 5, 6, 7, 8] [3, 2] [4 9]
[0, 2, 3, 4, 6, 7, 9] [1, 8] [5 5]
[0, 3, 4, 5, 7, 9] [1, 6] [8 2]
[1, 2, 4, 5, 6, 8] [0, 9] [3 7]
[0, 2, 5, 6, 7, 8, 9] [1, 3] [4 4]
[0, 1, 2, 4, 6, 7] [3, 8] [9 5]
[1, 2, 3, 5, 6, 7] [9, 0] [4 8]
[0, 1, 4, 5, 6, 7] [8, 3] [9 2]
[0, 1, 2, 3, 7, 9] [8, 6] [5 4]
[0, 2, 4, 5, 6, 8] [3, 7] [1 9]
[0, 1, 2, 5, 7, 8] [9, 4] [3 6]
[1, 4, 5, 6, 8, 9] [0, 2] [7 3]
[0, 1, 2, 4, 7, 8] [6, 5] [9 3]
[1, 3, 5, 7, 8, 9] [4, 2] [6 0]
[0, 2, 6, 7, 8, 9] [3, 5] [4 1]
[0, 2, 3, 4, 7, 8] [1, 9] [6 5]
[2, 3, 5, 7, 8, 9] [6, 1] [4 0]
[1, 3, 4, 6, 7, 8] [5, 9] [0 2]
load TPCH succ
train, test, validation (122, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.489446, and there are 5978 training samples
in channel 9
Epoch 0/300 |loss: 0.051436| train set 2.411x speedup, test set 2.297x speedup, val set 2.448x speedup, step: 1
Epoch 1/300 |loss: 0.017954| train set 2.961x speedup, test set 2.781x speedup, val set 2.991x speedup, step: 1
Epoch 2/300 |loss: 0.009499| train set 3.086x speedup, test set 2.943x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006226| train set 3.701x speedup, test set 3.516x speedup, val set 3.830x speedup, step: 1
Epoch 4/300 |loss: 0.005078| train set 3.155x speedup, test set 3.017x speedup, val set 3.231x speedup, step: 2
Epoch 5/300 |loss: 0.004836| train set 3.457x speedup, test set 3.321x speedup, val set 3.592x speedup, step: 3
Epoch 6/300 |loss: 0.003938| train set 3.410x speedup, test set 3.237x speedup, val set 3.407x speedup, step: 4
Epoch 7/300 |loss: 0.003524| train set 3.633x speedup, test set 3.510x speedup, val set 3.652x speedup, step: 5
Epoch 8/300 |loss: 0.002940| train set 3.819x speedup, test set 3.685x speedup, val set 3.903x speedup, step: 1
Epoch 9/300 |loss: 0.002710| train set 4.761x speedup, test set 4.864x speedup, val set 4.985x speedup, step: 1
Epoch 10/300 |loss: 0.002237| train set 3.593x speedup, test set 3.468x speedup, val set 3.621x speedup, step: 2
Epoch 11/300 |loss: 0.002971| train set 4.906x speedup, test set 4.796x speedup, val set 5.021x speedup, step: 1
Epoch 12/300 |loss: 0.002449| train set 4.153x speedup, test set 3.939x speedup, val set 4.350x speedup, step: 2
Epoch 13/300 |loss: 0.002533| train set 4.899x speedup, test set 4.806x speedup, val set 4.948x speedup, step: 3
Epoch 14/300 |loss: 0.001981| train set 4.154x speedup, test set 3.948x speedup, val set 4.276x speedup, step: 4
Epoch 15/300 |loss: 0.001817| train set 4.968x speedup, test set 4.870x speedup, val set 4.989x speedup, step: 5
Epoch 16/300 |loss: 0.002198| train set 3.837x speedup, test set 3.613x speedup, val set 3.946x speedup, step: 6
Epoch 17/300 |loss: 0.002221| train set 5.129x speedup, test set 5.254x speedup, val set 5.512x speedup, step: 1
Epoch 18/300 |loss: 0.001575| train set 5.314x speedup, test set 5.171x speedup, val set 5.589x speedup, step: 1
Epoch 19/300 |loss: 0.001872| train set 5.309x speedup, test set 5.187x speedup, val set 5.467x speedup, step: 2
Epoch 20/300 |loss: 0.001286| train set 4.901x speedup, test set 4.799x speedup, val set 5.018x speedup, step: 3
Epoch 21/300 |loss: 0.001096| train set 5.363x speedup, test set 5.254x speedup, val set 5.512x speedup, step: 4
Epoch 22/300 |loss: 0.000912| train set 5.374x speedup, test set 5.260x speedup, val set 5.475x speedup, step: 5
Epoch 23/300 |loss: 0.000808| train set 5.379x speedup, test set 5.244x speedup, val set 5.539x speedup, step: 6
Epoch 24/300 |loss: 0.000836| train set 5.389x speedup, test set 5.256x speedup, val set 5.547x speedup, step: 7
Epoch 25/300 |loss: 0.000899| train set 5.385x speedup, test set 5.258x speedup, val set 5.544x speedup, step: 8
Epoch 26/300 |loss: 0.000824| train set 5.359x speedup, test set 5.256x speedup, val set 5.513x speedup, step: 9
Epoch 27/300 |loss: 0.000733| train set 5.389x speedup, test set 5.256x speedup, val set 5.551x speedup, step: 10
Epoch 28/300 |loss: 0.000794| train set 5.291x speedup, test set 5.169x speedup, val set 5.556x speedup, step: 11
Epoch 29/300 |loss: 0.000834| train set 5.389x speedup, test set 5.256x speedup, val set 5.551x speedup, step: 12
Epoch 30/300 |loss: 0.000770| train set 5.387x speedup, test set 5.262x speedup, val set 5.552x speedup, step: 13
Epoch 31/300 |loss: 0.000830| train set 5.364x speedup, test set 5.254x speedup, val set 5.512x speedup, step: 14
Epoch 32/300 |loss: 0.000713| train set 5.389x speedup, test set 5.258x speedup, val set 5.548x speedup, step: 15
Epoch 33/300 |loss: 0.000748| train set 5.382x speedup, test set 5.263x speedup, val set 5.547x speedup, step: 16
Epoch 34/300 |loss: 0.000729| train set 5.359x speedup, test set 5.253x speedup, val set 5.506x speedup, step: 17
Epoch 35/300 |loss: 0.000749| train set 5.389x speedup, test set 5.256x speedup, val set 5.547x speedup, step: 18
Epoch 36/300 |loss: 0.000820| train set 5.378x speedup, test set 5.261x speedup, val set 5.541x speedup, step: 19
early stopping at epoch 36
Training per epoch cost 0.437 s
Optimal speedup on test set is 5.356x
01, opt runtime 29.200s, model runtime 29.200s, pg runtime 29.200s, speedup 1.000x
02, opt runtime 26.072s, model runtime 26.072s, pg runtime 26.072s, speedup 1.000x
03, opt runtime 29.269s, model runtime 29.269s, pg runtime 91.296s, speedup 3.119x
04, opt runtime 29.286s, model runtime 29.286s, pg runtime 92.131s, speedup 3.146x
05, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
06, opt runtime 17.779s, model runtime 17.779s, pg runtime 17.779s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.913s, model runtime 9.037s, pg runtime 15.548s, speedup 1.720x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 21.913s, model runtime 21.913s, pg runtime 74.973s, speedup 3.421x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.590s, model runtime 3.590s, pg runtime 12.193s, speedup 3.396x
15, opt runtime 47.812s, model runtime 47.812s, pg runtime 83.069s, speedup 1.737x
16, opt runtime 49.511s, model runtime 49.511s, pg runtime 87.329s, speedup 1.764x
17, opt runtime 7.565s, model runtime 7.565s, pg runtime 20.255s, speedup 2.678x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.148s, model runtime 1.240s, pg runtime 1.214s, speedup 0.979x
20, opt runtime 1.347s, model runtime 1.457s, pg runtime 1.438s, speedup 0.987x
21, opt runtime 18.267s, model runtime 21.055s, pg runtime 21.055s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 5.961s, model runtime 5.961s, pg runtime 31.210s, speedup 5.236x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.360s, model runtime 1.360s, pg runtime 1.360s, speedup 1.000x
26, opt runtime 1.265s, model runtime 1.265s, pg runtime 1.265s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.799s, pg runtime 7.799s, speedup 1.000x
28, opt runtime 7.063s, model runtime 7.063s, pg runtime 7.063s, speedup 1.000x
29, opt runtime 5.415s, model runtime 5.415s, pg runtime 5.415s, speedup 1.000x
30, opt runtime 5.175s, model runtime 5.175s, pg runtime 5.175s, speedup 1.000x
31, opt runtime 25.236s, model runtime 25.236s, pg runtime 601.756s, speedup 23.845x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 35.538s, model runtime 42.151s, pg runtime 70.116s, speedup 1.663x
34, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
35, opt runtime 15.120s, model runtime 16.499s, pg runtime 566.078s, speedup 34.310x
36, opt runtime 16.305s, model runtime 16.305s, pg runtime 436.168s, speedup 26.751x
37, opt runtime 11.734s, model runtime 11.734s, pg runtime 11.734s, speedup 1.000x
38, opt runtime 15.302s, model runtime 15.302s, pg runtime 15.302s, speedup 1.000x
39, opt runtime 1.015s, model runtime 1.015s, pg runtime 1.092s, speedup 1.076x
40, opt runtime 1.084s, model runtime 1.084s, pg runtime 1.155s, speedup 1.065x
====================
best train speedup epoch: 35, train speedup 5.389, test speedup 5.256, val speedup 5.547
best test speedup epoch: 33, train speedup 5.382, test speedup 5.263, val speedup 5.547
best validation speedup epoch: 18, train speedup 5.314, test speedup 5.171, val speedup 5.589
last model at epoch 36, train speedup 5.378, test speedup 5.261, val speedup 5.541
execution cost 0:00:36.949561
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

load TPCH...
[2, 3, 4, 6, 7, 9] [1, 0] [8 5]
[0, 1, 2, 5, 7, 9] [4, 3] [6 8]
[0, 1, 5, 6, 7, 8] [3, 2] [4 9]
[0, 2, 3, 4, 6, 7, 9] [1, 8] [5 5]
[0, 3, 4, 5, 7, 9] [1, 6] [8 2]
[1, 2, 4, 5, 6, 8] [0, 9] [3 7]
[0, 2, 5, 6, 7, 8, 9] [1, 3] [4 4]
[0, 1, 2, 4, 6, 7] [3, 8] [9 5]
[1, 2, 3, 5, 6, 7] [9, 0] [4 8]
[0, 1, 4, 5, 6, 7] [8, 3] [9 2]
[0, 1, 2, 3, 7, 9] [8, 6] [5 4]
[0, 2, 4, 5, 6, 8] [3, 7] [1 9]
[0, 1, 2, 5, 7, 8] [9, 4] [3 6]
[1, 4, 5, 6, 8, 9] [0, 2] [7 3]
[0, 1, 2, 4, 7, 8] [6, 5] [9 3]
[1, 3, 5, 7, 8, 9] [4, 2] [6 0]
[0, 2, 6, 7, 8, 9] [3, 5] [4 1]
[0, 2, 3, 4, 7, 8] [1, 9] [6 5]
[2, 3, 5, 7, 8, 9] [6, 1] [4 0]
[1, 3, 4, 6, 7, 8] [5, 9] [0 2]
load TPCH succ
train, test, validation (122, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.498724, and there are 5978 training samples
in channel 9
Epoch 0/300 |loss: 0.051436| train set 2.411x speedup, test set 2.297x speedup, val set 2.448x speedup, step: 1
Epoch 1/300 |loss: 0.017954| train set 2.961x speedup, test set 2.781x speedup, val set 2.991x speedup, step: 1
Epoch 2/300 |loss: 0.009499| train set 3.086x speedup, test set 2.943x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006226| train set 3.701x speedup, test set 3.516x speedup, val set 3.830x speedup, step: 1
Epoch 4/300 |loss: 0.005077| train set 3.155x speedup, test set 3.017x speedup, val set 3.231x speedup, step: 2
Epoch 5/300 |loss: 0.004908| train set 3.269x speedup, test set 3.119x speedup, val set 3.330x speedup, step: 3
Epoch 6/300 |loss: 0.003952| train set 3.407x speedup, test set 3.236x speedup, val set 3.404x speedup, step: 4
Epoch 7/300 |loss: 0.003479| train set 3.822x speedup, test set 3.672x speedup, val set 3.906x speedup, step: 1
Epoch 8/300 |loss: 0.003009| train set 3.849x speedup, test set 3.719x speedup, val set 3.903x speedup, step: 2
Epoch 9/300 |loss: 0.002761| train set 4.463x speedup, test set 4.436x speedup, val set 4.468x speedup, step: 1
Epoch 10/300 |loss: 0.002211| train set 3.594x speedup, test set 3.470x speedup, val set 3.623x speedup, step: 2
Epoch 11/300 |loss: 0.002479| train set 4.855x speedup, test set 4.761x speedup, val set 4.924x speedup, step: 1
Epoch 12/300 |loss: 0.002481| train set 3.672x speedup, test set 3.467x speedup, val set 3.692x speedup, step: 2
Epoch 13/300 |loss: 0.002292| train set 5.349x speedup, test set 5.220x speedup, val set 5.536x speedup, step: 1
Epoch 14/300 |loss: 0.001679| train set 4.088x speedup, test set 3.758x speedup, val set 3.988x speedup, step: 2
Epoch 15/300 |loss: 0.001610| train set 4.677x speedup, test set 4.792x speedup, val set 4.985x speedup, step: 3
Epoch 16/300 |loss: 0.001725| train set 4.767x speedup, test set 5.159x speedup, val set 5.395x speedup, step: 4
Epoch 17/300 |loss: 0.002058| train set 4.529x speedup, test set 4.790x speedup, val set 5.020x speedup, step: 5
Epoch 18/300 |loss: 0.001647| train set 5.382x speedup, test set 5.263x speedup, val set 5.547x speedup, step: 1
Epoch 19/300 |loss: 0.001804| train set 5.205x speedup, test set 5.083x speedup, val set 5.463x speedup, step: 2
Epoch 20/300 |loss: 0.001177| train set 4.963x speedup, test set 4.863x speedup, val set 4.987x speedup, step: 3
Epoch 21/300 |loss: 0.000914| train set 5.385x speedup, test set 5.258x speedup, val set 5.544x speedup, step: 4
Epoch 22/300 |loss: 0.000826| train set 5.389x speedup, test set 5.255x speedup, val set 5.550x speedup, step: 1
Epoch 23/300 |loss: 0.000824| train set 5.307x speedup, test set 5.167x speedup, val set 5.581x speedup, step: 1
Epoch 24/300 |loss: 0.000855| train set 5.323x speedup, test set 5.163x speedup, val set 5.451x speedup, step: 2
Epoch 25/300 |loss: 0.000862| train set 5.381x speedup, test set 5.254x speedup, val set 5.550x speedup, step: 3
Epoch 26/300 |loss: 0.000788| train set 5.378x speedup, test set 5.252x speedup, val set 5.540x speedup, step: 4
Epoch 27/300 |loss: 0.000684| train set 5.383x speedup, test set 5.248x speedup, val set 5.545x speedup, step: 5
Epoch 28/300 |loss: 0.000750| train set 5.291x speedup, test set 5.170x speedup, val set 5.553x speedup, step: 6
Epoch 29/300 |loss: 0.000834| train set 5.389x speedup, test set 5.255x speedup, val set 5.550x speedup, step: 7
Epoch 30/300 |loss: 0.000816| train set 5.383x speedup, test set 5.262x speedup, val set 5.547x speedup, step: 8
Epoch 31/300 |loss: 0.000798| train set 5.362x speedup, test set 5.257x speedup, val set 5.518x speedup, step: 9
Epoch 32/300 |loss: 0.000747| train set 5.263x speedup, test set 5.086x speedup, val set 5.561x speedup, step: 10
Epoch 33/300 |loss: 0.000736| train set 5.382x speedup, test set 5.262x speedup, val set 5.545x speedup, step: 11
Epoch 34/300 |loss: 0.000752| train set 5.384x speedup, test set 5.263x speedup, val set 5.549x speedup, step: 12
Epoch 35/300 |loss: 0.000770| train set 5.287x speedup, test set 5.159x speedup, val set 5.474x speedup, step: 13
Epoch 36/300 |loss: 0.000791| train set 5.387x speedup, test set 5.262x speedup, val set 5.552x speedup, step: 14
early stopping at epoch 36
Training per epoch cost 0.442 s
Optimal speedup on test set is 5.356x
01, opt runtime 29.200s, model runtime 29.200s, pg runtime 29.200s, speedup 1.000x
02, opt runtime 26.072s, model runtime 26.072s, pg runtime 26.072s, speedup 1.000x
03, opt runtime 29.269s, model runtime 29.269s, pg runtime 91.296s, speedup 3.119x
04, opt runtime 29.286s, model runtime 29.286s, pg runtime 92.131s, speedup 3.146x
05, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
06, opt runtime 17.779s, model runtime 17.779s, pg runtime 17.779s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.913s, model runtime 9.037s, pg runtime 15.548s, speedup 1.720x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 21.913s, model runtime 21.913s, pg runtime 74.973s, speedup 3.421x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 3.332s, pg runtime 21.298s, speedup 6.391x
14, opt runtime 3.590s, model runtime 4.223s, pg runtime 12.193s, speedup 2.887x
15, opt runtime 47.812s, model runtime 47.812s, pg runtime 83.069s, speedup 1.737x
16, opt runtime 49.511s, model runtime 49.511s, pg runtime 87.329s, speedup 1.764x
17, opt runtime 7.565s, model runtime 7.565s, pg runtime 20.255s, speedup 2.678x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.148s, model runtime 1.148s, pg runtime 1.214s, speedup 1.057x
20, opt runtime 1.347s, model runtime 1.347s, pg runtime 1.438s, speedup 1.067x
21, opt runtime 18.267s, model runtime 21.055s, pg runtime 21.055s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 5.961s, model runtime 5.961s, pg runtime 31.210s, speedup 5.236x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.360s, model runtime 1.360s, pg runtime 1.360s, speedup 1.000x
26, opt runtime 1.265s, model runtime 1.265s, pg runtime 1.265s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.799s, pg runtime 7.799s, speedup 1.000x
28, opt runtime 7.063s, model runtime 7.063s, pg runtime 7.063s, speedup 1.000x
29, opt runtime 5.415s, model runtime 5.829s, pg runtime 5.415s, speedup 0.929x
30, opt runtime 5.175s, model runtime 5.538s, pg runtime 5.175s, speedup 0.934x
31, opt runtime 25.236s, model runtime 25.236s, pg runtime 601.756s, speedup 23.845x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 35.538s, model runtime 42.151s, pg runtime 70.116s, speedup 1.663x
34, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
35, opt runtime 15.120s, model runtime 16.499s, pg runtime 566.078s, speedup 34.310x
36, opt runtime 16.305s, model runtime 16.305s, pg runtime 436.168s, speedup 26.751x
37, opt runtime 11.734s, model runtime 11.734s, pg runtime 11.734s, speedup 1.000x
38, opt runtime 15.302s, model runtime 15.302s, pg runtime 15.302s, speedup 1.000x
39, opt runtime 1.015s, model runtime 1.015s, pg runtime 1.092s, speedup 1.076x
40, opt runtime 1.084s, model runtime 1.084s, pg runtime 1.155s, speedup 1.065x
====================
best train speedup epoch: 22, train speedup 5.389, test speedup 5.255, val speedup 5.550
best test speedup epoch: 34, train speedup 5.384, test speedup 5.263, val speedup 5.549
best validation speedup epoch: 23, train speedup 5.307, test speedup 5.167, val speedup 5.581
last model at epoch 36, train speedup 5.387, test speedup 5.262, val speedup 5.552
execution cost 0:00:37.253735
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

load TPCH...
[2, 3, 4, 6, 7, 9] [1, 0] [8 5]
[0, 1, 2, 5, 7, 9] [4, 3] [6 8]
[0, 1, 5, 6, 7, 8] [3, 2] [4 9]
[0, 2, 3, 4, 6, 7, 9] [1, 8] [5 5]
[0, 3, 4, 5, 7, 9] [1, 6] [8 2]
[1, 2, 4, 5, 6, 8] [0, 9] [3 7]
[0, 2, 5, 6, 7, 8, 9] [1, 3] [4 4]
[0, 1, 2, 4, 6, 7] [3, 8] [9 5]
[1, 2, 3, 5, 6, 7] [9, 0] [4 8]
[0, 1, 4, 5, 6, 7] [8, 3] [9 2]
[0, 1, 2, 3, 7, 9] [8, 6] [5 4]
[0, 2, 4, 5, 6, 8] [3, 7] [1 9]
[0, 1, 2, 5, 7, 8] [9, 4] [3 6]
[1, 4, 5, 6, 8, 9] [0, 2] [7 3]
[0, 1, 2, 4, 7, 8] [6, 5] [9 3]
[1, 3, 5, 7, 8, 9] [4, 2] [6 0]
[0, 2, 6, 7, 8, 9] [3, 5] [4 1]
[0, 2, 3, 4, 7, 8] [1, 9] [6 5]
[2, 3, 5, 7, 8, 9] [6, 1] [4 0]
[1, 3, 4, 6, 7, 8] [5, 9] [0 2]
load TPCH succ
train, test, validation (122, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.502728, and there are 5978 training samples
in channel 9
Epoch 0/300 |loss: 0.051436| train set 2.411x speedup, test set 2.297x speedup, val set 2.448x speedup, step: 1
Epoch 1/300 |loss: 0.017954| train set 2.961x speedup, test set 2.781x speedup, val set 2.991x speedup, step: 1
Epoch 2/300 |loss: 0.009499| train set 3.086x speedup, test set 2.943x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006226| train set 3.701x speedup, test set 3.516x speedup, val set 3.830x speedup, step: 1
Epoch 4/300 |loss: 0.005078| train set 3.155x speedup, test set 3.017x speedup, val set 3.231x speedup, step: 2
Epoch 5/300 |loss: 0.004846| train set 3.457x speedup, test set 3.321x speedup, val set 3.592x speedup, step: 3
Epoch 6/300 |loss: 0.003948| train set 3.408x speedup, test set 3.236x speedup, val set 3.404x speedup, step: 4
Epoch 7/300 |loss: 0.003503| train set 3.653x speedup, test set 3.491x speedup, val set 3.721x speedup, step: 5
Epoch 8/300 |loss: 0.002919| train set 3.819x speedup, test set 3.685x speedup, val set 3.904x speedup, step: 1
Epoch 9/300 |loss: 0.002664| train set 4.963x speedup, test set 4.863x speedup, val set 4.987x speedup, step: 1
Epoch 10/300 |loss: 0.002206| train set 3.880x speedup, test set 3.701x speedup, val set 3.941x speedup, step: 2
Epoch 11/300 |loss: 0.002663| train set 4.887x speedup, test set 4.790x speedup, val set 4.935x speedup, step: 3
Epoch 12/300 |loss: 0.002508| train set 4.094x speedup, test set 3.938x speedup, val set 4.160x speedup, step: 4
Epoch 13/300 |loss: 0.002250| train set 5.339x speedup, test set 5.224x speedup, val set 5.457x speedup, step: 1
Epoch 14/300 |loss: 0.001737| train set 4.165x speedup, test set 3.946x speedup, val set 4.295x speedup, step: 2
Epoch 15/300 |loss: 0.001684| train set 4.761x speedup, test set 4.863x speedup, val set 4.984x speedup, step: 3
Epoch 16/300 |loss: 0.001818| train set 3.823x speedup, test set 3.613x speedup, val set 3.890x speedup, step: 4
Epoch 17/300 |loss: 0.002262| train set 4.818x speedup, test set 5.104x speedup, val set 5.501x speedup, step: 1
Epoch 18/300 |loss: 0.002091| train set 5.389x speedup, test set 5.258x speedup, val set 5.548x speedup, step: 1
Epoch 19/300 |loss: 0.001781| train set 5.375x speedup, test set 5.256x speedup, val set 5.541x speedup, step: 2
Epoch 20/300 |loss: 0.001160| train set 4.906x speedup, test set 4.797x speedup, val set 5.022x speedup, step: 3
Epoch 21/300 |loss: 0.000961| train set 5.316x speedup, test set 5.171x speedup, val set 5.592x speedup, step: 1
Epoch 22/300 |loss: 0.000950| train set 5.386x speedup, test set 5.261x speedup, val set 5.551x speedup, step: 2
Epoch 23/300 |loss: 0.000771| train set 5.383x speedup, test set 5.251x speedup, val set 5.543x speedup, step: 3
Epoch 24/300 |loss: 0.000886| train set 5.389x speedup, test set 5.258x speedup, val set 5.548x speedup, step: 4
Epoch 25/300 |loss: 0.000896| train set 5.290x speedup, test set 5.167x speedup, val set 5.476x speedup, step: 5
Epoch 26/300 |loss: 0.000829| train set 5.382x speedup, test set 5.251x speedup, val set 5.527x speedup, step: 6
Epoch 27/300 |loss: 0.000702| train set 5.389x speedup, test set 5.255x speedup, val set 5.550x speedup, step: 7
Epoch 28/300 |loss: 0.000751| train set 5.364x speedup, test set 5.254x speedup, val set 5.516x speedup, step: 8
Epoch 29/300 |loss: 0.000794| train set 5.389x speedup, test set 5.256x speedup, val set 5.551x speedup, step: 9
Epoch 30/300 |loss: 0.000821| train set 5.387x speedup, test set 5.261x speedup, val set 5.550x speedup, step: 10
Epoch 31/300 |loss: 0.000816| train set 5.387x speedup, test set 5.259x speedup, val set 5.553x speedup, step: 11
Epoch 32/300 |loss: 0.000743| train set 5.316x speedup, test set 5.171x speedup, val set 5.588x speedup, step: 12
Epoch 33/300 |loss: 0.000735| train set 5.389x speedup, test set 5.256x speedup, val set 5.547x speedup, step: 13
Epoch 34/300 |loss: 0.000791| train set 5.359x speedup, test set 5.270x speedup, val set 5.485x speedup, step: 14
Epoch 35/300 |loss: 0.000736| train set 5.389x speedup, test set 5.256x speedup, val set 5.547x speedup, step: 15
Epoch 36/300 |loss: 0.000896| train set 5.214x speedup, test set 5.084x speedup, val set 5.470x speedup, step: 16
early stopping at epoch 36
Training per epoch cost 0.447 s
Optimal speedup on test set is 5.356x
01, opt runtime 29.200s, model runtime 29.200s, pg runtime 29.200s, speedup 1.000x
02, opt runtime 26.072s, model runtime 26.072s, pg runtime 26.072s, speedup 1.000x
03, opt runtime 29.269s, model runtime 29.269s, pg runtime 91.296s, speedup 3.119x
04, opt runtime 29.286s, model runtime 29.286s, pg runtime 92.131s, speedup 3.146x
05, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
06, opt runtime 17.779s, model runtime 17.779s, pg runtime 17.779s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.913s, model runtime 9.037s, pg runtime 15.548s, speedup 1.720x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 21.913s, model runtime 21.913s, pg runtime 74.973s, speedup 3.421x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.590s, model runtime 3.590s, pg runtime 12.193s, speedup 3.396x
15, opt runtime 47.812s, model runtime 47.812s, pg runtime 83.069s, speedup 1.737x
16, opt runtime 49.511s, model runtime 49.511s, pg runtime 87.329s, speedup 1.764x
17, opt runtime 7.565s, model runtime 7.565s, pg runtime 20.255s, speedup 2.678x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.148s, model runtime 1.214s, pg runtime 1.214s, speedup 1.000x
20, opt runtime 1.347s, model runtime 1.438s, pg runtime 1.438s, speedup 1.000x
21, opt runtime 18.267s, model runtime 21.055s, pg runtime 21.055s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 5.961s, model runtime 5.961s, pg runtime 31.210s, speedup 5.236x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.360s, model runtime 1.360s, pg runtime 1.360s, speedup 1.000x
26, opt runtime 1.265s, model runtime 1.265s, pg runtime 1.265s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.799s, pg runtime 7.799s, speedup 1.000x
28, opt runtime 7.063s, model runtime 7.063s, pg runtime 7.063s, speedup 1.000x
29, opt runtime 5.415s, model runtime 5.415s, pg runtime 5.415s, speedup 1.000x
30, opt runtime 5.175s, model runtime 5.175s, pg runtime 5.175s, speedup 1.000x
31, opt runtime 25.236s, model runtime 25.236s, pg runtime 601.756s, speedup 23.845x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 35.538s, model runtime 42.151s, pg runtime 70.116s, speedup 1.663x
34, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
35, opt runtime 15.120s, model runtime 16.499s, pg runtime 566.078s, speedup 34.310x
36, opt runtime 16.305s, model runtime 16.305s, pg runtime 436.168s, speedup 26.751x
37, opt runtime 11.734s, model runtime 11.734s, pg runtime 11.734s, speedup 1.000x
38, opt runtime 15.302s, model runtime 15.302s, pg runtime 15.302s, speedup 1.000x
39, opt runtime 1.015s, model runtime 1.015s, pg runtime 1.092s, speedup 1.076x
40, opt runtime 1.084s, model runtime 1.084s, pg runtime 1.155s, speedup 1.065x
====================
best train speedup epoch: 33, train speedup 5.389, test speedup 5.256, val speedup 5.547
best test speedup epoch: 34, train speedup 5.359, test speedup 5.270, val speedup 5.485
best validation speedup epoch: 21, train speedup 5.316, test speedup 5.171, val speedup 5.592
last model at epoch 36, train speedup 5.214, test speedup 5.084, val speedup 5.470
execution cost 0:00:37.130145
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

load TPCH...
[2, 3, 4, 6, 7, 9] [1, 0] [8 5]
[0, 1, 2, 5, 7, 9] [4, 3] [6 8]
[0, 1, 5, 6, 7, 8] [3, 2] [4 9]
[0, 2, 3, 4, 6, 7, 9] [1, 8] [5 5]
[0, 3, 4, 5, 7, 9] [1, 6] [8 2]
[1, 2, 4, 5, 6, 8] [0, 9] [3 7]
[0, 2, 5, 6, 7, 8, 9] [1, 3] [4 4]
[0, 1, 2, 4, 6, 7] [3, 8] [9 5]
[1, 2, 3, 5, 6, 7] [9, 0] [4 8]
[0, 1, 4, 5, 6, 7] [8, 3] [9 2]
[0, 1, 2, 3, 7, 9] [8, 6] [5 4]
[0, 2, 4, 5, 6, 8] [3, 7] [1 9]
[0, 1, 2, 5, 7, 8] [9, 4] [3 6]
[1, 4, 5, 6, 8, 9] [0, 2] [7 3]
[0, 1, 2, 4, 7, 8] [6, 5] [9 3]
[1, 3, 5, 7, 8, 9] [4, 2] [6 0]
[0, 2, 6, 7, 8, 9] [3, 5] [4 1]
[0, 2, 3, 4, 7, 8] [1, 9] [6 5]
[2, 3, 5, 7, 8, 9] [6, 1] [4 0]
[1, 3, 4, 6, 7, 8] [5, 9] [0 2]
load TPCH succ
train, test, validation (122, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.487717, and there are 5978 training samples
in channel 9
Epoch 0/300 |loss: 0.051436| train set 2.411x speedup, test set 2.297x speedup, val set 2.448x speedup, step: 1
Epoch 1/300 |loss: 0.017954| train set 2.961x speedup, test set 2.781x speedup, val set 2.991x speedup, step: 1
Epoch 2/300 |loss: 0.009502| train set 3.086x speedup, test set 2.943x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006184| train set 3.506x speedup, test set 3.283x speedup, val set 3.535x speedup, step: 1
Epoch 4/300 |loss: 0.005225| train set 3.225x speedup, test set 3.093x speedup, val set 3.252x speedup, step: 2
Epoch 5/300 |loss: 0.004841| train set 3.498x speedup, test set 3.416x speedup, val set 3.487x speedup, step: 3
Epoch 6/300 |loss: 0.004025| train set 3.369x speedup, test set 3.203x speedup, val set 3.363x speedup, step: 4
Epoch 7/300 |loss: 0.003453| train set 3.940x speedup, test set 3.674x speedup, val set 4.298x speedup, step: 1
Epoch 8/300 |loss: 0.002992| train set 3.821x speedup, test set 3.686x speedup, val set 3.905x speedup, step: 2
Epoch 9/300 |loss: 0.002641| train set 4.503x speedup, test set 4.844x speedup, val set 4.960x speedup, step: 1
Epoch 10/300 |loss: 0.002180| train set 3.933x speedup, test set 3.748x speedup, val set 3.981x speedup, step: 2
Epoch 11/300 |loss: 0.002248| train set 4.885x speedup, test set 4.788x speedup, val set 4.932x speedup, step: 3
Epoch 12/300 |loss: 0.002421| train set 3.682x speedup, test set 3.488x speedup, val set 3.721x speedup, step: 4
Epoch 13/300 |loss: 0.002304| train set 4.999x speedup, test set 4.900x speedup, val set 5.048x speedup, step: 1
Epoch 14/300 |loss: 0.001765| train set 4.159x speedup, test set 3.946x speedup, val set 4.291x speedup, step: 2
Epoch 15/300 |loss: 0.001815| train set 4.653x speedup, test set 4.714x speedup, val set 4.936x speedup, step: 3
Epoch 16/300 |loss: 0.001769| train set 4.934x speedup, test set 5.074x speedup, val set 5.358x speedup, step: 1
Epoch 17/300 |loss: 0.002119| train set 5.222x speedup, test set 5.104x speedup, val set 5.474x speedup, step: 1
Epoch 18/300 |loss: 0.001828| train set 5.160x speedup, test set 5.043x speedup, val set 5.330x speedup, step: 2
Epoch 19/300 |loss: 0.002048| train set 5.299x speedup, test set 5.168x speedup, val set 5.582x speedup, step: 1
Epoch 20/300 |loss: 0.001051| train set 4.964x speedup, test set 4.867x speedup, val set 4.982x speedup, step: 2
Epoch 21/300 |loss: 0.000956| train set 5.385x speedup, test set 5.258x speedup, val set 5.544x speedup, step: 3
Epoch 22/300 |loss: 0.000810| train set 5.383x speedup, test set 5.261x speedup, val set 5.550x speedup, step: 4
Epoch 23/300 |loss: 0.000783| train set 5.305x speedup, test set 5.160x speedup, val set 5.580x speedup, step: 5
Epoch 24/300 |loss: 0.000936| train set 5.389x speedup, test set 5.256x speedup, val set 5.547x speedup, step: 6
Epoch 25/300 |loss: 0.000901| train set 5.389x speedup, test set 5.256x speedup, val set 5.547x speedup, step: 7
Epoch 26/300 |loss: 0.000772| train set 5.389x speedup, test set 5.256x speedup, val set 5.551x speedup, step: 8
Epoch 27/300 |loss: 0.000686| train set 5.389x speedup, test set 5.256x speedup, val set 5.551x speedup, step: 9
Epoch 28/300 |loss: 0.000742| train set 5.364x speedup, test set 5.256x speedup, val set 5.513x speedup, step: 10
Epoch 29/300 |loss: 0.000846| train set 5.389x speedup, test set 5.256x speedup, val set 5.551x speedup, step: 11
Epoch 30/300 |loss: 0.000788| train set 5.385x speedup, test set 5.259x speedup, val set 5.545x speedup, step: 12
Epoch 31/300 |loss: 0.000813| train set 5.364x speedup, test set 5.254x speedup, val set 5.512x speedup, step: 13
Epoch 32/300 |loss: 0.000735| train set 5.387x speedup, test set 5.261x speedup, val set 5.550x speedup, step: 14
Epoch 33/300 |loss: 0.000737| train set 5.389x speedup, test set 5.258x speedup, val set 5.548x speedup, step: 15
Epoch 34/300 |loss: 0.000757| train set 5.380x speedup, test set 5.252x speedup, val set 5.518x speedup, step: 16
Epoch 35/300 |loss: 0.000764| train set 5.389x speedup, test set 5.256x speedup, val set 5.547x speedup, step: 17
Epoch 36/300 |loss: 0.000776| train set 5.360x speedup, test set 5.257x speedup, val set 5.510x speedup, step: 18
early stopping at epoch 36
Training per epoch cost 0.436 s
Optimal speedup on test set is 5.356x
01, opt runtime 29.200s, model runtime 29.200s, pg runtime 29.200s, speedup 1.000x
02, opt runtime 26.072s, model runtime 26.072s, pg runtime 26.072s, speedup 1.000x
03, opt runtime 29.269s, model runtime 29.269s, pg runtime 91.296s, speedup 3.119x
04, opt runtime 29.286s, model runtime 29.286s, pg runtime 92.131s, speedup 3.146x
05, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
06, opt runtime 17.779s, model runtime 17.779s, pg runtime 17.779s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.913s, model runtime 9.037s, pg runtime 15.548s, speedup 1.720x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 21.913s, model runtime 21.913s, pg runtime 74.973s, speedup 3.421x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.590s, model runtime 3.590s, pg runtime 12.193s, speedup 3.396x
15, opt runtime 47.812s, model runtime 47.812s, pg runtime 83.069s, speedup 1.737x
16, opt runtime 49.511s, model runtime 49.511s, pg runtime 87.329s, speedup 1.764x
17, opt runtime 7.565s, model runtime 7.565s, pg runtime 20.255s, speedup 2.678x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.148s, model runtime 1.942s, pg runtime 1.214s, speedup 0.625x
20, opt runtime 1.347s, model runtime 1.768s, pg runtime 1.438s, speedup 0.813x
21, opt runtime 18.267s, model runtime 21.055s, pg runtime 21.055s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 5.961s, model runtime 5.961s, pg runtime 31.210s, speedup 5.236x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.360s, model runtime 1.360s, pg runtime 1.360s, speedup 1.000x
26, opt runtime 1.265s, model runtime 1.265s, pg runtime 1.265s, speedup 1.000x
27, opt runtime 6.789s, model runtime 6.789s, pg runtime 7.799s, speedup 1.149x
28, opt runtime 7.063s, model runtime 7.430s, pg runtime 7.063s, speedup 0.951x
29, opt runtime 5.415s, model runtime 5.415s, pg runtime 5.415s, speedup 1.000x
30, opt runtime 5.175s, model runtime 5.175s, pg runtime 5.175s, speedup 1.000x
31, opt runtime 25.236s, model runtime 25.236s, pg runtime 601.756s, speedup 23.845x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 35.538s, model runtime 42.151s, pg runtime 70.116s, speedup 1.663x
34, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
35, opt runtime 15.120s, model runtime 16.499s, pg runtime 566.078s, speedup 34.310x
36, opt runtime 16.305s, model runtime 16.305s, pg runtime 436.168s, speedup 26.751x
37, opt runtime 11.734s, model runtime 11.734s, pg runtime 11.734s, speedup 1.000x
38, opt runtime 15.302s, model runtime 15.302s, pg runtime 15.302s, speedup 1.000x
39, opt runtime 1.015s, model runtime 1.015s, pg runtime 1.092s, speedup 1.076x
40, opt runtime 1.084s, model runtime 1.084s, pg runtime 1.155s, speedup 1.065x
====================
best train speedup epoch: 24, train speedup 5.389, test speedup 5.256, val speedup 5.547
best test speedup epoch: 22, train speedup 5.383, test speedup 5.261, val speedup 5.550
best validation speedup epoch: 19, train speedup 5.299, test speedup 5.168, val speedup 5.582
last model at epoch 36, train speedup 5.360, test speedup 5.257, val speedup 5.510
execution cost 0:00:36.834849
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

load TPCH...
[2, 3, 4, 6, 7, 9] [1, 0] [8 5]
[0, 1, 2, 5, 7, 9] [4, 3] [6 8]
[0, 1, 5, 6, 7, 8] [3, 2] [4 9]
[0, 2, 3, 4, 6, 7, 9] [1, 8] [5 5]
[0, 3, 4, 5, 7, 9] [1, 6] [8 2]
[1, 2, 4, 5, 6, 8] [0, 9] [3 7]
[0, 2, 5, 6, 7, 8, 9] [1, 3] [4 4]
[0, 1, 2, 4, 6, 7] [3, 8] [9 5]
[1, 2, 3, 5, 6, 7] [9, 0] [4 8]
[0, 1, 4, 5, 6, 7] [8, 3] [9 2]
[0, 1, 2, 3, 7, 9] [8, 6] [5 4]
[0, 2, 4, 5, 6, 8] [3, 7] [1 9]
[0, 1, 2, 5, 7, 8] [9, 4] [3 6]
[1, 4, 5, 6, 8, 9] [0, 2] [7 3]
[0, 1, 2, 4, 7, 8] [6, 5] [9 3]
[1, 3, 5, 7, 8, 9] [4, 2] [6 0]
[0, 2, 6, 7, 8, 9] [3, 5] [4 1]
[0, 2, 3, 4, 7, 8] [1, 9] [6 5]
[2, 3, 5, 7, 8, 9] [6, 1] [4 0]
[1, 3, 4, 6, 7, 8] [5, 9] [0 2]
load TPCH succ
train, test, validation (122, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.489063, and there are 5978 training samples
in channel 9
Epoch 0/300 |loss: 0.051436| train set 2.411x speedup, test set 2.297x speedup, val set 2.448x speedup, step: 1
Epoch 1/300 |loss: 0.017954| train set 2.961x speedup, test set 2.781x speedup, val set 2.991x speedup, step: 1
Epoch 2/300 |loss: 0.009499| train set 3.086x speedup, test set 2.943x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006226| train set 3.701x speedup, test set 3.516x speedup, val set 3.830x speedup, step: 1
Epoch 4/300 |loss: 0.005073| train set 3.155x speedup, test set 3.017x speedup, val set 3.231x speedup, step: 2
Epoch 5/300 |loss: 0.004866| train set 3.297x speedup, test set 3.120x speedup, val set 3.343x speedup, step: 3
Epoch 6/300 |loss: 0.003902| train set 3.573x speedup, test set 3.536x speedup, val set 3.433x speedup, step: 4
Epoch 7/300 |loss: 0.003497| train set 3.940x speedup, test set 3.671x speedup, val set 4.294x speedup, step: 1
Epoch 8/300 |loss: 0.003037| train set 3.858x speedup, test set 3.720x speedup, val set 3.945x speedup, step: 2
Epoch 9/300 |loss: 0.002674| train set 4.947x speedup, test set 4.850x speedup, val set 4.965x speedup, step: 1
Epoch 10/300 |loss: 0.002246| train set 3.594x speedup, test set 3.466x speedup, val set 3.625x speedup, step: 2
Epoch 11/300 |loss: 0.002555| train set 4.967x speedup, test set 4.867x speedup, val set 4.988x speedup, step: 1
Epoch 12/300 |loss: 0.002476| train set 3.695x speedup, test set 3.466x speedup, val set 3.692x speedup, step: 2
Epoch 13/300 |loss: 0.002301| train set 5.287x speedup, test set 5.135x speedup, val set 5.439x speedup, step: 1
Epoch 14/300 |loss: 0.001790| train set 4.165x speedup, test set 3.946x speedup, val set 4.295x speedup, step: 2
Epoch 15/300 |loss: 0.001779| train set 4.579x speedup, test set 4.860x speedup, val set 4.983x speedup, step: 3
Epoch 16/300 |loss: 0.001851| train set 3.654x speedup, test set 3.457x speedup, val set 3.690x speedup, step: 4
Epoch 17/300 |loss: 0.002223| train set 4.700x speedup, test set 4.790x speedup, val set 5.008x speedup, step: 5
Epoch 18/300 |loss: 0.002121| train set 5.314x speedup, test set 5.175x speedup, val set 5.591x speedup, step: 1
Epoch 19/300 |loss: 0.002032| train set 5.307x speedup, test set 5.192x speedup, val set 5.464x speedup, step: 2
Epoch 20/300 |loss: 0.001161| train set 5.289x speedup, test set 5.183x speedup, val set 5.431x speedup, step: 3
Epoch 21/300 |loss: 0.000968| train set 5.389x speedup, test set 5.257x speedup, val set 5.538x speedup, step: 4
Epoch 22/300 |loss: 0.000894| train set 5.387x speedup, test set 5.260x speedup, val set 5.555x speedup, step: 5
Epoch 23/300 |loss: 0.000874| train set 5.383x speedup, test set 5.250x speedup, val set 5.546x speedup, step: 6
Epoch 24/300 |loss: 0.000968| train set 5.318x speedup, test set 5.165x speedup, val set 5.440x speedup, step: 7
Epoch 25/300 |loss: 0.000934| train set 5.389x speedup, test set 5.256x speedup, val set 5.547x speedup, step: 8
Epoch 26/300 |loss: 0.000814| train set 5.389x speedup, test set 5.256x speedup, val set 5.551x speedup, step: 9
Epoch 27/300 |loss: 0.000713| train set 5.383x speedup, test set 5.250x speedup, val set 5.546x speedup, step: 10
Epoch 28/300 |loss: 0.000762| train set 5.355x speedup, test set 5.256x speedup, val set 5.500x speedup, step: 11
Epoch 29/300 |loss: 0.000813| train set 5.389x speedup, test set 5.256x speedup, val set 5.551x speedup, step: 12
Epoch 30/300 |loss: 0.000776| train set 5.387x speedup, test set 5.262x speedup, val set 5.552x speedup, step: 13
Epoch 31/300 |loss: 0.000797| train set 5.389x speedup, test set 5.256x speedup, val set 5.547x speedup, step: 14
Epoch 32/300 |loss: 0.000733| train set 5.381x speedup, test set 5.255x speedup, val set 5.551x speedup, step: 15
Epoch 33/300 |loss: 0.000752| train set 5.387x speedup, test set 5.259x speedup, val set 5.553x speedup, step: 16
Epoch 34/300 |loss: 0.000777| train set 5.279x speedup, test set 5.157x speedup, val set 5.542x speedup, step: 17
Epoch 35/300 |loss: 0.000794| train set 5.383x speedup, test set 5.250x speedup, val set 5.542x speedup, step: 18
Epoch 36/300 |loss: 0.000792| train set 5.283x speedup, test set 5.172x speedup, val set 5.412x speedup, step: 19
early stopping at epoch 36
Training per epoch cost 0.421 s
Optimal speedup on test set is 5.356x
01, opt runtime 29.200s, model runtime 29.200s, pg runtime 29.200s, speedup 1.000x
02, opt runtime 26.072s, model runtime 26.072s, pg runtime 26.072s, speedup 1.000x
03, opt runtime 29.269s, model runtime 29.269s, pg runtime 91.296s, speedup 3.119x
04, opt runtime 29.286s, model runtime 29.286s, pg runtime 92.131s, speedup 3.146x
05, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
06, opt runtime 17.779s, model runtime 17.779s, pg runtime 17.779s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.913s, model runtime 9.037s, pg runtime 15.548s, speedup 1.720x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 21.913s, model runtime 21.913s, pg runtime 74.973s, speedup 3.421x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.590s, model runtime 3.590s, pg runtime 12.193s, speedup 3.396x
15, opt runtime 47.812s, model runtime 47.812s, pg runtime 83.069s, speedup 1.737x
16, opt runtime 49.511s, model runtime 49.511s, pg runtime 87.329s, speedup 1.764x
17, opt runtime 7.565s, model runtime 7.565s, pg runtime 20.255s, speedup 2.678x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.148s, model runtime 1.148s, pg runtime 1.214s, speedup 1.057x
20, opt runtime 1.347s, model runtime 1.347s, pg runtime 1.438s, speedup 1.067x
21, opt runtime 18.267s, model runtime 21.055s, pg runtime 21.055s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 5.961s, model runtime 5.961s, pg runtime 31.210s, speedup 5.236x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.360s, model runtime 1.360s, pg runtime 1.360s, speedup 1.000x
26, opt runtime 1.265s, model runtime 1.265s, pg runtime 1.265s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.197s, pg runtime 7.799s, speedup 1.084x
28, opt runtime 7.063s, model runtime 7.159s, pg runtime 7.063s, speedup 0.987x
29, opt runtime 5.415s, model runtime 5.415s, pg runtime 5.415s, speedup 1.000x
30, opt runtime 5.175s, model runtime 5.175s, pg runtime 5.175s, speedup 1.000x
31, opt runtime 25.236s, model runtime 25.236s, pg runtime 601.756s, speedup 23.845x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 35.538s, model runtime 42.151s, pg runtime 70.116s, speedup 1.663x
34, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
35, opt runtime 15.120s, model runtime 16.499s, pg runtime 566.078s, speedup 34.310x
36, opt runtime 16.305s, model runtime 16.305s, pg runtime 436.168s, speedup 26.751x
37, opt runtime 11.734s, model runtime 11.734s, pg runtime 11.734s, speedup 1.000x
38, opt runtime 15.302s, model runtime 15.302s, pg runtime 15.302s, speedup 1.000x
39, opt runtime 1.015s, model runtime 1.092s, pg runtime 1.092s, speedup 1.000x
40, opt runtime 1.084s, model runtime 1.155s, pg runtime 1.155s, speedup 1.000x
====================
best train speedup epoch: 25, train speedup 5.389, test speedup 5.256, val speedup 5.547
best test speedup epoch: 30, train speedup 5.387, test speedup 5.262, val speedup 5.552
best validation speedup epoch: 18, train speedup 5.314, test speedup 5.175, val speedup 5.591
last model at epoch 36, train speedup 5.283, test speedup 5.172, val speedup 5.412
execution cost 0:00:36.100578
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

load TPCH...
[2, 3, 4, 6, 7, 9] [1, 0] [8 5]
[0, 1, 2, 5, 7, 9] [4, 3] [6 8]
[0, 1, 5, 6, 7, 8] [3, 2] [4 9]
[0, 2, 3, 4, 6, 7, 9] [1, 8] [5 5]
[0, 3, 4, 5, 7, 9] [1, 6] [8 2]
[1, 2, 4, 5, 6, 8] [0, 9] [3 7]
[0, 2, 5, 6, 7, 8, 9] [1, 3] [4 4]
[0, 1, 2, 4, 6, 7] [3, 8] [9 5]
[1, 2, 3, 5, 6, 7] [9, 0] [4 8]
[0, 1, 4, 5, 6, 7] [8, 3] [9 2]
[0, 1, 2, 3, 7, 9] [8, 6] [5 4]
[0, 2, 4, 5, 6, 8] [3, 7] [1 9]
[0, 1, 2, 5, 7, 8] [9, 4] [3 6]
[1, 4, 5, 6, 8, 9] [0, 2] [7 3]
[0, 1, 2, 4, 7, 8] [6, 5] [9 3]
[1, 3, 5, 7, 8, 9] [4, 2] [6 0]
[0, 2, 6, 7, 8, 9] [3, 5] [4 1]
[0, 2, 3, 4, 7, 8] [1, 9] [6 5]
[2, 3, 5, 7, 8, 9] [6, 1] [4 0]
[1, 3, 4, 6, 7, 8] [5, 9] [0 2]
load TPCH succ
train, test, validation (122, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.497545, and there are 5978 training samples
in channel 9
Epoch 0/300 |loss: 0.051436| train set 2.411x speedup, test set 2.297x speedup, val set 2.448x speedup, step: 1
Epoch 1/300 |loss: 0.017954| train set 2.961x speedup, test set 2.781x speedup, val set 2.991x speedup, step: 1
Epoch 2/300 |loss: 0.009499| train set 3.086x speedup, test set 2.943x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006226| train set 3.701x speedup, test set 3.516x speedup, val set 3.830x speedup, step: 1
Epoch 4/300 |loss: 0.005077| train set 3.155x speedup, test set 3.017x speedup, val set 3.231x speedup, step: 2
Epoch 5/300 |loss: 0.004849| train set 3.457x speedup, test set 3.321x speedup, val set 3.592x speedup, step: 3
Epoch 6/300 |loss: 0.003879| train set 3.407x speedup, test set 3.236x speedup, val set 3.404x speedup, step: 4
Epoch 7/300 |loss: 0.003599| train set 3.823x speedup, test set 3.673x speedup, val set 3.907x speedup, step: 1
Epoch 8/300 |loss: 0.003003| train set 3.819x speedup, test set 3.685x speedup, val set 3.904x speedup, step: 2
Epoch 9/300 |loss: 0.002697| train set 4.961x speedup, test set 4.863x speedup, val set 4.985x speedup, step: 1
Epoch 10/300 |loss: 0.002217| train set 3.862x speedup, test set 3.746x speedup, val set 3.827x speedup, step: 2
Epoch 11/300 |loss: 0.002398| train set 4.855x speedup, test set 4.761x speedup, val set 4.924x speedup, step: 3
Epoch 12/300 |loss: 0.002518| train set 3.798x speedup, test set 3.716x speedup, val set 3.692x speedup, step: 4
Epoch 13/300 |loss: 0.002313| train set 4.832x speedup, test set 4.713x speedup, val set 4.996x speedup, step: 1
Epoch 14/300 |loss: 0.001769| train set 3.947x speedup, test set 3.757x speedup, val set 3.987x speedup, step: 2
Epoch 15/300 |loss: 0.001807| train set 4.766x speedup, test set 4.869x speedup, val set 4.988x speedup, step: 3
Epoch 16/300 |loss: 0.002066| train set 3.560x speedup, test set 3.375x speedup, val set 3.607x speedup, step: 4
Epoch 17/300 |loss: 0.002293| train set 4.356x speedup, test set 3.713x speedup, val set 5.008x speedup, step: 1
Epoch 18/300 |loss: 0.002118| train set 5.315x speedup, test set 5.172x speedup, val set 5.589x speedup, step: 1
Epoch 19/300 |loss: 0.002026| train set 5.233x speedup, test set 5.104x speedup, val set 5.500x speedup, step: 2
Epoch 20/300 |loss: 0.001239| train set 4.963x speedup, test set 4.862x speedup, val set 4.986x speedup, step: 3
Epoch 21/300 |loss: 0.001146| train set 5.309x speedup, test set 5.174x speedup, val set 5.581x speedup, step: 4
Epoch 22/300 |loss: 0.000948| train set 5.314x speedup, test set 5.174x speedup, val set 5.594x speedup, step: 1
Epoch 23/300 |loss: 0.000833| train set 5.383x speedup, test set 5.251x speedup, val set 5.543x speedup, step: 2
Epoch 24/300 |loss: 0.000925| train set 5.323x speedup, test set 5.166x speedup, val set 5.450x speedup, step: 3
Epoch 25/300 |loss: 0.000940| train set 5.386x speedup, test set 5.258x speedup, val set 5.544x speedup, step: 4
Epoch 26/300 |loss: 0.000812| train set 5.290x speedup, test set 5.165x speedup, val set 5.479x speedup, step: 5
Epoch 27/300 |loss: 0.000733| train set 5.372x speedup, test set 5.252x speedup, val set 5.541x speedup, step: 6
Epoch 28/300 |loss: 0.000774| train set 5.364x speedup, test set 5.254x speedup, val set 5.516x speedup, step: 7
Epoch 29/300 |loss: 0.000797| train set 5.389x speedup, test set 5.256x speedup, val set 5.551x speedup, step: 8
Epoch 30/300 |loss: 0.000722| train set 5.362x speedup, test set 5.259x speedup, val set 5.515x speedup, step: 9
Epoch 31/300 |loss: 0.000891| train set 5.387x speedup, test set 5.259x speedup, val set 5.553x speedup, step: 10
Epoch 32/300 |loss: 0.000737| train set 5.389x speedup, test set 5.256x speedup, val set 5.547x speedup, step: 11
Epoch 33/300 |loss: 0.000717| train set 5.387x speedup, test set 5.262x speedup, val set 5.552x speedup, step: 12
Epoch 34/300 |loss: 0.000783| train set 5.362x speedup, test set 5.258x speedup, val set 5.519x speedup, step: 13
Epoch 35/300 |loss: 0.000758| train set 5.287x speedup, test set 5.169x speedup, val set 5.476x speedup, step: 14
Epoch 36/300 |loss: 0.000753| train set 5.358x speedup, test set 5.260x speedup, val set 5.516x speedup, step: 15
early stopping at epoch 36
Training per epoch cost 0.441 s
Optimal speedup on test set is 5.356x
01, opt runtime 29.200s, model runtime 29.200s, pg runtime 29.200s, speedup 1.000x
02, opt runtime 26.072s, model runtime 26.072s, pg runtime 26.072s, speedup 1.000x
03, opt runtime 29.269s, model runtime 29.269s, pg runtime 91.296s, speedup 3.119x
04, opt runtime 29.286s, model runtime 29.286s, pg runtime 92.131s, speedup 3.146x
05, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
06, opt runtime 17.779s, model runtime 17.779s, pg runtime 17.779s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.913s, model runtime 9.037s, pg runtime 15.548s, speedup 1.720x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 21.913s, model runtime 21.913s, pg runtime 74.973s, speedup 3.421x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.590s, model runtime 3.590s, pg runtime 12.193s, speedup 3.396x
15, opt runtime 47.812s, model runtime 47.812s, pg runtime 83.069s, speedup 1.737x
16, opt runtime 49.511s, model runtime 49.511s, pg runtime 87.329s, speedup 1.764x
17, opt runtime 7.565s, model runtime 7.565s, pg runtime 20.255s, speedup 2.678x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.148s, model runtime 1.214s, pg runtime 1.214s, speedup 1.000x
20, opt runtime 1.347s, model runtime 1.438s, pg runtime 1.438s, speedup 1.000x
21, opt runtime 18.267s, model runtime 21.055s, pg runtime 21.055s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 5.961s, model runtime 5.961s, pg runtime 31.210s, speedup 5.236x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.360s, model runtime 1.360s, pg runtime 1.360s, speedup 1.000x
26, opt runtime 1.265s, model runtime 1.265s, pg runtime 1.265s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.197s, pg runtime 7.799s, speedup 1.084x
28, opt runtime 7.063s, model runtime 7.159s, pg runtime 7.063s, speedup 0.987x
29, opt runtime 5.415s, model runtime 5.415s, pg runtime 5.415s, speedup 1.000x
30, opt runtime 5.175s, model runtime 5.175s, pg runtime 5.175s, speedup 1.000x
31, opt runtime 25.236s, model runtime 25.236s, pg runtime 601.756s, speedup 23.845x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 35.538s, model runtime 42.151s, pg runtime 70.116s, speedup 1.663x
34, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
35, opt runtime 15.120s, model runtime 16.499s, pg runtime 566.078s, speedup 34.310x
36, opt runtime 16.305s, model runtime 16.305s, pg runtime 436.168s, speedup 26.751x
37, opt runtime 11.734s, model runtime 11.734s, pg runtime 11.734s, speedup 1.000x
38, opt runtime 15.302s, model runtime 15.302s, pg runtime 15.302s, speedup 1.000x
39, opt runtime 1.015s, model runtime 1.092s, pg runtime 1.092s, speedup 1.000x
40, opt runtime 1.084s, model runtime 1.155s, pg runtime 1.155s, speedup 1.000x
====================
best train speedup epoch: 29, train speedup 5.389, test speedup 5.256, val speedup 5.551
best test speedup epoch: 33, train speedup 5.387, test speedup 5.262, val speedup 5.552
best validation speedup epoch: 22, train speedup 5.314, test speedup 5.174, val speedup 5.594
last model at epoch 36, train speedup 5.358, test speedup 5.260, val speedup 5.516
execution cost 0:00:36.401582
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

load TPCH...
[2, 3, 4, 6, 7, 9] [1, 0] [8 5]
[0, 1, 2, 5, 7, 9] [4, 3] [6 8]
[0, 1, 5, 6, 7, 8] [3, 2] [4 9]
[0, 2, 3, 4, 6, 7, 9] [1, 8] [5 5]
[0, 3, 4, 5, 7, 9] [1, 6] [8 2]
[1, 2, 4, 5, 6, 8] [0, 9] [3 7]
[0, 2, 5, 6, 7, 8, 9] [1, 3] [4 4]
[0, 1, 2, 4, 6, 7] [3, 8] [9 5]
[1, 2, 3, 5, 6, 7] [9, 0] [4 8]
[0, 1, 4, 5, 6, 7] [8, 3] [9 2]
[0, 1, 2, 3, 7, 9] [8, 6] [5 4]
[0, 2, 4, 5, 6, 8] [3, 7] [1 9]
[0, 1, 2, 5, 7, 8] [9, 4] [3 6]
[1, 4, 5, 6, 8, 9] [0, 2] [7 3]
[0, 1, 2, 4, 7, 8] [6, 5] [9 3]
[1, 3, 5, 7, 8, 9] [4, 2] [6 0]
[0, 2, 6, 7, 8, 9] [3, 5] [4 1]
[0, 2, 3, 4, 7, 8] [1, 9] [6 5]
[2, 3, 5, 7, 8, 9] [6, 1] [4 0]
[1, 3, 4, 6, 7, 8] [5, 9] [0 2]
load TPCH succ
train, test, validation (122, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.516501, and there are 5978 training samples
in channel 9
Epoch 0/300 |loss: 0.051436| train set 2.411x speedup, test set 2.297x speedup, val set 2.448x speedup, step: 1
Epoch 1/300 |loss: 0.017954| train set 2.961x speedup, test set 2.781x speedup, val set 2.991x speedup, step: 1
Epoch 2/300 |loss: 0.009502| train set 3.086x speedup, test set 2.943x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006184| train set 3.506x speedup, test set 3.283x speedup, val set 3.535x speedup, step: 1
Epoch 4/300 |loss: 0.005225| train set 3.225x speedup, test set 3.093x speedup, val set 3.252x speedup, step: 2
Epoch 5/300 |loss: 0.004841| train set 3.498x speedup, test set 3.416x speedup, val set 3.487x speedup, step: 3
Epoch 6/300 |loss: 0.004024| train set 3.336x speedup, test set 3.202x speedup, val set 3.364x speedup, step: 4
Epoch 7/300 |loss: 0.003471| train set 3.822x speedup, test set 3.672x speedup, val set 3.906x speedup, step: 1
Epoch 8/300 |loss: 0.003064| train set 3.858x speedup, test set 3.720x speedup, val set 3.945x speedup, step: 1
Epoch 9/300 |loss: 0.002640| train set 3.698x speedup, test set 3.503x speedup, val set 3.688x speedup, step: 2
Epoch 10/300 |loss: 0.002245| train set 3.594x speedup, test set 3.469x speedup, val set 3.628x speedup, step: 3
Epoch 11/300 |loss: 0.002729| train set 4.849x speedup, test set 4.755x speedup, val set 4.912x speedup, step: 1
Epoch 12/300 |loss: 0.002526| train set 3.806x speedup, test set 3.647x speedup, val set 3.885x speedup, step: 2
Epoch 13/300 |loss: 0.002734| train set 4.896x speedup, test set 4.803x speedup, val set 4.948x speedup, step: 1
Epoch 14/300 |loss: 0.002122| train set 3.907x speedup, test set 3.717x speedup, val set 4.016x speedup, step: 2
Epoch 15/300 |loss: 0.002036| train set 4.955x speedup, test set 4.856x speedup, val set 4.981x speedup, step: 1
Epoch 16/300 |loss: 0.002076| train set 4.693x speedup, test set 5.071x speedup, val set 5.330x speedup, step: 1
Epoch 17/300 |loss: 0.002223| train set 5.078x speedup, test set 4.949x speedup, val set 5.343x speedup, step: 1
Epoch 18/300 |loss: 0.001601| train set 5.316x speedup, test set 5.170x speedup, val set 5.591x speedup, step: 1
Epoch 19/300 |loss: 0.001544| train set 5.375x speedup, test set 5.254x speedup, val set 5.543x speedup, step: 2
Epoch 20/300 |loss: 0.001107| train set 4.885x speedup, test set 4.794x speedup, val set 4.991x speedup, step: 3
Epoch 21/300 |loss: 0.001022| train set 5.316x speedup, test set 5.170x speedup, val set 5.591x speedup, step: 1
Epoch 22/300 |loss: 0.000862| train set 5.382x speedup, test set 5.260x speedup, val set 5.548x speedup, step: 2
Epoch 23/300 |loss: 0.000825| train set 5.389x speedup, test set 5.256x speedup, val set 5.551x speedup, step: 3
Epoch 24/300 |loss: 0.000950| train set 5.389x speedup, test set 5.255x speedup, val set 5.550x speedup, step: 4
Epoch 25/300 |loss: 0.000900| train set 5.389x speedup, test set 5.256x speedup, val set 5.547x speedup, step: 5
Epoch 26/300 |loss: 0.000831| train set 5.315x speedup, test set 5.172x speedup, val set 5.589x speedup, step: 6
Epoch 27/300 |loss: 0.000715| train set 5.389x speedup, test set 5.256x speedup, val set 5.551x speedup, step: 7
Epoch 28/300 |loss: 0.000711| train set 5.353x speedup, test set 5.249x speedup, val set 5.508x speedup, step: 8
Epoch 29/300 |loss: 0.000855| train set 5.389x speedup, test set 5.256x speedup, val set 5.551x speedup, step: 9
Epoch 30/300 |loss: 0.000918| train set 5.387x speedup, test set 5.262x speedup, val set 5.552x speedup, step: 10
Epoch 31/300 |loss: 0.000811| train set 5.364x speedup, test set 5.254x speedup, val set 5.512x speedup, step: 11
Epoch 32/300 |loss: 0.000748| train set 5.316x speedup, test set 5.170x speedup, val set 5.591x speedup, step: 1
Epoch 33/300 |loss: 0.000756| train set 5.382x speedup, test set 5.262x speedup, val set 5.545x speedup, step: 2
Epoch 34/300 |loss: 0.000755| train set 5.389x speedup, test set 5.259x speedup, val set 5.530x speedup, step: 3
Epoch 35/300 |loss: 0.000733| train set 5.352x speedup, test set 5.224x speedup, val set 5.536x speedup, step: 4
Epoch 36/300 |loss: 0.000763| train set 5.387x speedup, test set 5.262x speedup, val set 5.552x speedup, step: 5
early stopping at epoch 36
Training per epoch cost 0.441 s
Optimal speedup on test set is 5.356x
01, opt runtime 29.200s, model runtime 29.200s, pg runtime 29.200s, speedup 1.000x
02, opt runtime 26.072s, model runtime 26.072s, pg runtime 26.072s, speedup 1.000x
03, opt runtime 29.269s, model runtime 29.269s, pg runtime 91.296s, speedup 3.119x
04, opt runtime 29.286s, model runtime 29.286s, pg runtime 92.131s, speedup 3.146x
05, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
06, opt runtime 17.779s, model runtime 17.779s, pg runtime 17.779s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.913s, model runtime 9.037s, pg runtime 15.548s, speedup 1.720x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 21.913s, model runtime 21.913s, pg runtime 74.973s, speedup 3.421x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.590s, model runtime 3.590s, pg runtime 12.193s, speedup 3.396x
15, opt runtime 47.812s, model runtime 47.812s, pg runtime 83.069s, speedup 1.737x
16, opt runtime 49.511s, model runtime 49.511s, pg runtime 87.329s, speedup 1.764x
17, opt runtime 7.565s, model runtime 7.565s, pg runtime 20.255s, speedup 2.678x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.148s, model runtime 1.214s, pg runtime 1.214s, speedup 1.000x
20, opt runtime 1.347s, model runtime 1.438s, pg runtime 1.438s, speedup 1.000x
21, opt runtime 18.267s, model runtime 21.055s, pg runtime 21.055s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 5.961s, model runtime 5.961s, pg runtime 31.210s, speedup 5.236x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.360s, model runtime 1.360s, pg runtime 1.360s, speedup 1.000x
26, opt runtime 1.265s, model runtime 1.265s, pg runtime 1.265s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.799s, pg runtime 7.799s, speedup 1.000x
28, opt runtime 7.063s, model runtime 7.063s, pg runtime 7.063s, speedup 1.000x
29, opt runtime 5.415s, model runtime 5.415s, pg runtime 5.415s, speedup 1.000x
30, opt runtime 5.175s, model runtime 5.175s, pg runtime 5.175s, speedup 1.000x
31, opt runtime 25.236s, model runtime 25.236s, pg runtime 601.756s, speedup 23.845x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 35.538s, model runtime 42.151s, pg runtime 70.116s, speedup 1.663x
34, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
35, opt runtime 15.120s, model runtime 16.499s, pg runtime 566.078s, speedup 34.310x
36, opt runtime 16.305s, model runtime 16.305s, pg runtime 436.168s, speedup 26.751x
37, opt runtime 11.734s, model runtime 11.734s, pg runtime 11.734s, speedup 1.000x
38, opt runtime 15.302s, model runtime 15.302s, pg runtime 15.302s, speedup 1.000x
39, opt runtime 1.015s, model runtime 1.092s, pg runtime 1.092s, speedup 1.000x
40, opt runtime 1.084s, model runtime 1.155s, pg runtime 1.155s, speedup 1.000x
====================
best train speedup epoch: 25, train speedup 5.389, test speedup 5.256, val speedup 5.547
best test speedup epoch: 30, train speedup 5.387, test speedup 5.262, val speedup 5.552
best validation speedup epoch: 32, train speedup 5.316, test speedup 5.170, val speedup 5.591
last model at epoch 36, train speedup 5.387, test speedup 5.262, val speedup 5.552
execution cost 0:00:36.747403
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

load TPCH...
[2, 3, 4, 6, 7, 9] [1, 0] [8 5]
[0, 1, 2, 5, 7, 9] [4, 3] [6 8]
[0, 1, 5, 6, 7, 8] [3, 2] [4 9]
[0, 2, 3, 4, 6, 7, 9] [1, 8] [5 5]
[0, 3, 4, 5, 7, 9] [1, 6] [8 2]
[1, 2, 4, 5, 6, 8] [0, 9] [3 7]
[0, 2, 5, 6, 7, 8, 9] [1, 3] [4 4]
[0, 1, 2, 4, 6, 7] [3, 8] [9 5]
[1, 2, 3, 5, 6, 7] [9, 0] [4 8]
[0, 1, 4, 5, 6, 7] [8, 3] [9 2]
[0, 1, 2, 3, 7, 9] [8, 6] [5 4]
[0, 2, 4, 5, 6, 8] [3, 7] [1 9]
[0, 1, 2, 5, 7, 8] [9, 4] [3 6]
[1, 4, 5, 6, 8, 9] [0, 2] [7 3]
[0, 1, 2, 4, 7, 8] [6, 5] [9 3]
[1, 3, 5, 7, 8, 9] [4, 2] [6 0]
[0, 2, 6, 7, 8, 9] [3, 5] [4 1]
[0, 2, 3, 4, 7, 8] [1, 9] [6 5]
[2, 3, 5, 7, 8, 9] [6, 1] [4 0]
[1, 3, 4, 6, 7, 8] [5, 9] [0 2]
load TPCH succ
train, test, validation (122, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.510683, and there are 5978 training samples
in channel 9
Epoch 0/300 |loss: 0.051436| train set 2.411x speedup, test set 2.297x speedup, val set 2.448x speedup, step: 1
Epoch 1/300 |loss: 0.017954| train set 2.961x speedup, test set 2.781x speedup, val set 2.991x speedup, step: 1
Epoch 2/300 |loss: 0.009502| train set 3.086x speedup, test set 2.943x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006184| train set 3.506x speedup, test set 3.283x speedup, val set 3.535x speedup, step: 1
Epoch 4/300 |loss: 0.005225| train set 3.225x speedup, test set 3.093x speedup, val set 3.252x speedup, step: 2
Epoch 5/300 |loss: 0.004841| train set 3.498x speedup, test set 3.416x speedup, val set 3.487x speedup, step: 3
Epoch 6/300 |loss: 0.004022| train set 3.369x speedup, test set 3.202x speedup, val set 3.364x speedup, step: 4
Epoch 7/300 |loss: 0.003464| train set 3.725x speedup, test set 3.578x speedup, val set 3.789x speedup, step: 1
Epoch 8/300 |loss: 0.003155| train set 3.826x speedup, test set 3.685x speedup, val set 3.907x speedup, step: 1
Epoch 9/300 |loss: 0.002715| train set 3.864x speedup, test set 3.496x speedup, val set 4.217x speedup, step: 1
Epoch 10/300 |loss: 0.002231| train set 3.420x speedup, test set 3.241x speedup, val set 3.403x speedup, step: 2
Epoch 11/300 |loss: 0.002881| train set 4.870x speedup, test set 4.766x speedup, val set 5.004x speedup, step: 1
Epoch 12/300 |loss: 0.002475| train set 3.926x speedup, test set 3.887x speedup, val set 3.929x speedup, step: 2
Epoch 13/300 |loss: 0.002322| train set 5.030x speedup, test set 4.930x speedup, val set 5.055x speedup, step: 1
Epoch 14/300 |loss: 0.001843| train set 4.125x speedup, test set 3.901x speedup, val set 4.322x speedup, step: 2
Epoch 15/300 |loss: 0.001863| train set 4.968x speedup, test set 4.870x speedup, val set 4.980x speedup, step: 3
Epoch 16/300 |loss: 0.002060| train set 3.880x speedup, test set 3.655x speedup, val set 3.909x speedup, step: 4
Epoch 17/300 |loss: 0.002144| train set 5.291x speedup, test set 5.169x speedup, val set 5.552x speedup, step: 1
Epoch 18/300 |loss: 0.001526| train set 5.387x speedup, test set 5.262x speedup, val set 5.552x speedup, step: 2
Epoch 19/300 |loss: 0.001676| train set 5.239x speedup, test set 5.111x speedup, val set 5.507x speedup, step: 3
Epoch 20/300 |loss: 0.001172| train set 5.314x speedup, test set 5.190x speedup, val set 5.472x speedup, step: 4
Epoch 21/300 |loss: 0.000946| train set 5.316x speedup, test set 5.171x speedup, val set 5.588x speedup, step: 1
Epoch 22/300 |loss: 0.000804| train set 5.387x speedup, test set 5.259x speedup, val set 5.553x speedup, step: 2
Epoch 23/300 |loss: 0.000790| train set 5.389x speedup, test set 5.257x speedup, val set 5.548x speedup, step: 3
Epoch 24/300 |loss: 0.000912| train set 5.318x speedup, test set 5.163x speedup, val set 5.442x speedup, step: 4
Epoch 25/300 |loss: 0.000906| train set 5.389x speedup, test set 5.256x speedup, val set 5.547x speedup, step: 5
Epoch 26/300 |loss: 0.000820| train set 5.311x speedup, test set 5.173x speedup, val set 5.586x speedup, step: 6
Epoch 27/300 |loss: 0.000735| train set 5.389x speedup, test set 5.256x speedup, val set 5.547x speedup, step: 7
Epoch 28/300 |loss: 0.000773| train set 5.345x speedup, test set 5.249x speedup, val set 5.493x speedup, step: 8
Epoch 29/300 |loss: 0.000918| train set 5.389x speedup, test set 5.256x speedup, val set 5.551x speedup, step: 9
Epoch 30/300 |loss: 0.000884| train set 5.384x speedup, test set 5.262x speedup, val set 5.547x speedup, step: 10
Epoch 31/300 |loss: 0.000866| train set 5.357x speedup, test set 5.249x speedup, val set 5.508x speedup, step: 11
early stopping at epoch 31
Training per epoch cost 0.435 s
Optimal speedup on test set is 5.356x
01, opt runtime 29.200s, model runtime 29.200s, pg runtime 29.200s, speedup 1.000x
02, opt runtime 26.072s, model runtime 26.072s, pg runtime 26.072s, speedup 1.000x
03, opt runtime 29.269s, model runtime 29.269s, pg runtime 91.296s, speedup 3.119x
04, opt runtime 29.286s, model runtime 29.286s, pg runtime 92.131s, speedup 3.146x
05, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
06, opt runtime 17.779s, model runtime 17.779s, pg runtime 17.779s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.913s, model runtime 9.037s, pg runtime 15.548s, speedup 1.720x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 21.913s, model runtime 21.913s, pg runtime 74.973s, speedup 3.421x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.590s, model runtime 3.590s, pg runtime 12.193s, speedup 3.396x
15, opt runtime 47.812s, model runtime 47.812s, pg runtime 83.069s, speedup 1.737x
16, opt runtime 49.511s, model runtime 49.511s, pg runtime 87.329s, speedup 1.764x
17, opt runtime 7.565s, model runtime 7.565s, pg runtime 20.255s, speedup 2.678x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.148s, model runtime 1.148s, pg runtime 1.214s, speedup 1.057x
20, opt runtime 1.347s, model runtime 1.347s, pg runtime 1.438s, speedup 1.067x
21, opt runtime 18.267s, model runtime 21.055s, pg runtime 21.055s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 5.961s, model runtime 5.961s, pg runtime 31.210s, speedup 5.236x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.360s, model runtime 1.360s, pg runtime 1.360s, speedup 1.000x
26, opt runtime 1.265s, model runtime 1.265s, pg runtime 1.265s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.799s, pg runtime 7.799s, speedup 1.000x
28, opt runtime 7.063s, model runtime 7.063s, pg runtime 7.063s, speedup 1.000x
29, opt runtime 5.415s, model runtime 5.415s, pg runtime 5.415s, speedup 1.000x
30, opt runtime 5.175s, model runtime 5.175s, pg runtime 5.175s, speedup 1.000x
31, opt runtime 25.236s, model runtime 25.236s, pg runtime 601.756s, speedup 23.845x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 35.538s, model runtime 42.151s, pg runtime 70.116s, speedup 1.663x
34, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
35, opt runtime 15.120s, model runtime 16.499s, pg runtime 566.078s, speedup 34.310x
36, opt runtime 16.305s, model runtime 16.305s, pg runtime 436.168s, speedup 26.751x
37, opt runtime 11.734s, model runtime 11.734s, pg runtime 11.734s, speedup 1.000x
38, opt runtime 15.302s, model runtime 15.302s, pg runtime 15.302s, speedup 1.000x
39, opt runtime 1.015s, model runtime 1.092s, pg runtime 1.092s, speedup 1.000x
40, opt runtime 1.084s, model runtime 1.155s, pg runtime 1.155s, speedup 1.000x
====================
best train speedup epoch: 25, train speedup 5.389, test speedup 5.256, val speedup 5.547
best test speedup epoch: 30, train speedup 5.384, test speedup 5.262, val speedup 5.547
best validation speedup epoch: 21, train speedup 5.316, test speedup 5.171, val speedup 5.588
last model at epoch 31, train speedup 5.357, test speedup 5.249, val speedup 5.508
execution cost 0:00:32.238504
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

load TPCH...
[2, 3, 4, 6, 7, 9] [1, 0] [8 5]
[0, 1, 2, 5, 7, 9] [4, 3] [6 8]
[0, 1, 5, 6, 7, 8] [3, 2] [4 9]
[0, 2, 3, 4, 6, 7, 9] [1, 8] [5 5]
[0, 3, 4, 5, 7, 9] [1, 6] [8 2]
[1, 2, 4, 5, 6, 8] [0, 9] [3 7]
[0, 2, 5, 6, 7, 8, 9] [1, 3] [4 4]
[0, 1, 2, 4, 6, 7] [3, 8] [9 5]
[1, 2, 3, 5, 6, 7] [9, 0] [4 8]
[0, 1, 4, 5, 6, 7] [8, 3] [9 2]
[0, 1, 2, 3, 7, 9] [8, 6] [5 4]
[0, 2, 4, 5, 6, 8] [3, 7] [1 9]
[0, 1, 2, 5, 7, 8] [9, 4] [3 6]
[1, 4, 5, 6, 8, 9] [0, 2] [7 3]
[0, 1, 2, 4, 7, 8] [6, 5] [9 3]
[1, 3, 5, 7, 8, 9] [4, 2] [6 0]
[0, 2, 6, 7, 8, 9] [3, 5] [4 1]
[0, 2, 3, 4, 7, 8] [1, 9] [6 5]
[2, 3, 5, 7, 8, 9] [6, 1] [4 0]
[1, 3, 4, 6, 7, 8] [5, 9] [0 2]
load TPCH succ
train, test, validation (122, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.488580, and there are 5978 training samples
in channel 9
Epoch 0/300 |loss: 0.051436| train set 2.411x speedup, test set 2.297x speedup, val set 2.448x speedup, step: 1
Epoch 1/300 |loss: 0.017954| train set 2.961x speedup, test set 2.781x speedup, val set 2.991x speedup, step: 1
Epoch 2/300 |loss: 0.009499| train set 3.086x speedup, test set 2.943x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006226| train set 3.701x speedup, test set 3.516x speedup, val set 3.830x speedup, step: 1
Epoch 4/300 |loss: 0.005077| train set 3.155x speedup, test set 3.017x speedup, val set 3.231x speedup, step: 2
Epoch 5/300 |loss: 0.004852| train set 3.297x speedup, test set 3.120x speedup, val set 3.343x speedup, step: 3
Epoch 6/300 |loss: 0.003931| train set 3.460x speedup, test set 3.309x speedup, val set 3.433x speedup, step: 4
Epoch 7/300 |loss: 0.003467| train set 3.953x speedup, test set 3.672x speedup, val set 4.315x speedup, step: 1
Epoch 8/300 |loss: 0.002999| train set 3.824x speedup, test set 3.683x speedup, val set 3.906x speedup, step: 2
Epoch 9/300 |loss: 0.002688| train set 4.316x speedup, test set 4.480x speedup, val set 4.494x speedup, step: 1
Epoch 10/300 |loss: 0.002235| train set 3.594x speedup, test set 3.470x speedup, val set 3.620x speedup, step: 2
Epoch 11/300 |loss: 0.002645| train set 4.885x speedup, test set 4.788x speedup, val set 4.932x speedup, step: 1
Epoch 12/300 |loss: 0.002480| train set 3.981x speedup, test set 3.937x speedup, val set 3.991x speedup, step: 2
Epoch 13/300 |loss: 0.002319| train set 5.297x speedup, test set 5.170x speedup, val set 5.469x speedup, step: 1
Epoch 14/300 |loss: 0.001751| train set 4.165x speedup, test set 3.946x speedup, val set 4.295x speedup, step: 2
Epoch 15/300 |loss: 0.001704| train set 4.579x speedup, test set 4.861x speedup, val set 4.984x speedup, step: 3
Epoch 16/300 |loss: 0.001837| train set 3.839x speedup, test set 3.614x speedup, val set 3.948x speedup, step: 4
Epoch 17/300 |loss: 0.002132| train set 4.404x speedup, test set 3.752x speedup, val set 5.083x speedup, step: 5
Epoch 18/300 |loss: 0.001906| train set 5.316x speedup, test set 5.171x speedup, val set 5.592x speedup, step: 1
Epoch 19/300 |loss: 0.001925| train set 5.277x speedup, test set 5.163x speedup, val set 5.431x speedup, step: 2
Epoch 20/300 |loss: 0.001257| train set 5.239x speedup, test set 5.109x speedup, val set 5.508x speedup, step: 3
Epoch 21/300 |loss: 0.000908| train set 5.389x speedup, test set 5.255x speedup, val set 5.550x speedup, step: 4
Epoch 22/300 |loss: 0.000934| train set 5.387x speedup, test set 5.259x speedup, val set 5.553x speedup, step: 5
Epoch 23/300 |loss: 0.000837| train set 5.383x speedup, test set 5.251x speedup, val set 5.543x speedup, step: 6
Epoch 24/300 |loss: 0.000896| train set 5.384x speedup, test set 5.255x speedup, val set 5.537x speedup, step: 7
Epoch 25/300 |loss: 0.000939| train set 5.148x speedup, test set 5.258x speedup, val set 5.544x speedup, step: 8
Epoch 26/300 |loss: 0.000839| train set 5.313x speedup, test set 5.169x speedup, val set 5.588x speedup, step: 9
Epoch 27/300 |loss: 0.000717| train set 5.389x speedup, test set 5.256x speedup, val set 5.540x speedup, step: 10
Epoch 28/300 |loss: 0.000725| train set 5.364x speedup, test set 5.254x speedup, val set 5.516x speedup, step: 11
Epoch 29/300 |loss: 0.000791| train set 5.389x speedup, test set 5.256x speedup, val set 5.551x speedup, step: 12
Epoch 30/300 |loss: 0.000800| train set 5.387x speedup, test set 5.260x speedup, val set 5.555x speedup, step: 13
Epoch 31/300 |loss: 0.000839| train set 5.386x speedup, test set 5.259x speedup, val set 5.550x speedup, step: 14
Epoch 32/300 |loss: 0.000744| train set 5.384x speedup, test set 5.257x speedup, val set 5.544x speedup, step: 15
Epoch 33/300 |loss: 0.000738| train set 5.389x speedup, test set 5.256x speedup, val set 5.551x speedup, step: 16
Epoch 34/300 |loss: 0.000788| train set 5.309x speedup, test set 5.168x speedup, val set 5.565x speedup, step: 17
Epoch 35/300 |loss: 0.000785| train set 5.389x speedup, test set 5.256x speedup, val set 5.547x speedup, step: 18
Epoch 36/300 |loss: 0.000765| train set 5.389x speedup, test set 5.258x speedup, val set 5.548x speedup, step: 19
early stopping at epoch 36
Training per epoch cost 0.438 s
Optimal speedup on test set is 5.356x
01, opt runtime 29.200s, model runtime 29.200s, pg runtime 29.200s, speedup 1.000x
02, opt runtime 26.072s, model runtime 26.072s, pg runtime 26.072s, speedup 1.000x
03, opt runtime 29.269s, model runtime 29.269s, pg runtime 91.296s, speedup 3.119x
04, opt runtime 29.286s, model runtime 29.286s, pg runtime 92.131s, speedup 3.146x
05, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
06, opt runtime 17.779s, model runtime 17.779s, pg runtime 17.779s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.913s, model runtime 9.037s, pg runtime 15.548s, speedup 1.720x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 21.913s, model runtime 21.913s, pg runtime 74.973s, speedup 3.421x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.590s, model runtime 3.590s, pg runtime 12.193s, speedup 3.396x
15, opt runtime 47.812s, model runtime 47.812s, pg runtime 83.069s, speedup 1.737x
16, opt runtime 49.511s, model runtime 49.511s, pg runtime 87.329s, speedup 1.764x
17, opt runtime 7.565s, model runtime 7.565s, pg runtime 20.255s, speedup 2.678x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.148s, model runtime 1.214s, pg runtime 1.214s, speedup 1.000x
20, opt runtime 1.347s, model runtime 1.438s, pg runtime 1.438s, speedup 1.000x
21, opt runtime 18.267s, model runtime 21.055s, pg runtime 21.055s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 5.961s, model runtime 5.961s, pg runtime 31.210s, speedup 5.236x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.360s, model runtime 1.360s, pg runtime 1.360s, speedup 1.000x
26, opt runtime 1.265s, model runtime 1.265s, pg runtime 1.265s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.799s, pg runtime 7.799s, speedup 1.000x
28, opt runtime 7.063s, model runtime 7.063s, pg runtime 7.063s, speedup 1.000x
29, opt runtime 5.415s, model runtime 5.415s, pg runtime 5.415s, speedup 1.000x
30, opt runtime 5.175s, model runtime 5.175s, pg runtime 5.175s, speedup 1.000x
31, opt runtime 25.236s, model runtime 25.236s, pg runtime 601.756s, speedup 23.845x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 35.538s, model runtime 42.151s, pg runtime 70.116s, speedup 1.663x
34, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
35, opt runtime 15.120s, model runtime 16.499s, pg runtime 566.078s, speedup 34.310x
36, opt runtime 16.305s, model runtime 16.305s, pg runtime 436.168s, speedup 26.751x
37, opt runtime 11.734s, model runtime 11.734s, pg runtime 11.734s, speedup 1.000x
38, opt runtime 15.302s, model runtime 15.302s, pg runtime 15.302s, speedup 1.000x
39, opt runtime 1.015s, model runtime 1.015s, pg runtime 1.092s, speedup 1.076x
40, opt runtime 1.084s, model runtime 1.084s, pg runtime 1.155s, speedup 1.065x
====================
best train speedup epoch: 35, train speedup 5.389, test speedup 5.256, val speedup 5.547
best test speedup epoch: 30, train speedup 5.387, test speedup 5.260, val speedup 5.555
best validation speedup epoch: 18, train speedup 5.316, test speedup 5.171, val speedup 5.592
last model at epoch 36, train speedup 5.389, test speedup 5.258, val speedup 5.548
execution cost 0:00:37.117711
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

load TPCH...
[2, 3, 4, 6, 7, 9] [1, 0] [8 5]
[0, 1, 2, 5, 7, 9] [4, 3] [6 8]
[0, 1, 5, 6, 7, 8] [3, 2] [4 9]
[0, 2, 3, 4, 6, 7, 9] [1, 8] [5 5]
[0, 3, 4, 5, 7, 9] [1, 6] [8 2]
[1, 2, 4, 5, 6, 8] [0, 9] [3 7]
[0, 2, 5, 6, 7, 8, 9] [1, 3] [4 4]
[0, 1, 2, 4, 6, 7] [3, 8] [9 5]
[1, 2, 3, 5, 6, 7] [9, 0] [4 8]
[0, 1, 4, 5, 6, 7] [8, 3] [9 2]
[0, 1, 2, 3, 7, 9] [8, 6] [5 4]
[0, 2, 4, 5, 6, 8] [3, 7] [1 9]
[0, 1, 2, 5, 7, 8] [9, 4] [3 6]
[1, 4, 5, 6, 8, 9] [0, 2] [7 3]
[0, 1, 2, 4, 7, 8] [6, 5] [9 3]
[1, 3, 5, 7, 8, 9] [4, 2] [6 0]
[0, 2, 6, 7, 8, 9] [3, 5] [4 1]
[0, 2, 3, 4, 7, 8] [1, 9] [6 5]
[2, 3, 5, 7, 8, 9] [6, 1] [4 0]
[1, 3, 4, 6, 7, 8] [5, 9] [0 2]
load TPCH succ
train, test, validation (122, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.524679, and there are 5978 training samples
in channel 9
Epoch 0/300 |loss: 0.051436| train set 2.411x speedup, test set 2.297x speedup, val set 2.448x speedup, step: 1
Epoch 1/300 |loss: 0.017954| train set 2.961x speedup, test set 2.781x speedup, val set 2.991x speedup, step: 1
Epoch 2/300 |loss: 0.009499| train set 3.086x speedup, test set 2.943x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006226| train set 3.701x speedup, test set 3.516x speedup, val set 3.830x speedup, step: 1
Epoch 4/300 |loss: 0.005078| train set 3.155x speedup, test set 3.017x speedup, val set 3.231x speedup, step: 2
Epoch 5/300 |loss: 0.004847| train set 3.457x speedup, test set 3.321x speedup, val set 3.592x speedup, step: 3
Epoch 6/300 |loss: 0.003946| train set 3.446x speedup, test set 3.309x speedup, val set 3.433x speedup, step: 4
Epoch 7/300 |loss: 0.003470| train set 3.757x speedup, test set 3.509x speedup, val set 4.011x speedup, step: 1
Epoch 8/300 |loss: 0.003036| train set 3.819x speedup, test set 3.685x speedup, val set 3.904x speedup, step: 2
Epoch 9/300 |loss: 0.002647| train set 4.521x speedup, test set 4.863x speedup, val set 4.987x speedup, step: 1
Epoch 10/300 |loss: 0.002222| train set 3.637x speedup, test set 3.509x speedup, val set 3.651x speedup, step: 2
Epoch 11/300 |loss: 0.002407| train set 4.881x speedup, test set 4.789x speedup, val set 4.930x speedup, step: 3
Epoch 12/300 |loss: 0.002491| train set 3.730x speedup, test set 3.497x speedup, val set 3.728x speedup, step: 4
Epoch 13/300 |loss: 0.002310| train set 5.342x speedup, test set 5.226x speedup, val set 5.536x speedup, step: 1
Epoch 14/300 |loss: 0.001889| train set 4.169x speedup, test set 3.949x speedup, val set 4.298x speedup, step: 2
Epoch 15/300 |loss: 0.001787| train set 4.582x speedup, test set 4.864x speedup, val set 4.985x speedup, step: 3
Epoch 16/300 |loss: 0.001881| train set 4.012x speedup, test set 3.616x speedup, val set 4.553x speedup, step: 4
Epoch 17/300 |loss: 0.002170| train set 4.847x speedup, test set 4.719x speedup, val set 4.932x speedup, step: 5
Epoch 18/300 |loss: 0.001831| train set 5.387x speedup, test set 5.262x speedup, val set 5.552x speedup, step: 1
Epoch 19/300 |loss: 0.001936| train set 5.120x speedup, test set 4.997x speedup, val set 5.231x speedup, step: 2
Epoch 20/300 |loss: 0.001192| train set 4.968x speedup, test set 4.869x speedup, val set 4.988x speedup, step: 3
Epoch 21/300 |loss: 0.000987| train set 5.312x speedup, test set 5.173x speedup, val set 5.585x speedup, step: 1
Epoch 22/300 |loss: 0.000861| train set 5.386x speedup, test set 5.258x speedup, val set 5.543x speedup, step: 2
Epoch 23/300 |loss: 0.000838| train set 5.236x speedup, test set 5.101x speedup, val set 5.500x speedup, step: 3
Epoch 24/300 |loss: 0.000890| train set 5.323x speedup, test set 5.163x speedup, val set 5.451x speedup, step: 4
Epoch 25/300 |loss: 0.000913| train set 5.389x speedup, test set 5.256x speedup, val set 5.551x speedup, step: 5
Epoch 26/300 |loss: 0.000813| train set 5.378x speedup, test set 5.251x speedup, val set 5.543x speedup, step: 6
Epoch 27/300 |loss: 0.000700| train set 5.389x speedup, test set 5.255x speedup, val set 5.550x speedup, step: 7
Epoch 28/300 |loss: 0.000774| train set 5.284x speedup, test set 5.163x speedup, val set 5.551x speedup, step: 8
Epoch 29/300 |loss: 0.000796| train set 5.389x speedup, test set 5.256x speedup, val set 5.551x speedup, step: 9
Epoch 30/300 |loss: 0.000775| train set 5.383x speedup, test set 5.260x speedup, val set 5.540x speedup, step: 10
Epoch 31/300 |loss: 0.000797| train set 5.364x speedup, test set 5.254x speedup, val set 5.512x speedup, step: 11
Epoch 32/300 |loss: 0.000725| train set 5.387x speedup, test set 5.260x speedup, val set 5.550x speedup, step: 12
Epoch 33/300 |loss: 0.000755| train set 5.389x speedup, test set 5.256x speedup, val set 5.551x speedup, step: 13
Epoch 34/300 |loss: 0.000766| train set 5.289x speedup, test set 5.173x speedup, val set 5.560x speedup, step: 14
Epoch 35/300 |loss: 0.000748| train set 5.389x speedup, test set 5.256x speedup, val set 5.547x speedup, step: 15
Epoch 36/300 |loss: 0.000831| train set 5.262x speedup, test set 5.168x speedup, val set 5.400x speedup, step: 16
early stopping at epoch 36
Training per epoch cost 0.460 s
Optimal speedup on test set is 5.356x
01, opt runtime 29.200s, model runtime 29.200s, pg runtime 29.200s, speedup 1.000x
02, opt runtime 26.072s, model runtime 26.072s, pg runtime 26.072s, speedup 1.000x
03, opt runtime 29.269s, model runtime 29.269s, pg runtime 91.296s, speedup 3.119x
04, opt runtime 29.286s, model runtime 29.286s, pg runtime 92.131s, speedup 3.146x
05, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
06, opt runtime 17.779s, model runtime 17.779s, pg runtime 17.779s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.913s, model runtime 9.037s, pg runtime 15.548s, speedup 1.720x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 21.913s, model runtime 21.913s, pg runtime 74.973s, speedup 3.421x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 3.332s, pg runtime 21.298s, speedup 6.391x
14, opt runtime 3.590s, model runtime 4.223s, pg runtime 12.193s, speedup 2.887x
15, opt runtime 47.812s, model runtime 47.812s, pg runtime 83.069s, speedup 1.737x
16, opt runtime 49.511s, model runtime 49.511s, pg runtime 87.329s, speedup 1.764x
17, opt runtime 7.565s, model runtime 7.565s, pg runtime 20.255s, speedup 2.678x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.148s, model runtime 1.148s, pg runtime 1.214s, speedup 1.057x
20, opt runtime 1.347s, model runtime 1.347s, pg runtime 1.438s, speedup 1.067x
21, opt runtime 18.267s, model runtime 21.055s, pg runtime 21.055s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 5.961s, model runtime 5.961s, pg runtime 31.210s, speedup 5.236x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.360s, model runtime 1.360s, pg runtime 1.360s, speedup 1.000x
26, opt runtime 1.265s, model runtime 1.265s, pg runtime 1.265s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.799s, pg runtime 7.799s, speedup 1.000x
28, opt runtime 7.063s, model runtime 7.063s, pg runtime 7.063s, speedup 1.000x
29, opt runtime 5.415s, model runtime 5.415s, pg runtime 5.415s, speedup 1.000x
30, opt runtime 5.175s, model runtime 5.175s, pg runtime 5.175s, speedup 1.000x
31, opt runtime 25.236s, model runtime 25.236s, pg runtime 601.756s, speedup 23.845x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 35.538s, model runtime 42.151s, pg runtime 70.116s, speedup 1.663x
34, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
35, opt runtime 15.120s, model runtime 16.499s, pg runtime 566.078s, speedup 34.310x
36, opt runtime 16.305s, model runtime 16.305s, pg runtime 436.168s, speedup 26.751x
37, opt runtime 11.734s, model runtime 11.734s, pg runtime 11.734s, speedup 1.000x
38, opt runtime 15.302s, model runtime 15.302s, pg runtime 15.302s, speedup 1.000x
39, opt runtime 1.015s, model runtime 1.092s, pg runtime 1.092s, speedup 1.000x
40, opt runtime 1.084s, model runtime 1.155s, pg runtime 1.155s, speedup 1.000x
====================
best train speedup epoch: 35, train speedup 5.389, test speedup 5.256, val speedup 5.547
best test speedup epoch: 18, train speedup 5.387, test speedup 5.262, val speedup 5.552
best validation speedup epoch: 21, train speedup 5.312, test speedup 5.173, val speedup 5.585
last model at epoch 36, train speedup 5.262, test speedup 5.168, val speedup 5.400
execution cost 0:00:38.288193
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1c.sql' '10b.sql' '11b.sql' '12a.sql' '13d.sql' '14c.sql' '15d.sql'
 '16a.sql' '17a.sql' '18a.sql' '19a.sql' '2b.sql' '20b.sql' '21a.sql'
 '22b.sql' '23c.sql' '24a.sql' '25a.sql' '26c.sql' '27a.sql' '28a.sql'
 '29a.sql' '3c.sql' '30b.sql' '31b.sql' '32a.sql' '33a.sql' '4c.sql'
 '5b.sql' '6c.sql' '7a.sql' '8a.sql' '9a.sql']
load JOB succ
load TPCH...
[0, 1, 3, 6, 7, 9] [4, 2] [5, 8]
[0, 3, 6, 7, 8, 9] [5, 1] [2, 4]
[0, 2, 3, 4, 8, 9] [1, 5] [7, 6]
[1, 2, 3, 5, 7, 8] [4, 0] [9, 6]
[0, 3, 4, 7, 8, 9] [1, 6] [2, 5]
[0, 1, 2, 6, 8, 9] [4, 5] [3, 7]
[2, 3, 4, 6, 7, 9] [1, 0] [5, 8]
[0, 2, 3, 6, 7, 9] [4, 1] [5, 8]
[0, 2, 3, 7, 8, 9] [1, 6] [5, 4]
[0, 1, 4, 6, 8, 9] [5, 2] [7, 3]
[0, 2, 5, 7, 8, 9] [3, 4] [1, 6]
[0, 3, 5, 6, 7, 9] [2, 8] [4, 1]
[0, 1, 2, 3, 8, 9] [7, 6] [4, 5]
[0, 1, 2, 4, 5, 9] [8, 3] [6, 7]
[2, 4, 5, 6, 7, 9] [0, 3] [1, 8]
[1, 2, 3, 7, 8, 9] [5, 6] [4, 0]
[0, 1, 2, 6, 8, 9] [3, 5] [4, 7]
[0, 2, 3, 4, 5, 8] [7, 6] [9, 1]
[0, 1, 3, 6, 8, 9] [4, 2] [5, 7]
[0, 1, 2, 3, 6, 7] [8, 9] [4, 5]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.872705, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.049662| train set 2.636x speedup, test set 2.555x speedup, val set 2.435x speedup, step: 1
Epoch 1/300 |loss: 0.020790| train set 2.944x speedup, test set 2.779x speedup, val set 2.627x speedup, step: 1
Epoch 2/300 |loss: 0.010599| train set 3.374x speedup, test set 3.149x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006414| train set 3.841x speedup, test set 3.659x speedup, val set 3.568x speedup, step: 1
Epoch 4/300 |loss: 0.004772| train set 3.593x speedup, test set 3.481x speedup, val set 3.343x speedup, step: 2
Epoch 5/300 |loss: 0.003747| train set 3.600x speedup, test set 3.492x speedup, val set 3.348x speedup, step: 3
Epoch 6/300 |loss: 0.004243| train set 4.736x speedup, test set 4.487x speedup, val set 4.462x speedup, step: 1
Epoch 7/300 |loss: 0.003400| train set 4.965x speedup, test set 4.703x speedup, val set 4.838x speedup, step: 1
Epoch 8/300 |loss: 0.002585| train set 4.019x speedup, test set 3.846x speedup, val set 3.715x speedup, step: 2
Epoch 9/300 |loss: 0.002183| train set 5.297x speedup, test set 5.024x speedup, val set 5.018x speedup, step: 1
Epoch 10/300 |loss: 0.002067| train set 4.928x speedup, test set 5.282x speedup, val set 5.005x speedup, step: 2
Epoch 11/300 |loss: 0.002087| train set 5.111x speedup, test set 5.218x speedup, val set 4.991x speedup, step: 3
Epoch 12/300 |loss: 0.002316| train set 4.977x speedup, test set 5.395x speedup, val set 4.960x speedup, step: 4
Epoch 13/300 |loss: 0.001974| train set 5.176x speedup, test set 5.340x speedup, val set 5.030x speedup, step: 1
Epoch 14/300 |loss: 0.002075| train set 4.309x speedup, test set 4.031x speedup, val set 3.933x speedup, step: 2
Epoch 15/300 |loss: 0.002050| train set 4.315x speedup, test set 4.070x speedup, val set 3.741x speedup, step: 3
Epoch 16/300 |loss: 0.001424| train set 5.224x speedup, test set 5.422x speedup, val set 5.064x speedup, step: 1
Epoch 17/300 |loss: 0.001423| train set 4.261x speedup, test set 4.141x speedup, val set 3.881x speedup, step: 2
Epoch 18/300 |loss: 0.001719| train set 5.205x speedup, test set 5.222x speedup, val set 5.049x speedup, step: 3
Epoch 19/300 |loss: 0.001293| train set 5.467x speedup, test set 5.422x speedup, val set 5.067x speedup, step: 1
Epoch 20/300 |loss: 0.001071| train set 5.448x speedup, test set 5.332x speedup, val set 5.067x speedup, step: 2
Epoch 21/300 |loss: 0.000897| train set 5.245x speedup, test set 5.412x speedup, val set 5.094x speedup, step: 1
Epoch 22/300 |loss: 0.001254| train set 4.858x speedup, test set 5.215x speedup, val set 4.835x speedup, step: 2
Epoch 23/300 |loss: 0.001166| train set 5.478x speedup, test set 5.488x speedup, val set 5.098x speedup, step: 1
Epoch 24/300 |loss: 0.000781| train set 4.976x speedup, test set 5.294x speedup, val set 5.065x speedup, step: 2
Epoch 25/300 |loss: 0.000873| train set 5.492x speedup, test set 5.422x speedup, val set 5.104x speedup, step: 1
Epoch 26/300 |loss: 0.000810| train set 5.495x speedup, test set 5.409x speedup, val set 5.099x speedup, step: 2
Epoch 27/300 |loss: 0.000829| train set 5.447x speedup, test set 5.329x speedup, val set 5.066x speedup, step: 3
Epoch 28/300 |loss: 0.000795| train set 5.448x speedup, test set 5.220x speedup, val set 5.054x speedup, step: 4
Epoch 29/300 |loss: 0.001011| train set 5.466x speedup, test set 5.368x speedup, val set 5.097x speedup, step: 5
Epoch 30/300 |loss: 0.000721| train set 5.448x speedup, test set 5.332x speedup, val set 5.067x speedup, step: 6
Epoch 31/300 |loss: 0.000727| train set 5.495x speedup, test set 5.418x speedup, val set 5.104x speedup, step: 1
Epoch 32/300 |loss: 0.000735| train set 5.492x speedup, test set 5.422x speedup, val set 5.099x speedup, step: 2
Epoch 33/300 |loss: 0.000722| train set 5.497x speedup, test set 5.421x speedup, val set 5.106x speedup, step: 1
Epoch 34/300 |loss: 0.000727| train set 5.496x speedup, test set 5.421x speedup, val set 5.107x speedup, step: 1
Epoch 35/300 |loss: 0.000688| train set 5.447x speedup, test set 5.211x speedup, val set 5.049x speedup, step: 2
Epoch 36/300 |loss: 0.000674| train set 5.447x speedup, test set 5.331x speedup, val set 5.068x speedup, step: 3
Epoch 37/300 |loss: 0.000711| train set 5.441x speedup, test set 5.324x speedup, val set 5.061x speedup, step: 4
Epoch 38/300 |loss: 0.000626| train set 5.488x speedup, test set 5.402x speedup, val set 5.092x speedup, step: 5
Epoch 39/300 |loss: 0.000753| train set 5.490x speedup, test set 5.414x speedup, val set 5.098x speedup, step: 6
Epoch 40/300 |loss: 0.000809| train set 5.448x speedup, test set 5.332x speedup, val set 5.068x speedup, step: 7
early stopping at epoch 40
Training per epoch cost 0.423 s
Optimal speedup on test set is 5.508x
01, opt runtime 18.665s, model runtime 18.665s, pg runtime 18.665s, speedup 1.000x
02, opt runtime 25.356s, model runtime 25.356s, pg runtime 25.356s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 29.763s, model runtime 29.763s, pg runtime 91.648s, speedup 3.079x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 19.263s, model runtime 19.263s, pg runtime 19.263s, speedup 1.000x
07, opt runtime 7.110s, model runtime 7.110s, pg runtime 14.286s, speedup 2.009x
08, opt runtime 7.237s, model runtime 7.237s, pg runtime 17.708s, speedup 2.447x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 25.043s, model runtime 25.043s, pg runtime 73.019s, speedup 2.916x
12, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 2.995s, model runtime 2.995s, pg runtime 14.646s, speedup 4.890x
15, opt runtime 47.518s, model runtime 47.518s, pg runtime 75.736s, speedup 1.594x
16, opt runtime 48.784s, model runtime 48.784s, pg runtime 78.349s, speedup 1.606x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 7.469s, model runtime 7.469s, pg runtime 23.223s, speedup 3.109x
19, opt runtime 1.309s, model runtime 1.382s, pg runtime 1.356s, speedup 0.981x
20, opt runtime 1.340s, model runtime 1.478s, pg runtime 1.340s, speedup 0.907x
21, opt runtime 6.281s, model runtime 6.281s, pg runtime 6.281s, speedup 1.000x
22, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
23, opt runtime 5.961s, model runtime 5.961s, pg runtime 31.210s, speedup 5.236x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.306s, model runtime 1.306s, pg runtime 1.306s, speedup 1.000x
26, opt runtime 1.342s, model runtime 1.342s, pg runtime 1.342s, speedup 1.000x
27, opt runtime 7.066s, model runtime 7.355s, pg runtime 7.533s, speedup 1.024x
28, opt runtime 7.268s, model runtime 7.333s, pg runtime 7.268s, speedup 0.991x
29, opt runtime 5.414s, model runtime 5.414s, pg runtime 5.414s, speedup 1.000x
30, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
31, opt runtime 25.363s, model runtime 25.363s, pg runtime 611.327s, speedup 24.103x
32, opt runtime 24.706s, model runtime 24.706s, pg runtime 610.808s, speedup 24.723x
33, opt runtime 35.538s, model runtime 35.538s, pg runtime 70.116s, speedup 1.973x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 16.138s, model runtime 16.138s, pg runtime 501.793s, speedup 31.094x
36, opt runtime 16.438s, model runtime 16.438s, pg runtime 546.887s, speedup 33.269x
37, opt runtime 15.754s, model runtime 15.754s, pg runtime 15.754s, speedup 1.000x
38, opt runtime 13.961s, model runtime 13.961s, pg runtime 13.961s, speedup 1.000x
39, opt runtime 1.098s, model runtime 1.098s, pg runtime 1.100s, speedup 1.001x
40, opt runtime 1.084s, model runtime 1.084s, pg runtime 1.155s, speedup 1.065x
====================
best train speedup epoch: 33, train speedup 5.497, test speedup 5.421, val speedup 5.106
best test speedup epoch: 23, train speedup 5.478, test speedup 5.488, val speedup 5.098
best validation speedup epoch: 34, train speedup 5.496, test speedup 5.421, val speedup 5.107
last model at epoch 40, train speedup 5.448, test speedup 5.332, val speedup 5.068
execution cost 0:00:40.854879
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1c.sql' '10b.sql' '11b.sql' '12a.sql' '13d.sql' '14c.sql' '15d.sql'
 '16a.sql' '17a.sql' '18a.sql' '19a.sql' '2b.sql' '20b.sql' '21a.sql'
 '22b.sql' '23c.sql' '24a.sql' '25a.sql' '26c.sql' '27a.sql' '28a.sql'
 '29a.sql' '3c.sql' '30b.sql' '31b.sql' '32a.sql' '33a.sql' '4c.sql'
 '5b.sql' '6c.sql' '7a.sql' '8a.sql' '9a.sql']
load JOB succ
load TPCH...
[0, 1, 3, 6, 7, 9] [4, 2] [5, 8]
[0, 3, 6, 7, 8, 9] [5, 1] [2, 4]
[0, 2, 3, 4, 8, 9] [1, 5] [7, 6]
[1, 2, 3, 5, 7, 8] [4, 0] [9, 6]
[0, 3, 4, 7, 8, 9] [1, 6] [2, 5]
[0, 1, 2, 6, 8, 9] [4, 5] [3, 7]
[2, 3, 4, 6, 7, 9] [1, 0] [5, 8]
[0, 2, 3, 6, 7, 9] [4, 1] [5, 8]
[0, 2, 3, 7, 8, 9] [1, 6] [5, 4]
[0, 1, 4, 6, 8, 9] [5, 2] [7, 3]
[0, 2, 5, 7, 8, 9] [3, 4] [1, 6]
[0, 3, 5, 6, 7, 9] [2, 8] [4, 1]
[0, 1, 2, 3, 8, 9] [7, 6] [4, 5]
[0, 1, 2, 4, 5, 9] [8, 3] [6, 7]
[2, 4, 5, 6, 7, 9] [0, 3] [1, 8]
[1, 2, 3, 7, 8, 9] [5, 6] [4, 0]
[0, 1, 2, 6, 8, 9] [3, 5] [4, 7]
[0, 2, 3, 4, 5, 8] [7, 6] [9, 1]
[0, 1, 3, 6, 8, 9] [4, 2] [5, 7]
[0, 1, 2, 3, 6, 7] [8, 9] [4, 5]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.787986, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.049662| train set 2.636x speedup, test set 2.555x speedup, val set 2.435x speedup, step: 1
Epoch 1/300 |loss: 0.020790| train set 2.944x speedup, test set 2.779x speedup, val set 2.627x speedup, step: 1
Epoch 2/300 |loss: 0.010599| train set 3.374x speedup, test set 3.149x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006414| train set 3.841x speedup, test set 3.659x speedup, val set 3.568x speedup, step: 1
Epoch 4/300 |loss: 0.004772| train set 3.593x speedup, test set 3.481x speedup, val set 3.343x speedup, step: 2
Epoch 5/300 |loss: 0.003753| train set 3.429x speedup, test set 3.230x speedup, val set 3.130x speedup, step: 3
Epoch 6/300 |loss: 0.004329| train set 5.306x speedup, test set 5.058x speedup, val set 4.982x speedup, step: 1
Epoch 7/300 |loss: 0.003316| train set 4.966x speedup, test set 4.704x speedup, val set 4.838x speedup, step: 2
Epoch 8/300 |loss: 0.002521| train set 4.015x speedup, test set 3.841x speedup, val set 3.715x speedup, step: 3
Epoch 9/300 |loss: 0.002215| train set 5.270x speedup, test set 4.988x speedup, val set 5.025x speedup, step: 1
Epoch 10/300 |loss: 0.002056| train set 4.216x speedup, test set 4.116x speedup, val set 3.848x speedup, step: 2
Epoch 11/300 |loss: 0.002076| train set 5.352x speedup, test set 5.207x speedup, val set 5.122x speedup, step: 1
Epoch 12/300 |loss: 0.002284| train set 4.978x speedup, test set 5.396x speedup, val set 4.949x speedup, step: 2
Epoch 13/300 |loss: 0.002037| train set 4.968x speedup, test set 5.340x speedup, val set 5.032x speedup, step: 3
Epoch 14/300 |loss: 0.002050| train set 5.023x speedup, test set 4.815x speedup, val set 4.754x speedup, step: 4
Epoch 15/300 |loss: 0.002083| train set 4.910x speedup, test set 5.240x speedup, val set 4.969x speedup, step: 5
Epoch 16/300 |loss: 0.001408| train set 5.246x speedup, test set 5.420x speedup, val set 5.096x speedup, step: 6
Epoch 17/300 |loss: 0.001536| train set 3.989x speedup, test set 3.797x speedup, val set 3.698x speedup, step: 7
Epoch 18/300 |loss: 0.001584| train set 5.347x speedup, test set 5.304x speedup, val set 4.902x speedup, step: 8
Epoch 19/300 |loss: 0.001416| train set 5.496x speedup, test set 5.421x speedup, val set 5.107x speedup, step: 9
Epoch 20/300 |loss: 0.001096| train set 5.446x speedup, test set 5.329x speedup, val set 5.064x speedup, step: 10
Epoch 21/300 |loss: 0.000909| train set 5.032x speedup, test set 5.414x speedup, val set 5.098x speedup, step: 11
Epoch 22/300 |loss: 0.001043| train set 4.856x speedup, test set 5.204x speedup, val set 4.830x speedup, step: 12
Epoch 23/300 |loss: 0.001105| train set 5.492x speedup, test set 5.422x speedup, val set 5.101x speedup, step: 13
Epoch 24/300 |loss: 0.000776| train set 4.892x speedup, test set 5.191x speedup, val set 4.966x speedup, step: 14
Epoch 25/300 |loss: 0.000863| train set 5.490x speedup, test set 5.411x speedup, val set 5.093x speedup, step: 15
Epoch 26/300 |loss: 0.000773| train set 5.445x speedup, test set 5.317x speedup, val set 5.059x speedup, step: 16
Epoch 27/300 |loss: 0.000920| train set 5.495x speedup, test set 5.418x speedup, val set 5.104x speedup, step: 17
Epoch 28/300 |loss: 0.000789| train set 5.448x speedup, test set 5.219x speedup, val set 5.053x speedup, step: 18
Epoch 29/300 |loss: 0.001002| train set 5.492x speedup, test set 5.414x speedup, val set 5.100x speedup, step: 19
Epoch 30/300 |loss: 0.000803| train set 5.448x speedup, test set 5.332x speedup, val set 5.067x speedup, step: 20
Epoch 31/300 |loss: 0.000710| train set 5.495x speedup, test set 5.418x speedup, val set 5.104x speedup, step: 21
Epoch 32/300 |loss: 0.000790| train set 5.490x speedup, test set 5.413x speedup, val set 5.097x speedup, step: 22
Epoch 33/300 |loss: 0.000715| train set 5.497x speedup, test set 5.421x speedup, val set 5.106x speedup, step: 23
Epoch 34/300 |loss: 0.000698| train set 5.443x speedup, test set 5.327x speedup, val set 5.076x speedup, step: 24
Epoch 35/300 |loss: 0.000668| train set 5.494x speedup, test set 5.409x speedup, val set 5.100x speedup, step: 25
Epoch 36/300 |loss: 0.000724| train set 5.441x speedup, test set 5.321x speedup, val set 5.055x speedup, step: 26
Epoch 37/300 |loss: 0.000704| train set 5.436x speedup, test set 5.319x speedup, val set 5.053x speedup, step: 27
Epoch 38/300 |loss: 0.000652| train set 5.490x speedup, test set 5.404x speedup, val set 5.097x speedup, step: 28
Epoch 39/300 |loss: 0.000775| train set 5.492x speedup, test set 5.422x speedup, val set 5.099x speedup, step: 29
Epoch 40/300 |loss: 0.000878| train set 5.448x speedup, test set 5.332x speedup, val set 5.067x speedup, step: 30
early stopping at epoch 40
Training per epoch cost 0.417 s
Optimal speedup on test set is 5.508x
01, opt runtime 18.665s, model runtime 18.665s, pg runtime 18.665s, speedup 1.000x
02, opt runtime 25.356s, model runtime 25.356s, pg runtime 25.356s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 29.763s, model runtime 29.763s, pg runtime 91.648s, speedup 3.079x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 19.263s, model runtime 19.263s, pg runtime 19.263s, speedup 1.000x
07, opt runtime 7.110s, model runtime 7.110s, pg runtime 14.286s, speedup 2.009x
08, opt runtime 7.237s, model runtime 7.237s, pg runtime 17.708s, speedup 2.447x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 25.043s, model runtime 25.043s, pg runtime 73.019s, speedup 2.916x
12, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 2.995s, model runtime 2.995s, pg runtime 14.646s, speedup 4.890x
15, opt runtime 47.518s, model runtime 47.518s, pg runtime 75.736s, speedup 1.594x
16, opt runtime 48.784s, model runtime 48.784s, pg runtime 78.349s, speedup 1.606x
17, opt runtime 10.788s, model runtime 16.078s, pg runtime 32.939s, speedup 2.049x
18, opt runtime 7.469s, model runtime 14.931s, pg runtime 23.223s, speedup 1.555x
19, opt runtime 1.309s, model runtime 1.356s, pg runtime 1.356s, speedup 1.000x
20, opt runtime 1.340s, model runtime 1.340s, pg runtime 1.340s, speedup 1.000x
21, opt runtime 6.281s, model runtime 6.281s, pg runtime 6.281s, speedup 1.000x
22, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
23, opt runtime 5.961s, model runtime 9.875s, pg runtime 31.210s, speedup 3.161x
24, opt runtime 6.234s, model runtime 10.545s, pg runtime 32.540s, speedup 3.086x
25, opt runtime 1.306s, model runtime 1.306s, pg runtime 1.306s, speedup 1.000x
26, opt runtime 1.342s, model runtime 1.342s, pg runtime 1.342s, speedup 1.000x
27, opt runtime 7.066s, model runtime 7.355s, pg runtime 7.533s, speedup 1.024x
28, opt runtime 7.268s, model runtime 7.333s, pg runtime 7.268s, speedup 0.991x
29, opt runtime 5.414s, model runtime 5.414s, pg runtime 5.414s, speedup 1.000x
30, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
31, opt runtime 25.363s, model runtime 25.363s, pg runtime 611.327s, speedup 24.103x
32, opt runtime 24.706s, model runtime 24.706s, pg runtime 610.808s, speedup 24.723x
33, opt runtime 35.538s, model runtime 35.538s, pg runtime 70.116s, speedup 1.973x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 16.138s, model runtime 17.327s, pg runtime 501.793s, speedup 28.960x
36, opt runtime 16.438s, model runtime 19.535s, pg runtime 546.887s, speedup 27.995x
37, opt runtime 15.754s, model runtime 15.754s, pg runtime 15.754s, speedup 1.000x
38, opt runtime 13.961s, model runtime 13.961s, pg runtime 13.961s, speedup 1.000x
39, opt runtime 1.098s, model runtime 1.098s, pg runtime 1.100s, speedup 1.001x
40, opt runtime 1.084s, model runtime 1.084s, pg runtime 1.155s, speedup 1.065x
====================
best train speedup epoch: 33, train speedup 5.497, test speedup 5.421, val speedup 5.106
best test speedup epoch: 39, train speedup 5.492, test speedup 5.422, val speedup 5.099
best validation speedup epoch: 11, train speedup 5.352, test speedup 5.207, val speedup 5.122
last model at epoch 40, train speedup 5.448, test speedup 5.332, val speedup 5.067
execution cost 0:00:40.793895
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1c.sql' '10b.sql' '11b.sql' '12a.sql' '13d.sql' '14c.sql' '15d.sql'
 '16a.sql' '17a.sql' '18a.sql' '19a.sql' '2b.sql' '20b.sql' '21a.sql'
 '22b.sql' '23c.sql' '24a.sql' '25a.sql' '26c.sql' '27a.sql' '28a.sql'
 '29a.sql' '3c.sql' '30b.sql' '31b.sql' '32a.sql' '33a.sql' '4c.sql'
 '5b.sql' '6c.sql' '7a.sql' '8a.sql' '9a.sql']
load JOB succ
load TPCH...
[0, 1, 3, 6, 7, 9] [4, 2] [5, 8]
[0, 3, 6, 7, 8, 9] [5, 1] [2, 4]
[0, 2, 3, 4, 8, 9] [1, 5] [7, 6]
[1, 2, 3, 5, 7, 8] [4, 0] [9, 6]
[0, 3, 4, 7, 8, 9] [1, 6] [2, 5]
[0, 1, 2, 6, 8, 9] [4, 5] [3, 7]
[2, 3, 4, 6, 7, 9] [1, 0] [5, 8]
[0, 2, 3, 6, 7, 9] [4, 1] [5, 8]
[0, 2, 3, 7, 8, 9] [1, 6] [5, 4]
[0, 1, 4, 6, 8, 9] [5, 2] [7, 3]
[0, 2, 5, 7, 8, 9] [3, 4] [1, 6]
[0, 3, 5, 6, 7, 9] [2, 8] [4, 1]
[0, 1, 2, 3, 8, 9] [7, 6] [4, 5]
[0, 1, 2, 4, 5, 9] [8, 3] [6, 7]
[2, 4, 5, 6, 7, 9] [0, 3] [1, 8]
[1, 2, 3, 7, 8, 9] [5, 6] [4, 0]
[0, 1, 2, 6, 8, 9] [3, 5] [4, 7]
[0, 2, 3, 4, 5, 8] [7, 6] [9, 1]
[0, 1, 3, 6, 8, 9] [4, 2] [5, 7]
[0, 1, 2, 3, 6, 7] [8, 9] [4, 5]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.761937, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.049662| train set 2.636x speedup, test set 2.555x speedup, val set 2.435x speedup, step: 1
Epoch 1/300 |loss: 0.020790| train set 2.944x speedup, test set 2.779x speedup, val set 2.627x speedup, step: 1
Epoch 2/300 |loss: 0.010599| train set 3.374x speedup, test set 3.149x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006414| train set 3.841x speedup, test set 3.659x speedup, val set 3.568x speedup, step: 1
Epoch 4/300 |loss: 0.004772| train set 3.593x speedup, test set 3.481x speedup, val set 3.343x speedup, step: 2
Epoch 5/300 |loss: 0.003750| train set 3.395x speedup, test set 3.230x speedup, val set 3.130x speedup, step: 3
Epoch 6/300 |loss: 0.004254| train set 4.779x speedup, test set 4.461x speedup, val set 4.631x speedup, step: 1
Epoch 7/300 |loss: 0.003391| train set 4.971x speedup, test set 4.709x speedup, val set 4.842x speedup, step: 1
Epoch 8/300 |loss: 0.002522| train set 3.768x speedup, test set 3.538x speedup, val set 3.455x speedup, step: 2
Epoch 9/300 |loss: 0.002180| train set 5.272x speedup, test set 4.989x speedup, val set 5.029x speedup, step: 1
Epoch 10/300 |loss: 0.002063| train set 4.216x speedup, test set 4.116x speedup, val set 3.848x speedup, step: 2
Epoch 11/300 |loss: 0.002037| train set 5.389x speedup, test set 5.310x speedup, val set 5.018x speedup, step: 3
Epoch 12/300 |loss: 0.002217| train set 5.165x speedup, test set 5.358x speedup, val set 4.959x speedup, step: 4
Epoch 13/300 |loss: 0.002207| train set 4.966x speedup, test set 5.340x speedup, val set 5.030x speedup, step: 1
Epoch 14/300 |loss: 0.001982| train set 3.835x speedup, test set 3.421x speedup, val set 3.345x speedup, step: 2
Epoch 15/300 |loss: 0.002215| train set 5.095x speedup, test set 5.292x speedup, val set 4.863x speedup, step: 3
Epoch 16/300 |loss: 0.001443| train set 4.970x speedup, test set 5.338x speedup, val set 5.030x speedup, step: 4
Epoch 17/300 |loss: 0.001508| train set 4.177x speedup, test set 3.967x speedup, val set 3.814x speedup, step: 5
Epoch 18/300 |loss: 0.001551| train set 5.376x speedup, test set 5.199x speedup, val set 4.907x speedup, step: 6
Epoch 19/300 |loss: 0.001301| train set 5.492x speedup, test set 5.422x speedup, val set 5.101x speedup, step: 1
Epoch 20/300 |loss: 0.001091| train set 5.496x speedup, test set 5.421x speedup, val set 5.107x speedup, step: 1
Epoch 21/300 |loss: 0.000943| train set 5.246x speedup, test set 5.413x speedup, val set 5.097x speedup, step: 2
Epoch 22/300 |loss: 0.001252| train set 4.656x speedup, test set 4.592x speedup, val set 4.167x speedup, step: 3
Epoch 23/300 |loss: 0.001189| train set 5.420x speedup, test set 5.390x speedup, val set 4.952x speedup, step: 4
Epoch 24/300 |loss: 0.000824| train set 4.889x speedup, test set 5.197x speedup, val set 4.968x speedup, step: 5
Epoch 25/300 |loss: 0.000856| train set 5.483x speedup, test set 5.405x speedup, val set 5.088x speedup, step: 6
Epoch 26/300 |loss: 0.000744| train set 5.447x speedup, test set 5.330x speedup, val set 5.067x speedup, step: 7
Epoch 27/300 |loss: 0.000879| train set 5.495x speedup, test set 5.418x speedup, val set 5.104x speedup, step: 8
Epoch 28/300 |loss: 0.000813| train set 5.379x speedup, test set 5.195x speedup, val set 4.898x speedup, step: 9
Epoch 29/300 |loss: 0.001025| train set 5.492x speedup, test set 5.413x speedup, val set 5.100x speedup, step: 10
Epoch 30/300 |loss: 0.000749| train set 5.450x speedup, test set 5.331x speedup, val set 5.064x speedup, step: 11
Epoch 31/300 |loss: 0.000732| train set 5.495x speedup, test set 5.418x speedup, val set 5.104x speedup, step: 12
Epoch 32/300 |loss: 0.000815| train set 5.490x speedup, test set 5.413x speedup, val set 5.097x speedup, step: 13
Epoch 33/300 |loss: 0.000705| train set 5.497x speedup, test set 5.421x speedup, val set 5.106x speedup, step: 14
Epoch 34/300 |loss: 0.000721| train set 5.447x speedup, test set 5.329x speedup, val set 5.066x speedup, step: 15
Epoch 35/300 |loss: 0.000683| train set 5.449x speedup, test set 5.222x speedup, val set 5.056x speedup, step: 16
Epoch 36/300 |loss: 0.000670| train set 5.445x speedup, test set 5.317x speedup, val set 5.059x speedup, step: 17
Epoch 37/300 |loss: 0.000730| train set 5.443x speedup, test set 5.332x speedup, val set 5.061x speedup, step: 18
Epoch 38/300 |loss: 0.000632| train set 5.490x speedup, test set 5.417x speedup, val set 5.117x speedup, step: 1
Epoch 39/300 |loss: 0.000747| train set 5.491x speedup, test set 5.415x speedup, val set 5.097x speedup, step: 2
Epoch 40/300 |loss: 0.000878| train set 5.448x speedup, test set 5.332x speedup, val set 5.064x speedup, step: 3
early stopping at epoch 40
Training per epoch cost 0.408 s
Optimal speedup on test set is 5.508x
01, opt runtime 18.665s, model runtime 18.665s, pg runtime 18.665s, speedup 1.000x
02, opt runtime 25.356s, model runtime 25.356s, pg runtime 25.356s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 29.763s, model runtime 29.763s, pg runtime 91.648s, speedup 3.079x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 19.263s, model runtime 19.263s, pg runtime 19.263s, speedup 1.000x
07, opt runtime 7.110s, model runtime 7.110s, pg runtime 14.286s, speedup 2.009x
08, opt runtime 7.237s, model runtime 7.237s, pg runtime 17.708s, speedup 2.447x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 25.043s, model runtime 25.043s, pg runtime 73.019s, speedup 2.916x
12, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
13, opt runtime 3.332s, model runtime 3.332s, pg runtime 21.298s, speedup 6.391x
14, opt runtime 2.995s, model runtime 4.213s, pg runtime 14.646s, speedup 3.477x
15, opt runtime 47.518s, model runtime 47.518s, pg runtime 75.736s, speedup 1.594x
16, opt runtime 48.784s, model runtime 48.784s, pg runtime 78.349s, speedup 1.606x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 7.469s, model runtime 7.469s, pg runtime 23.223s, speedup 3.109x
19, opt runtime 1.309s, model runtime 1.309s, pg runtime 1.356s, speedup 1.036x
20, opt runtime 1.340s, model runtime 1.490s, pg runtime 1.340s, speedup 0.899x
21, opt runtime 6.281s, model runtime 6.281s, pg runtime 6.281s, speedup 1.000x
22, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
23, opt runtime 5.961s, model runtime 5.961s, pg runtime 31.210s, speedup 5.236x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.306s, model runtime 1.306s, pg runtime 1.306s, speedup 1.000x
26, opt runtime 1.342s, model runtime 1.342s, pg runtime 1.342s, speedup 1.000x
27, opt runtime 7.066s, model runtime 7.533s, pg runtime 7.533s, speedup 1.000x
28, opt runtime 7.268s, model runtime 7.268s, pg runtime 7.268s, speedup 1.000x
29, opt runtime 5.414s, model runtime 5.414s, pg runtime 5.414s, speedup 1.000x
30, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
31, opt runtime 25.363s, model runtime 25.363s, pg runtime 611.327s, speedup 24.103x
32, opt runtime 24.706s, model runtime 24.706s, pg runtime 610.808s, speedup 24.723x
33, opt runtime 35.538s, model runtime 35.538s, pg runtime 70.116s, speedup 1.973x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 16.138s, model runtime 16.138s, pg runtime 501.793s, speedup 31.094x
36, opt runtime 16.438s, model runtime 16.438s, pg runtime 546.887s, speedup 33.269x
37, opt runtime 15.754s, model runtime 15.754s, pg runtime 15.754s, speedup 1.000x
38, opt runtime 13.961s, model runtime 13.961s, pg runtime 13.961s, speedup 1.000x
39, opt runtime 1.098s, model runtime 1.098s, pg runtime 1.100s, speedup 1.001x
40, opt runtime 1.084s, model runtime 1.084s, pg runtime 1.155s, speedup 1.065x
====================
best train speedup epoch: 33, train speedup 5.497, test speedup 5.421, val speedup 5.106
best test speedup epoch: 19, train speedup 5.492, test speedup 5.422, val speedup 5.101
best validation speedup epoch: 38, train speedup 5.490, test speedup 5.417, val speedup 5.117
last model at epoch 40, train speedup 5.448, test speedup 5.332, val speedup 5.064
execution cost 0:00:40.087457
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1c.sql' '10b.sql' '11b.sql' '12a.sql' '13d.sql' '14c.sql' '15d.sql'
 '16a.sql' '17a.sql' '18a.sql' '19a.sql' '2b.sql' '20b.sql' '21a.sql'
 '22b.sql' '23c.sql' '24a.sql' '25a.sql' '26c.sql' '27a.sql' '28a.sql'
 '29a.sql' '3c.sql' '30b.sql' '31b.sql' '32a.sql' '33a.sql' '4c.sql'
 '5b.sql' '6c.sql' '7a.sql' '8a.sql' '9a.sql']
load JOB succ
load TPCH...
[0, 1, 3, 6, 7, 9] [4, 2] [5, 8]
[0, 3, 6, 7, 8, 9] [5, 1] [2, 4]
[0, 2, 3, 4, 8, 9] [1, 5] [7, 6]
[1, 2, 3, 5, 7, 8] [4, 0] [9, 6]
[0, 3, 4, 7, 8, 9] [1, 6] [2, 5]
[0, 1, 2, 6, 8, 9] [4, 5] [3, 7]
[2, 3, 4, 6, 7, 9] [1, 0] [5, 8]
[0, 2, 3, 6, 7, 9] [4, 1] [5, 8]
[0, 2, 3, 7, 8, 9] [1, 6] [5, 4]
[0, 1, 4, 6, 8, 9] [5, 2] [7, 3]
[0, 2, 5, 7, 8, 9] [3, 4] [1, 6]
[0, 3, 5, 6, 7, 9] [2, 8] [4, 1]
[0, 1, 2, 3, 8, 9] [7, 6] [4, 5]
[0, 1, 2, 4, 5, 9] [8, 3] [6, 7]
[2, 4, 5, 6, 7, 9] [0, 3] [1, 8]
[1, 2, 3, 7, 8, 9] [5, 6] [4, 0]
[0, 1, 2, 6, 8, 9] [3, 5] [4, 7]
[0, 2, 3, 4, 5, 8] [7, 6] [9, 1]
[0, 1, 3, 6, 8, 9] [4, 2] [5, 7]
[0, 1, 2, 3, 6, 7] [8, 9] [4, 5]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.781795, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.049662| train set 2.636x speedup, test set 2.555x speedup, val set 2.435x speedup, step: 1
Epoch 1/300 |loss: 0.020790| train set 2.944x speedup, test set 2.779x speedup, val set 2.627x speedup, step: 1
Epoch 2/300 |loss: 0.010599| train set 3.374x speedup, test set 3.149x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006414| train set 3.841x speedup, test set 3.659x speedup, val set 3.568x speedup, step: 1
Epoch 4/300 |loss: 0.004772| train set 3.593x speedup, test set 3.481x speedup, val set 3.343x speedup, step: 2
Epoch 5/300 |loss: 0.003750| train set 3.395x speedup, test set 3.230x speedup, val set 3.130x speedup, step: 3
Epoch 6/300 |loss: 0.004254| train set 4.779x speedup, test set 4.461x speedup, val set 4.631x speedup, step: 1
Epoch 7/300 |loss: 0.003391| train set 4.971x speedup, test set 4.709x speedup, val set 4.842x speedup, step: 1
Epoch 8/300 |loss: 0.002525| train set 4.018x speedup, test set 3.845x speedup, val set 3.720x speedup, step: 2
Epoch 9/300 |loss: 0.002194| train set 5.339x speedup, test set 5.079x speedup, val set 5.077x speedup, step: 1
Epoch 10/300 |loss: 0.002026| train set 4.216x speedup, test set 4.117x speedup, val set 3.848x speedup, step: 2
Epoch 11/300 |loss: 0.002070| train set 5.395x speedup, test set 5.310x speedup, val set 5.033x speedup, step: 3
Epoch 12/300 |loss: 0.002314| train set 4.957x speedup, test set 5.358x speedup, val set 4.959x speedup, step: 4
Epoch 13/300 |loss: 0.001894| train set 4.966x speedup, test set 5.340x speedup, val set 5.030x speedup, step: 5
Epoch 14/300 |loss: 0.002103| train set 5.025x speedup, test set 4.819x speedup, val set 4.760x speedup, step: 6
Epoch 15/300 |loss: 0.002089| train set 5.113x speedup, test set 5.229x speedup, val set 4.963x speedup, step: 7
Epoch 16/300 |loss: 0.001431| train set 4.950x speedup, test set 5.328x speedup, val set 5.005x speedup, step: 8
Epoch 17/300 |loss: 0.001524| train set 3.989x speedup, test set 3.796x speedup, val set 3.697x speedup, step: 9
Epoch 18/300 |loss: 0.001636| train set 5.400x speedup, test set 5.200x speedup, val set 4.949x speedup, step: 10
Epoch 19/300 |loss: 0.001364| train set 5.496x speedup, test set 5.421x speedup, val set 5.107x speedup, step: 1
Epoch 20/300 |loss: 0.001059| train set 5.496x speedup, test set 5.421x speedup, val set 5.107x speedup, step: 1
Epoch 21/300 |loss: 0.000936| train set 5.031x speedup, test set 5.412x speedup, val set 5.094x speedup, step: 2
Epoch 22/300 |loss: 0.001214| train set 4.673x speedup, test set 4.076x speedup, val set 4.194x speedup, step: 3
Epoch 23/300 |loss: 0.001282| train set 5.418x speedup, test set 5.387x speedup, val set 4.948x speedup, step: 4
Epoch 24/300 |loss: 0.000873| train set 5.179x speedup, test set 5.286x speedup, val set 5.059x speedup, step: 5
Epoch 25/300 |loss: 0.000845| train set 5.447x speedup, test set 5.359x speedup, val set 5.186x speedup, step: 1
Epoch 26/300 |loss: 0.000771| train set 5.445x speedup, test set 5.319x speedup, val set 5.061x speedup, step: 2
Epoch 27/300 |loss: 0.000895| train set 5.446x speedup, test set 5.328x speedup, val set 5.065x speedup, step: 3
Epoch 28/300 |loss: 0.000774| train set 5.377x speedup, test set 5.102x speedup, val set 5.013x speedup, step: 4
Epoch 29/300 |loss: 0.000822| train set 5.494x speedup, test set 5.409x speedup, val set 5.100x speedup, step: 5
Epoch 30/300 |loss: 0.000738| train set 5.497x speedup, test set 5.422x speedup, val set 5.103x speedup, step: 6
Epoch 31/300 |loss: 0.000789| train set 5.495x speedup, test set 5.418x speedup, val set 5.104x speedup, step: 7
Epoch 32/300 |loss: 0.000727| train set 5.442x speedup, test set 5.325x speedup, val set 5.059x speedup, step: 8
Epoch 33/300 |loss: 0.000706| train set 5.497x speedup, test set 5.421x speedup, val set 5.106x speedup, step: 9
Epoch 34/300 |loss: 0.000727| train set 5.450x speedup, test set 5.314x speedup, val set 5.070x speedup, step: 10
Epoch 35/300 |loss: 0.000688| train set 5.496x speedup, test set 5.421x speedup, val set 5.107x speedup, step: 11
Epoch 36/300 |loss: 0.000734| train set 5.446x speedup, test set 5.319x speedup, val set 5.067x speedup, step: 12
Epoch 37/300 |loss: 0.000749| train set 5.437x speedup, test set 5.324x speedup, val set 5.056x speedup, step: 13
Epoch 38/300 |loss: 0.000649| train set 5.496x speedup, test set 5.420x speedup, val set 5.107x speedup, step: 14
Epoch 39/300 |loss: 0.000935| train set 5.317x speedup, test set 5.187x speedup, val set 4.974x speedup, step: 15
Epoch 40/300 |loss: 0.000923| train set 5.451x speedup, test set 5.316x speedup, val set 5.069x speedup, step: 16
early stopping at epoch 40
Training per epoch cost 0.414 s
Optimal speedup on test set is 5.508x
01, opt runtime 18.665s, model runtime 18.665s, pg runtime 18.665s, speedup 1.000x
02, opt runtime 25.356s, model runtime 25.356s, pg runtime 25.356s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 29.763s, model runtime 29.763s, pg runtime 91.648s, speedup 3.079x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 19.263s, model runtime 19.263s, pg runtime 19.263s, speedup 1.000x
07, opt runtime 7.110s, model runtime 7.110s, pg runtime 14.286s, speedup 2.009x
08, opt runtime 7.237s, model runtime 7.237s, pg runtime 17.708s, speedup 2.447x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 25.043s, model runtime 25.043s, pg runtime 73.019s, speedup 2.916x
12, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 2.995s, model runtime 2.995s, pg runtime 14.646s, speedup 4.890x
15, opt runtime 47.518s, model runtime 47.518s, pg runtime 75.736s, speedup 1.594x
16, opt runtime 48.784s, model runtime 48.784s, pg runtime 78.349s, speedup 1.606x
17, opt runtime 10.788s, model runtime 16.078s, pg runtime 32.939s, speedup 2.049x
18, opt runtime 7.469s, model runtime 7.469s, pg runtime 23.223s, speedup 3.109x
19, opt runtime 1.309s, model runtime 1.356s, pg runtime 1.356s, speedup 1.000x
20, opt runtime 1.340s, model runtime 1.340s, pg runtime 1.340s, speedup 1.000x
21, opt runtime 6.281s, model runtime 6.281s, pg runtime 6.281s, speedup 1.000x
22, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
23, opt runtime 5.961s, model runtime 5.961s, pg runtime 31.210s, speedup 5.236x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.306s, model runtime 1.418s, pg runtime 1.306s, speedup 0.921x
26, opt runtime 1.342s, model runtime 2.555s, pg runtime 1.342s, speedup 0.525x
27, opt runtime 7.066s, model runtime 7.066s, pg runtime 7.533s, speedup 1.066x
28, opt runtime 7.268s, model runtime 7.507s, pg runtime 7.268s, speedup 0.968x
29, opt runtime 5.414s, model runtime 5.780s, pg runtime 5.414s, speedup 0.937x
30, opt runtime 5.572s, model runtime 5.971s, pg runtime 5.572s, speedup 0.933x
31, opt runtime 25.363s, model runtime 25.363s, pg runtime 611.327s, speedup 24.103x
32, opt runtime 24.706s, model runtime 24.706s, pg runtime 610.808s, speedup 24.723x
33, opt runtime 35.538s, model runtime 35.538s, pg runtime 70.116s, speedup 1.973x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 16.138s, model runtime 16.138s, pg runtime 501.793s, speedup 31.094x
36, opt runtime 16.438s, model runtime 16.438s, pg runtime 546.887s, speedup 33.269x
37, opt runtime 15.754s, model runtime 15.754s, pg runtime 15.754s, speedup 1.000x
38, opt runtime 13.961s, model runtime 13.961s, pg runtime 13.961s, speedup 1.000x
39, opt runtime 1.098s, model runtime 1.098s, pg runtime 1.100s, speedup 1.001x
40, opt runtime 1.084s, model runtime 1.084s, pg runtime 1.155s, speedup 1.065x
====================
best train speedup epoch: 33, train speedup 5.497, test speedup 5.421, val speedup 5.106
best test speedup epoch: 30, train speedup 5.497, test speedup 5.422, val speedup 5.103
best validation speedup epoch: 25, train speedup 5.447, test speedup 5.359, val speedup 5.186
last model at epoch 40, train speedup 5.451, test speedup 5.316, val speedup 5.069
execution cost 0:00:40.011465
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1c.sql' '10b.sql' '11b.sql' '12a.sql' '13d.sql' '14c.sql' '15d.sql'
 '16a.sql' '17a.sql' '18a.sql' '19a.sql' '2b.sql' '20b.sql' '21a.sql'
 '22b.sql' '23c.sql' '24a.sql' '25a.sql' '26c.sql' '27a.sql' '28a.sql'
 '29a.sql' '3c.sql' '30b.sql' '31b.sql' '32a.sql' '33a.sql' '4c.sql'
 '5b.sql' '6c.sql' '7a.sql' '8a.sql' '9a.sql']
load JOB succ
load TPCH...
[0, 1, 3, 6, 7, 9] [4, 2] [5, 8]
[0, 3, 6, 7, 8, 9] [5, 1] [2, 4]
[0, 2, 3, 4, 8, 9] [1, 5] [7, 6]
[1, 2, 3, 5, 7, 8] [4, 0] [9, 6]
[0, 3, 4, 7, 8, 9] [1, 6] [2, 5]
[0, 1, 2, 6, 8, 9] [4, 5] [3, 7]
[2, 3, 4, 6, 7, 9] [1, 0] [5, 8]
[0, 2, 3, 6, 7, 9] [4, 1] [5, 8]
[0, 2, 3, 7, 8, 9] [1, 6] [5, 4]
[0, 1, 4, 6, 8, 9] [5, 2] [7, 3]
[0, 2, 5, 7, 8, 9] [3, 4] [1, 6]
[0, 3, 5, 6, 7, 9] [2, 8] [4, 1]
[0, 1, 2, 3, 8, 9] [7, 6] [4, 5]
[0, 1, 2, 4, 5, 9] [8, 3] [6, 7]
[2, 4, 5, 6, 7, 9] [0, 3] [1, 8]
[1, 2, 3, 7, 8, 9] [5, 6] [4, 0]
[0, 1, 2, 6, 8, 9] [3, 5] [4, 7]
[0, 2, 3, 4, 5, 8] [7, 6] [9, 1]
[0, 1, 3, 6, 8, 9] [4, 2] [5, 7]
[0, 1, 2, 3, 6, 7] [8, 9] [4, 5]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.750196, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.049662| train set 2.636x speedup, test set 2.555x speedup, val set 2.435x speedup, step: 1
Epoch 1/300 |loss: 0.020790| train set 2.944x speedup, test set 2.779x speedup, val set 2.627x speedup, step: 1
Epoch 2/300 |loss: 0.010599| train set 3.374x speedup, test set 3.149x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006414| train set 3.841x speedup, test set 3.659x speedup, val set 3.568x speedup, step: 1
Epoch 4/300 |loss: 0.004772| train set 3.593x speedup, test set 3.481x speedup, val set 3.343x speedup, step: 2
Epoch 5/300 |loss: 0.003757| train set 3.418x speedup, test set 3.239x speedup, val set 3.141x speedup, step: 3
Epoch 6/300 |loss: 0.004334| train set 5.306x speedup, test set 5.058x speedup, val set 4.982x speedup, step: 1
Epoch 7/300 |loss: 0.003329| train set 4.966x speedup, test set 4.704x speedup, val set 4.838x speedup, step: 2
Epoch 8/300 |loss: 0.002516| train set 4.015x speedup, test set 3.842x speedup, val set 3.719x speedup, step: 3
Epoch 9/300 |loss: 0.002171| train set 5.278x speedup, test set 4.995x speedup, val set 5.034x speedup, step: 1
Epoch 10/300 |loss: 0.002072| train set 4.216x speedup, test set 4.117x speedup, val set 3.848x speedup, step: 2
Epoch 11/300 |loss: 0.002029| train set 5.350x speedup, test set 5.227x speedup, val set 4.999x speedup, step: 3
Epoch 12/300 |loss: 0.002215| train set 5.165x speedup, test set 5.358x speedup, val set 4.959x speedup, step: 4
Epoch 13/300 |loss: 0.002185| train set 5.169x speedup, test set 5.333x speedup, val set 5.021x speedup, step: 5
Epoch 14/300 |loss: 0.002070| train set 3.737x speedup, test set 3.492x speedup, val set 3.427x speedup, step: 6
Epoch 15/300 |loss: 0.002185| train set 5.095x speedup, test set 5.303x speedup, val set 4.866x speedup, step: 7
Epoch 16/300 |loss: 0.001389| train set 5.249x speedup, test set 5.406x speedup, val set 5.096x speedup, step: 1
Epoch 17/300 |loss: 0.001465| train set 3.990x speedup, test set 3.797x speedup, val set 3.698x speedup, step: 2
Epoch 18/300 |loss: 0.001540| train set 5.464x speedup, test set 5.221x speedup, val set 5.047x speedup, step: 3
Epoch 19/300 |loss: 0.001367| train set 5.421x speedup, test set 5.349x speedup, val set 5.040x speedup, step: 4
Epoch 20/300 |loss: 0.001037| train set 5.448x speedup, test set 5.332x speedup, val set 5.068x speedup, step: 5
Epoch 21/300 |loss: 0.000904| train set 5.032x speedup, test set 5.414x speedup, val set 5.098x speedup, step: 1
Epoch 22/300 |loss: 0.001080| train set 4.914x speedup, test set 5.238x speedup, val set 4.974x speedup, step: 2
Epoch 23/300 |loss: 0.000984| train set 5.248x speedup, test set 5.422x speedup, val set 5.101x speedup, step: 1
Epoch 24/300 |loss: 0.000800| train set 4.974x speedup, test set 5.281x speedup, val set 5.061x speedup, step: 2
Epoch 25/300 |loss: 0.000876| train set 5.485x speedup, test set 5.415x speedup, val set 5.096x speedup, step: 3
Epoch 26/300 |loss: 0.000798| train set 5.442x speedup, test set 5.322x speedup, val set 5.055x speedup, step: 4
Epoch 27/300 |loss: 0.000982| train set 5.447x speedup, test set 5.329x speedup, val set 5.066x speedup, step: 5
Epoch 28/300 |loss: 0.000803| train set 5.379x speedup, test set 5.196x speedup, val set 4.910x speedup, step: 6
Epoch 29/300 |loss: 0.000971| train set 5.390x speedup, test set 5.311x speedup, val set 5.016x speedup, step: 7
Epoch 30/300 |loss: 0.000732| train set 5.497x speedup, test set 5.422x speedup, val set 5.106x speedup, step: 1
Epoch 31/300 |loss: 0.000731| train set 5.496x speedup, test set 5.408x speedup, val set 5.104x speedup, step: 2
Epoch 32/300 |loss: 0.000830| train set 5.491x speedup, test set 5.420x speedup, val set 5.099x speedup, step: 3
Epoch 33/300 |loss: 0.000678| train set 5.497x speedup, test set 5.421x speedup, val set 5.106x speedup, step: 4
Epoch 34/300 |loss: 0.000688| train set 5.447x speedup, test set 5.330x speedup, val set 5.067x speedup, step: 5
Epoch 35/300 |loss: 0.000677| train set 5.449x speedup, test set 5.222x speedup, val set 5.054x speedup, step: 6
Epoch 36/300 |loss: 0.000675| train set 5.445x speedup, test set 5.319x speedup, val set 5.061x speedup, step: 7
Epoch 37/300 |loss: 0.000708| train set 5.444x speedup, test set 5.309x speedup, val set 5.064x speedup, step: 8
Epoch 38/300 |loss: 0.000619| train set 5.490x speedup, test set 5.408x speedup, val set 5.115x speedup, step: 1
Epoch 39/300 |loss: 0.000754| train set 5.492x speedup, test set 5.423x speedup, val set 5.100x speedup, step: 2
Epoch 40/300 |loss: 0.000885| train set 5.499x speedup, test set 5.405x speedup, val set 5.108x speedup, step: 3
early stopping at epoch 40
Training per epoch cost 0.403 s
Optimal speedup on test set is 5.508x
01, opt runtime 18.665s, model runtime 18.665s, pg runtime 18.665s, speedup 1.000x
02, opt runtime 25.356s, model runtime 25.356s, pg runtime 25.356s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 29.763s, model runtime 29.763s, pg runtime 91.648s, speedup 3.079x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 19.263s, model runtime 19.263s, pg runtime 19.263s, speedup 1.000x
07, opt runtime 7.110s, model runtime 7.110s, pg runtime 14.286s, speedup 2.009x
08, opt runtime 7.237s, model runtime 7.237s, pg runtime 17.708s, speedup 2.447x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 25.043s, model runtime 25.043s, pg runtime 73.019s, speedup 2.916x
12, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
13, opt runtime 3.332s, model runtime 3.332s, pg runtime 21.298s, speedup 6.391x
14, opt runtime 2.995s, model runtime 4.213s, pg runtime 14.646s, speedup 3.477x
15, opt runtime 47.518s, model runtime 47.518s, pg runtime 75.736s, speedup 1.594x
16, opt runtime 48.784s, model runtime 48.784s, pg runtime 78.349s, speedup 1.606x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 7.469s, model runtime 7.469s, pg runtime 23.223s, speedup 3.109x
19, opt runtime 1.309s, model runtime 1.356s, pg runtime 1.356s, speedup 1.000x
20, opt runtime 1.340s, model runtime 1.340s, pg runtime 1.340s, speedup 1.000x
21, opt runtime 6.281s, model runtime 6.281s, pg runtime 6.281s, speedup 1.000x
22, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
23, opt runtime 5.961s, model runtime 5.961s, pg runtime 31.210s, speedup 5.236x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.306s, model runtime 1.306s, pg runtime 1.306s, speedup 1.000x
26, opt runtime 1.342s, model runtime 2.555s, pg runtime 1.342s, speedup 0.525x
27, opt runtime 7.066s, model runtime 7.355s, pg runtime 7.533s, speedup 1.024x
28, opt runtime 7.268s, model runtime 7.333s, pg runtime 7.268s, speedup 0.991x
29, opt runtime 5.414s, model runtime 5.414s, pg runtime 5.414s, speedup 1.000x
30, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
31, opt runtime 25.363s, model runtime 25.363s, pg runtime 611.327s, speedup 24.103x
32, opt runtime 24.706s, model runtime 24.706s, pg runtime 610.808s, speedup 24.723x
33, opt runtime 35.538s, model runtime 35.538s, pg runtime 70.116s, speedup 1.973x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 16.138s, model runtime 16.138s, pg runtime 501.793s, speedup 31.094x
36, opt runtime 16.438s, model runtime 16.438s, pg runtime 546.887s, speedup 33.269x
37, opt runtime 15.754s, model runtime 15.754s, pg runtime 15.754s, speedup 1.000x
38, opt runtime 13.961s, model runtime 13.961s, pg runtime 13.961s, speedup 1.000x
39, opt runtime 1.098s, model runtime 1.098s, pg runtime 1.100s, speedup 1.001x
40, opt runtime 1.084s, model runtime 1.084s, pg runtime 1.155s, speedup 1.065x
====================
best train speedup epoch: 40, train speedup 5.499, test speedup 5.405, val speedup 5.108
best test speedup epoch: 39, train speedup 5.492, test speedup 5.423, val speedup 5.100
best validation speedup epoch: 38, train speedup 5.490, test speedup 5.408, val speedup 5.115
last model at epoch 40, train speedup 5.499, test speedup 5.405, val speedup 5.108
execution cost 0:00:40.135510
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1c.sql' '10b.sql' '11b.sql' '12a.sql' '13d.sql' '14c.sql' '15d.sql'
 '16a.sql' '17a.sql' '18a.sql' '19a.sql' '2b.sql' '20b.sql' '21a.sql'
 '22b.sql' '23c.sql' '24a.sql' '25a.sql' '26c.sql' '27a.sql' '28a.sql'
 '29a.sql' '3c.sql' '30b.sql' '31b.sql' '32a.sql' '33a.sql' '4c.sql'
 '5b.sql' '6c.sql' '7a.sql' '8a.sql' '9a.sql']
load JOB succ
load TPCH...
[0, 1, 3, 6, 7, 9] [4, 2] [5, 8]
[0, 3, 6, 7, 8, 9] [5, 1] [2, 4]
[0, 2, 3, 4, 8, 9] [1, 5] [7, 6]
[1, 2, 3, 5, 7, 8] [4, 0] [9, 6]
[0, 3, 4, 7, 8, 9] [1, 6] [2, 5]
[0, 1, 2, 6, 8, 9] [4, 5] [3, 7]
[2, 3, 4, 6, 7, 9] [1, 0] [5, 8]
[0, 2, 3, 6, 7, 9] [4, 1] [5, 8]
[0, 2, 3, 7, 8, 9] [1, 6] [5, 4]
[0, 1, 4, 6, 8, 9] [5, 2] [7, 3]
[0, 2, 5, 7, 8, 9] [3, 4] [1, 6]
[0, 3, 5, 6, 7, 9] [2, 8] [4, 1]
[0, 1, 2, 3, 8, 9] [7, 6] [4, 5]
[0, 1, 2, 4, 5, 9] [8, 3] [6, 7]
[2, 4, 5, 6, 7, 9] [0, 3] [1, 8]
[1, 2, 3, 7, 8, 9] [5, 6] [4, 0]
[0, 1, 2, 6, 8, 9] [3, 5] [4, 7]
[0, 2, 3, 4, 5, 8] [7, 6] [9, 1]
[0, 1, 3, 6, 8, 9] [4, 2] [5, 7]
[0, 1, 2, 3, 6, 7] [8, 9] [4, 5]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.850322, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.049662| train set 2.636x speedup, test set 2.555x speedup, val set 2.435x speedup, step: 1
Epoch 1/300 |loss: 0.020790| train set 2.944x speedup, test set 2.779x speedup, val set 2.627x speedup, step: 1
Epoch 2/300 |loss: 0.010599| train set 3.374x speedup, test set 3.149x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006414| train set 3.841x speedup, test set 3.659x speedup, val set 3.568x speedup, step: 1
Epoch 4/300 |loss: 0.004772| train set 3.593x speedup, test set 3.481x speedup, val set 3.343x speedup, step: 2
Epoch 5/300 |loss: 0.003747| train set 3.600x speedup, test set 3.492x speedup, val set 3.348x speedup, step: 3
Epoch 6/300 |loss: 0.004243| train set 4.736x speedup, test set 4.487x speedup, val set 4.462x speedup, step: 1
Epoch 7/300 |loss: 0.003400| train set 4.965x speedup, test set 4.703x speedup, val set 4.838x speedup, step: 1
Epoch 8/300 |loss: 0.002589| train set 4.015x speedup, test set 3.842x speedup, val set 3.717x speedup, step: 2
Epoch 9/300 |loss: 0.002184| train set 5.186x speedup, test set 4.969x speedup, val set 4.846x speedup, step: 1
Epoch 10/300 |loss: 0.002048| train set 4.928x speedup, test set 5.282x speedup, val set 5.005x speedup, step: 1
Epoch 11/300 |loss: 0.002050| train set 5.395x speedup, test set 5.310x speedup, val set 5.033x speedup, step: 1
Epoch 12/300 |loss: 0.002312| train set 5.425x speedup, test set 5.396x speedup, val set 4.961x speedup, step: 2
Epoch 13/300 |loss: 0.002176| train set 5.162x speedup, test set 5.314x speedup, val set 5.007x speedup, step: 3
Epoch 14/300 |loss: 0.002055| train set 3.877x speedup, test set 3.477x speedup, val set 3.360x speedup, step: 4
Epoch 15/300 |loss: 0.002104| train set 4.949x speedup, test set 5.316x speedup, val set 5.005x speedup, step: 5
Epoch 16/300 |loss: 0.001421| train set 5.184x speedup, test set 5.340x speedup, val set 5.039x speedup, step: 1
Epoch 17/300 |loss: 0.001496| train set 4.007x speedup, test set 3.797x speedup, val set 3.698x speedup, step: 2
Epoch 18/300 |loss: 0.001476| train set 5.376x speedup, test set 5.200x speedup, val set 4.906x speedup, step: 3
Epoch 19/300 |loss: 0.001310| train set 5.421x speedup, test set 5.338x speedup, val set 5.039x speedup, step: 1
Epoch 20/300 |loss: 0.001033| train set 5.497x speedup, test set 5.422x speedup, val set 5.106x speedup, step: 1
Epoch 21/300 |loss: 0.000856| train set 5.031x speedup, test set 5.412x speedup, val set 5.094x speedup, step: 2
Epoch 22/300 |loss: 0.001310| train set 4.856x speedup, test set 5.204x speedup, val set 4.830x speedup, step: 3
Epoch 23/300 |loss: 0.001256| train set 5.442x speedup, test set 5.388x speedup, val set 4.990x speedup, step: 4
Epoch 24/300 |loss: 0.000841| train set 4.974x speedup, test set 5.283x speedup, val set 4.952x speedup, step: 5
Epoch 25/300 |loss: 0.000901| train set 5.489x speedup, test set 5.404x speedup, val set 5.101x speedup, step: 6
Epoch 26/300 |loss: 0.000729| train set 5.446x speedup, test set 5.320x speedup, val set 5.060x speedup, step: 7
Epoch 27/300 |loss: 0.000818| train set 5.495x speedup, test set 5.418x speedup, val set 5.104x speedup, step: 8
Epoch 28/300 |loss: 0.000764| train set 5.446x speedup, test set 5.220x speedup, val set 5.049x speedup, step: 9
Epoch 29/300 |loss: 0.000978| train set 5.437x speedup, test set 5.357x speedup, val set 5.000x speedup, step: 10
Epoch 30/300 |loss: 0.000746| train set 5.448x speedup, test set 5.331x speedup, val set 5.067x speedup, step: 11
Epoch 31/300 |loss: 0.000758| train set 5.495x speedup, test set 5.418x speedup, val set 5.104x speedup, step: 12
Epoch 32/300 |loss: 0.000705| train set 5.491x speedup, test set 5.420x speedup, val set 5.099x speedup, step: 13
Epoch 33/300 |loss: 0.000723| train set 5.497x speedup, test set 5.421x speedup, val set 5.106x speedup, step: 14
Epoch 34/300 |loss: 0.000722| train set 5.448x speedup, test set 5.303x speedup, val set 5.063x speedup, step: 15
Epoch 35/300 |loss: 0.000677| train set 5.496x speedup, test set 5.421x speedup, val set 5.107x speedup, step: 1
Epoch 36/300 |loss: 0.000679| train set 5.496x speedup, test set 5.421x speedup, val set 5.107x speedup, step: 2
Epoch 37/300 |loss: 0.000682| train set 5.499x speedup, test set 5.405x speedup, val set 5.108x speedup, step: 1
Epoch 38/300 |loss: 0.000604| train set 5.497x speedup, test set 5.422x speedup, val set 5.106x speedup, step: 2
Epoch 39/300 |loss: 0.000768| train set 5.492x speedup, test set 5.422x speedup, val set 5.101x speedup, step: 3
Epoch 40/300 |loss: 0.000854| train set 5.450x speedup, test set 5.315x speedup, val set 5.070x speedup, step: 4
early stopping at epoch 40
Training per epoch cost 0.416 s
Optimal speedup on test set is 5.508x
01, opt runtime 18.665s, model runtime 18.665s, pg runtime 18.665s, speedup 1.000x
02, opt runtime 25.356s, model runtime 25.356s, pg runtime 25.356s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 29.763s, model runtime 29.763s, pg runtime 91.648s, speedup 3.079x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 19.263s, model runtime 19.263s, pg runtime 19.263s, speedup 1.000x
07, opt runtime 7.110s, model runtime 7.841s, pg runtime 14.286s, speedup 1.822x
08, opt runtime 7.237s, model runtime 8.427s, pg runtime 17.708s, speedup 2.101x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 25.043s, model runtime 25.043s, pg runtime 73.019s, speedup 2.916x
12, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 2.995s, model runtime 2.995s, pg runtime 14.646s, speedup 4.890x
15, opt runtime 47.518s, model runtime 47.518s, pg runtime 75.736s, speedup 1.594x
16, opt runtime 48.784s, model runtime 48.784s, pg runtime 78.349s, speedup 1.606x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 7.469s, model runtime 7.469s, pg runtime 23.223s, speedup 3.109x
19, opt runtime 1.309s, model runtime 1.356s, pg runtime 1.356s, speedup 1.000x
20, opt runtime 1.340s, model runtime 1.340s, pg runtime 1.340s, speedup 1.000x
21, opt runtime 6.281s, model runtime 6.281s, pg runtime 6.281s, speedup 1.000x
22, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
23, opt runtime 5.961s, model runtime 5.961s, pg runtime 31.210s, speedup 5.236x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.306s, model runtime 1.306s, pg runtime 1.306s, speedup 1.000x
26, opt runtime 1.342s, model runtime 1.342s, pg runtime 1.342s, speedup 1.000x
27, opt runtime 7.066s, model runtime 7.355s, pg runtime 7.533s, speedup 1.024x
28, opt runtime 7.268s, model runtime 7.333s, pg runtime 7.268s, speedup 0.991x
29, opt runtime 5.414s, model runtime 5.414s, pg runtime 5.414s, speedup 1.000x
30, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
31, opt runtime 25.363s, model runtime 25.363s, pg runtime 611.327s, speedup 24.103x
32, opt runtime 24.706s, model runtime 24.706s, pg runtime 610.808s, speedup 24.723x
33, opt runtime 35.538s, model runtime 35.538s, pg runtime 70.116s, speedup 1.973x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 16.138s, model runtime 16.138s, pg runtime 501.793s, speedup 31.094x
36, opt runtime 16.438s, model runtime 16.438s, pg runtime 546.887s, speedup 33.269x
37, opt runtime 15.754s, model runtime 15.754s, pg runtime 15.754s, speedup 1.000x
38, opt runtime 13.961s, model runtime 13.961s, pg runtime 13.961s, speedup 1.000x
39, opt runtime 1.098s, model runtime 1.098s, pg runtime 1.100s, speedup 1.001x
40, opt runtime 1.084s, model runtime 1.084s, pg runtime 1.155s, speedup 1.065x
====================
best train speedup epoch: 37, train speedup 5.499, test speedup 5.405, val speedup 5.108
best test speedup epoch: 39, train speedup 5.492, test speedup 5.422, val speedup 5.101
best validation speedup epoch: 37, train speedup 5.499, test speedup 5.405, val speedup 5.108
last model at epoch 40, train speedup 5.450, test speedup 5.315, val speedup 5.070
execution cost 0:00:40.516692
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1c.sql' '10b.sql' '11b.sql' '12a.sql' '13d.sql' '14c.sql' '15d.sql'
 '16a.sql' '17a.sql' '18a.sql' '19a.sql' '2b.sql' '20b.sql' '21a.sql'
 '22b.sql' '23c.sql' '24a.sql' '25a.sql' '26c.sql' '27a.sql' '28a.sql'
 '29a.sql' '3c.sql' '30b.sql' '31b.sql' '32a.sql' '33a.sql' '4c.sql'
 '5b.sql' '6c.sql' '7a.sql' '8a.sql' '9a.sql']
load JOB succ
load TPCH...
[0, 1, 3, 6, 7, 9] [4, 2] [5, 8]
[0, 3, 6, 7, 8, 9] [5, 1] [2, 4]
[0, 2, 3, 4, 8, 9] [1, 5] [7, 6]
[1, 2, 3, 5, 7, 8] [4, 0] [9, 6]
[0, 3, 4, 7, 8, 9] [1, 6] [2, 5]
[0, 1, 2, 6, 8, 9] [4, 5] [3, 7]
[2, 3, 4, 6, 7, 9] [1, 0] [5, 8]
[0, 2, 3, 6, 7, 9] [4, 1] [5, 8]
[0, 2, 3, 7, 8, 9] [1, 6] [5, 4]
[0, 1, 4, 6, 8, 9] [5, 2] [7, 3]
[0, 2, 5, 7, 8, 9] [3, 4] [1, 6]
[0, 3, 5, 6, 7, 9] [2, 8] [4, 1]
[0, 1, 2, 3, 8, 9] [7, 6] [4, 5]
[0, 1, 2, 4, 5, 9] [8, 3] [6, 7]
[2, 4, 5, 6, 7, 9] [0, 3] [1, 8]
[1, 2, 3, 7, 8, 9] [5, 6] [4, 0]
[0, 1, 2, 6, 8, 9] [3, 5] [4, 7]
[0, 2, 3, 4, 5, 8] [7, 6] [9, 1]
[0, 1, 3, 6, 8, 9] [4, 2] [5, 7]
[0, 1, 2, 3, 6, 7] [8, 9] [4, 5]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.784835, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.049662| train set 2.636x speedup, test set 2.555x speedup, val set 2.435x speedup, step: 1
Epoch 1/300 |loss: 0.020790| train set 2.944x speedup, test set 2.779x speedup, val set 2.627x speedup, step: 1
Epoch 2/300 |loss: 0.010599| train set 3.374x speedup, test set 3.149x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006414| train set 3.841x speedup, test set 3.659x speedup, val set 3.568x speedup, step: 1
Epoch 4/300 |loss: 0.004772| train set 3.593x speedup, test set 3.481x speedup, val set 3.343x speedup, step: 2
Epoch 5/300 |loss: 0.003750| train set 3.395x speedup, test set 3.230x speedup, val set 3.130x speedup, step: 3
Epoch 6/300 |loss: 0.004196| train set 4.885x speedup, test set 4.664x speedup, val set 4.622x speedup, step: 1
Epoch 7/300 |loss: 0.003433| train set 4.971x speedup, test set 4.709x speedup, val set 4.842x speedup, step: 1
Epoch 8/300 |loss: 0.002536| train set 4.015x speedup, test set 3.842x speedup, val set 3.719x speedup, step: 2
Epoch 9/300 |loss: 0.002215| train set 5.230x speedup, test set 5.001x speedup, val set 4.889x speedup, step: 1
Epoch 10/300 |loss: 0.002031| train set 4.535x speedup, test set 4.117x speedup, val set 3.849x speedup, step: 2
Epoch 11/300 |loss: 0.002053| train set 5.154x speedup, test set 5.304x speedup, val set 5.029x speedup, step: 1
Epoch 12/300 |loss: 0.002215| train set 5.165x speedup, test set 5.358x speedup, val set 4.959x speedup, step: 2
Epoch 13/300 |loss: 0.002130| train set 4.886x speedup, test set 5.185x speedup, val set 4.961x speedup, step: 3
Epoch 14/300 |loss: 0.001925| train set 4.631x speedup, test set 4.800x speedup, val set 4.667x speedup, step: 4
Epoch 15/300 |loss: 0.001922| train set 4.854x speedup, test set 5.217x speedup, val set 4.831x speedup, step: 5
Epoch 16/300 |loss: 0.001579| train set 5.249x speedup, test set 5.417x speedup, val set 5.102x speedup, step: 1
Epoch 17/300 |loss: 0.001466| train set 4.266x speedup, test set 4.147x speedup, val set 3.885x speedup, step: 2
Epoch 18/300 |loss: 0.001294| train set 5.442x speedup, test set 5.205x speedup, val set 5.039x speedup, step: 3
Epoch 19/300 |loss: 0.001286| train set 5.490x speedup, test set 5.410x speedup, val set 5.094x speedup, step: 4
Epoch 20/300 |loss: 0.001018| train set 5.448x speedup, test set 5.331x speedup, val set 5.068x speedup, step: 5
Epoch 21/300 |loss: 0.000914| train set 5.033x speedup, test set 5.415x speedup, val set 5.097x speedup, step: 6
Epoch 22/300 |loss: 0.000999| train set 4.994x speedup, test set 5.328x speedup, val set 5.064x speedup, step: 7
Epoch 23/300 |loss: 0.000945| train set 5.488x speedup, test set 5.403x speedup, val set 5.090x speedup, step: 8
Epoch 24/300 |loss: 0.000836| train set 4.992x speedup, test set 5.325x speedup, val set 5.062x speedup, step: 9
Epoch 25/300 |loss: 0.000882| train set 5.494x speedup, test set 5.409x speedup, val set 5.100x speedup, step: 10
Epoch 26/300 |loss: 0.000833| train set 5.495x speedup, test set 5.409x speedup, val set 5.086x speedup, step: 11
Epoch 27/300 |loss: 0.000789| train set 5.447x speedup, test set 5.329x speedup, val set 5.066x speedup, step: 12
Epoch 28/300 |loss: 0.000758| train set 5.418x speedup, test set 5.179x speedup, val set 5.044x speedup, step: 13
Epoch 29/300 |loss: 0.000999| train set 5.492x speedup, test set 5.414x speedup, val set 5.099x speedup, step: 14
Epoch 30/300 |loss: 0.000728| train set 5.442x speedup, test set 5.322x speedup, val set 5.055x speedup, step: 15
Epoch 31/300 |loss: 0.000744| train set 5.491x speedup, test set 5.415x speedup, val set 5.097x speedup, step: 16
Epoch 32/300 |loss: 0.000734| train set 5.489x speedup, test set 5.413x speedup, val set 5.097x speedup, step: 17
Epoch 33/300 |loss: 0.000676| train set 5.497x speedup, test set 5.422x speedup, val set 5.106x speedup, step: 1
Epoch 34/300 |loss: 0.000669| train set 5.497x speedup, test set 5.421x speedup, val set 5.106x speedup, step: 2
Epoch 35/300 |loss: 0.000663| train set 5.447x speedup, test set 5.210x speedup, val set 5.049x speedup, step: 3
Epoch 36/300 |loss: 0.000665| train set 5.494x speedup, test set 5.408x speedup, val set 5.100x speedup, step: 4
Epoch 37/300 |loss: 0.000682| train set 5.489x speedup, test set 5.413x speedup, val set 5.101x speedup, step: 5
Epoch 38/300 |loss: 0.000629| train set 5.494x speedup, test set 5.409x speedup, val set 5.100x speedup, step: 6
Epoch 39/300 |loss: 0.000758| train set 5.490x speedup, test set 5.413x speedup, val set 5.098x speedup, step: 7
Epoch 40/300 |loss: 0.000754| train set 5.450x speedup, test set 5.314x speedup, val set 5.070x speedup, step: 8
early stopping at epoch 40
Training per epoch cost 0.415 s
Optimal speedup on test set is 5.508x
01, opt runtime 18.665s, model runtime 18.665s, pg runtime 18.665s, speedup 1.000x
02, opt runtime 25.356s, model runtime 25.356s, pg runtime 25.356s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 29.763s, model runtime 29.763s, pg runtime 91.648s, speedup 3.079x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 19.263s, model runtime 19.263s, pg runtime 19.263s, speedup 1.000x
07, opt runtime 7.110s, model runtime 7.110s, pg runtime 14.286s, speedup 2.009x
08, opt runtime 7.237s, model runtime 7.237s, pg runtime 17.708s, speedup 2.447x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 25.043s, model runtime 25.043s, pg runtime 73.019s, speedup 2.916x
12, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 2.995s, model runtime 2.995s, pg runtime 14.646s, speedup 4.890x
15, opt runtime 47.518s, model runtime 47.518s, pg runtime 75.736s, speedup 1.594x
16, opt runtime 48.784s, model runtime 48.784s, pg runtime 78.349s, speedup 1.606x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 7.469s, model runtime 7.469s, pg runtime 23.223s, speedup 3.109x
19, opt runtime 1.309s, model runtime 1.356s, pg runtime 1.356s, speedup 1.000x
20, opt runtime 1.340s, model runtime 1.340s, pg runtime 1.340s, speedup 1.000x
21, opt runtime 6.281s, model runtime 6.281s, pg runtime 6.281s, speedup 1.000x
22, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
23, opt runtime 5.961s, model runtime 5.961s, pg runtime 31.210s, speedup 5.236x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.306s, model runtime 1.306s, pg runtime 1.306s, speedup 1.000x
26, opt runtime 1.342s, model runtime 1.342s, pg runtime 1.342s, speedup 1.000x
27, opt runtime 7.066s, model runtime 7.355s, pg runtime 7.533s, speedup 1.024x
28, opt runtime 7.268s, model runtime 7.333s, pg runtime 7.268s, speedup 0.991x
29, opt runtime 5.414s, model runtime 5.414s, pg runtime 5.414s, speedup 1.000x
30, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
31, opt runtime 25.363s, model runtime 25.363s, pg runtime 611.327s, speedup 24.103x
32, opt runtime 24.706s, model runtime 24.706s, pg runtime 610.808s, speedup 24.723x
33, opt runtime 35.538s, model runtime 35.538s, pg runtime 70.116s, speedup 1.973x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 16.138s, model runtime 16.138s, pg runtime 501.793s, speedup 31.094x
36, opt runtime 16.438s, model runtime 16.438s, pg runtime 546.887s, speedup 33.269x
37, opt runtime 15.754s, model runtime 15.754s, pg runtime 15.754s, speedup 1.000x
38, opt runtime 13.961s, model runtime 13.961s, pg runtime 13.961s, speedup 1.000x
39, opt runtime 1.098s, model runtime 1.098s, pg runtime 1.100s, speedup 1.001x
40, opt runtime 1.084s, model runtime 1.084s, pg runtime 1.155s, speedup 1.065x
====================
best train speedup epoch: 34, train speedup 5.497, test speedup 5.421, val speedup 5.106
best test speedup epoch: 33, train speedup 5.497, test speedup 5.422, val speedup 5.106
best validation speedup epoch: 33, train speedup 5.497, test speedup 5.422, val speedup 5.106
last model at epoch 40, train speedup 5.450, test speedup 5.314, val speedup 5.070
execution cost 0:00:40.143267
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1c.sql' '10b.sql' '11b.sql' '12a.sql' '13d.sql' '14c.sql' '15d.sql'
 '16a.sql' '17a.sql' '18a.sql' '19a.sql' '2b.sql' '20b.sql' '21a.sql'
 '22b.sql' '23c.sql' '24a.sql' '25a.sql' '26c.sql' '27a.sql' '28a.sql'
 '29a.sql' '3c.sql' '30b.sql' '31b.sql' '32a.sql' '33a.sql' '4c.sql'
 '5b.sql' '6c.sql' '7a.sql' '8a.sql' '9a.sql']
load JOB succ
load TPCH...
[0, 1, 3, 6, 7, 9] [4, 2] [5, 8]
[0, 3, 6, 7, 8, 9] [5, 1] [2, 4]
[0, 2, 3, 4, 8, 9] [1, 5] [7, 6]
[1, 2, 3, 5, 7, 8] [4, 0] [9, 6]
[0, 3, 4, 7, 8, 9] [1, 6] [2, 5]
[0, 1, 2, 6, 8, 9] [4, 5] [3, 7]
[2, 3, 4, 6, 7, 9] [1, 0] [5, 8]
[0, 2, 3, 6, 7, 9] [4, 1] [5, 8]
[0, 2, 3, 7, 8, 9] [1, 6] [5, 4]
[0, 1, 4, 6, 8, 9] [5, 2] [7, 3]
[0, 2, 5, 7, 8, 9] [3, 4] [1, 6]
[0, 3, 5, 6, 7, 9] [2, 8] [4, 1]
[0, 1, 2, 3, 8, 9] [7, 6] [4, 5]
[0, 1, 2, 4, 5, 9] [8, 3] [6, 7]
[2, 4, 5, 6, 7, 9] [0, 3] [1, 8]
[1, 2, 3, 7, 8, 9] [5, 6] [4, 0]
[0, 1, 2, 6, 8, 9] [3, 5] [4, 7]
[0, 2, 3, 4, 5, 8] [7, 6] [9, 1]
[0, 1, 3, 6, 8, 9] [4, 2] [5, 7]
[0, 1, 2, 3, 6, 7] [8, 9] [4, 5]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.809847, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.049662| train set 2.636x speedup, test set 2.555x speedup, val set 2.435x speedup, step: 1
Epoch 1/300 |loss: 0.020790| train set 2.944x speedup, test set 2.779x speedup, val set 2.627x speedup, step: 1
Epoch 2/300 |loss: 0.010599| train set 3.374x speedup, test set 3.149x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006414| train set 3.841x speedup, test set 3.659x speedup, val set 3.568x speedup, step: 1
Epoch 4/300 |loss: 0.004772| train set 3.593x speedup, test set 3.481x speedup, val set 3.343x speedup, step: 2
Epoch 5/300 |loss: 0.003757| train set 3.418x speedup, test set 3.239x speedup, val set 3.141x speedup, step: 3
Epoch 6/300 |loss: 0.004334| train set 5.306x speedup, test set 5.058x speedup, val set 4.982x speedup, step: 1
Epoch 7/300 |loss: 0.003334| train set 4.966x speedup, test set 4.704x speedup, val set 4.838x speedup, step: 2
Epoch 8/300 |loss: 0.002501| train set 4.015x speedup, test set 3.842x speedup, val set 3.712x speedup, step: 3
Epoch 9/300 |loss: 0.002163| train set 5.278x speedup, test set 4.996x speedup, val set 5.033x speedup, step: 1
Epoch 10/300 |loss: 0.002093| train set 4.657x speedup, test set 4.079x speedup, val set 4.255x speedup, step: 2
Epoch 11/300 |loss: 0.002002| train set 5.344x speedup, test set 5.198x speedup, val set 5.110x speedup, step: 1
Epoch 12/300 |loss: 0.002093| train set 5.188x speedup, test set 5.396x speedup, val set 4.961x speedup, step: 2
Epoch 13/300 |loss: 0.002348| train set 5.169x speedup, test set 5.333x speedup, val set 5.021x speedup, step: 3
Epoch 14/300 |loss: 0.002241| train set 3.704x speedup, test set 3.477x speedup, val set 3.359x speedup, step: 4
Epoch 15/300 |loss: 0.002037| train set 4.854x speedup, test set 5.217x speedup, val set 4.831x speedup, step: 5
Epoch 16/300 |loss: 0.001480| train set 4.948x speedup, test set 5.315x speedup, val set 4.999x speedup, step: 6
Epoch 17/300 |loss: 0.001464| train set 4.177x speedup, test set 3.967x speedup, val set 3.814x speedup, step: 7
Epoch 18/300 |loss: 0.001500| train set 5.442x speedup, test set 5.213x speedup, val set 5.044x speedup, step: 8
Epoch 19/300 |loss: 0.001277| train set 5.450x speedup, test set 5.223x speedup, val set 5.055x speedup, step: 9
Epoch 20/300 |loss: 0.001048| train set 5.208x speedup, test set 5.332x speedup, val set 5.067x speedup, step: 10
Epoch 21/300 |loss: 0.000930| train set 5.247x speedup, test set 5.414x speedup, val set 5.098x speedup, step: 11
Epoch 22/300 |loss: 0.001218| train set 4.655x speedup, test set 4.584x speedup, val set 4.162x speedup, step: 12
Epoch 23/300 |loss: 0.001108| train set 5.495x speedup, test set 5.422x speedup, val set 5.104x speedup, step: 13
Epoch 24/300 |loss: 0.000809| train set 4.970x speedup, test set 5.287x speedup, val set 5.061x speedup, step: 14
Epoch 25/300 |loss: 0.000876| train set 5.485x speedup, test set 5.415x speedup, val set 5.096x speedup, step: 15
Epoch 26/300 |loss: 0.000799| train set 5.446x speedup, test set 5.320x speedup, val set 5.060x speedup, step: 16
Epoch 27/300 |loss: 0.000768| train set 5.495x speedup, test set 5.418x speedup, val set 5.104x speedup, step: 17
Epoch 28/300 |loss: 0.000791| train set 5.400x speedup, test set 5.135x speedup, val set 5.014x speedup, step: 18
Epoch 29/300 |loss: 0.000938| train set 5.459x speedup, test set 5.409x speedup, val set 5.048x speedup, step: 19
Epoch 30/300 |loss: 0.000753| train set 5.497x speedup, test set 5.422x speedup, val set 5.106x speedup, step: 20
Epoch 31/300 |loss: 0.000769| train set 5.495x speedup, test set 5.418x speedup, val set 5.104x speedup, step: 21
Epoch 32/300 |loss: 0.000715| train set 5.489x speedup, test set 5.412x speedup, val set 5.096x speedup, step: 22
Epoch 33/300 |loss: 0.000717| train set 5.497x speedup, test set 5.421x speedup, val set 5.106x speedup, step: 23
Epoch 34/300 |loss: 0.000702| train set 5.449x speedup, test set 5.312x speedup, val set 5.067x speedup, step: 24
Epoch 35/300 |loss: 0.000686| train set 5.448x speedup, test set 5.212x speedup, val set 5.048x speedup, step: 25
Epoch 36/300 |loss: 0.000694| train set 5.497x speedup, test set 5.402x speedup, val set 5.106x speedup, step: 26
Epoch 37/300 |loss: 0.000717| train set 5.440x speedup, test set 5.324x speedup, val set 5.057x speedup, step: 27
Epoch 38/300 |loss: 0.000633| train set 5.481x speedup, test set 5.398x speedup, val set 5.101x speedup, step: 28
Epoch 39/300 |loss: 0.000793| train set 5.491x speedup, test set 5.415x speedup, val set 5.097x speedup, step: 29
Epoch 40/300 |loss: 0.000835| train set 5.451x speedup, test set 5.316x speedup, val set 5.069x speedup, step: 30
early stopping at epoch 40
Training per epoch cost 0.426 s
Optimal speedup on test set is 5.508x
01, opt runtime 18.665s, model runtime 18.665s, pg runtime 18.665s, speedup 1.000x
02, opt runtime 25.356s, model runtime 25.356s, pg runtime 25.356s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 29.763s, model runtime 29.763s, pg runtime 91.648s, speedup 3.079x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 19.263s, model runtime 19.263s, pg runtime 19.263s, speedup 1.000x
07, opt runtime 7.110s, model runtime 7.110s, pg runtime 14.286s, speedup 2.009x
08, opt runtime 7.237s, model runtime 7.237s, pg runtime 17.708s, speedup 2.447x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 25.043s, model runtime 25.043s, pg runtime 73.019s, speedup 2.916x
12, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 2.995s, model runtime 2.995s, pg runtime 14.646s, speedup 4.890x
15, opt runtime 47.518s, model runtime 47.518s, pg runtime 75.736s, speedup 1.594x
16, opt runtime 48.784s, model runtime 48.784s, pg runtime 78.349s, speedup 1.606x
17, opt runtime 10.788s, model runtime 16.078s, pg runtime 32.939s, speedup 2.049x
18, opt runtime 7.469s, model runtime 14.931s, pg runtime 23.223s, speedup 1.555x
19, opt runtime 1.309s, model runtime 1.525s, pg runtime 1.356s, speedup 0.889x
20, opt runtime 1.340s, model runtime 1.540s, pg runtime 1.340s, speedup 0.870x
21, opt runtime 6.281s, model runtime 6.281s, pg runtime 6.281s, speedup 1.000x
22, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
23, opt runtime 5.961s, model runtime 9.875s, pg runtime 31.210s, speedup 3.161x
24, opt runtime 6.234s, model runtime 10.545s, pg runtime 32.540s, speedup 3.086x
25, opt runtime 1.306s, model runtime 1.306s, pg runtime 1.306s, speedup 1.000x
26, opt runtime 1.342s, model runtime 1.342s, pg runtime 1.342s, speedup 1.000x
27, opt runtime 7.066s, model runtime 8.012s, pg runtime 7.533s, speedup 0.940x
28, opt runtime 7.268s, model runtime 7.497s, pg runtime 7.268s, speedup 0.969x
29, opt runtime 5.414s, model runtime 5.414s, pg runtime 5.414s, speedup 1.000x
30, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
31, opt runtime 25.363s, model runtime 25.363s, pg runtime 611.327s, speedup 24.103x
32, opt runtime 24.706s, model runtime 24.706s, pg runtime 610.808s, speedup 24.723x
33, opt runtime 35.538s, model runtime 35.538s, pg runtime 70.116s, speedup 1.973x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 16.138s, model runtime 17.327s, pg runtime 501.793s, speedup 28.960x
36, opt runtime 16.438s, model runtime 19.535s, pg runtime 546.887s, speedup 27.995x
37, opt runtime 15.754s, model runtime 15.754s, pg runtime 15.754s, speedup 1.000x
38, opt runtime 13.961s, model runtime 13.961s, pg runtime 13.961s, speedup 1.000x
39, opt runtime 1.098s, model runtime 1.098s, pg runtime 1.100s, speedup 1.001x
40, opt runtime 1.084s, model runtime 1.084s, pg runtime 1.155s, speedup 1.065x
====================
best train speedup epoch: 36, train speedup 5.497, test speedup 5.402, val speedup 5.106
best test speedup epoch: 30, train speedup 5.497, test speedup 5.422, val speedup 5.106
best validation speedup epoch: 11, train speedup 5.344, test speedup 5.198, val speedup 5.110
last model at epoch 40, train speedup 5.451, test speedup 5.316, val speedup 5.069
execution cost 0:00:40.209121
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1c.sql' '10b.sql' '11b.sql' '12a.sql' '13d.sql' '14c.sql' '15d.sql'
 '16a.sql' '17a.sql' '18a.sql' '19a.sql' '2b.sql' '20b.sql' '21a.sql'
 '22b.sql' '23c.sql' '24a.sql' '25a.sql' '26c.sql' '27a.sql' '28a.sql'
 '29a.sql' '3c.sql' '30b.sql' '31b.sql' '32a.sql' '33a.sql' '4c.sql'
 '5b.sql' '6c.sql' '7a.sql' '8a.sql' '9a.sql']
load JOB succ
load TPCH...
[0, 1, 3, 6, 7, 9] [4, 2] [5, 8]
[0, 3, 6, 7, 8, 9] [5, 1] [2, 4]
[0, 2, 3, 4, 8, 9] [1, 5] [7, 6]
[1, 2, 3, 5, 7, 8] [4, 0] [9, 6]
[0, 3, 4, 7, 8, 9] [1, 6] [2, 5]
[0, 1, 2, 6, 8, 9] [4, 5] [3, 7]
[2, 3, 4, 6, 7, 9] [1, 0] [5, 8]
[0, 2, 3, 6, 7, 9] [4, 1] [5, 8]
[0, 2, 3, 7, 8, 9] [1, 6] [5, 4]
[0, 1, 4, 6, 8, 9] [5, 2] [7, 3]
[0, 2, 5, 7, 8, 9] [3, 4] [1, 6]
[0, 3, 5, 6, 7, 9] [2, 8] [4, 1]
[0, 1, 2, 3, 8, 9] [7, 6] [4, 5]
[0, 1, 2, 4, 5, 9] [8, 3] [6, 7]
[2, 4, 5, 6, 7, 9] [0, 3] [1, 8]
[1, 2, 3, 7, 8, 9] [5, 6] [4, 0]
[0, 1, 2, 6, 8, 9] [3, 5] [4, 7]
[0, 2, 3, 4, 5, 8] [7, 6] [9, 1]
[0, 1, 3, 6, 8, 9] [4, 2] [5, 7]
[0, 1, 2, 3, 6, 7] [8, 9] [4, 5]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.763840, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.049662| train set 2.636x speedup, test set 2.555x speedup, val set 2.435x speedup, step: 1
Epoch 1/300 |loss: 0.020790| train set 2.944x speedup, test set 2.779x speedup, val set 2.627x speedup, step: 1
Epoch 2/300 |loss: 0.010599| train set 3.374x speedup, test set 3.149x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006414| train set 3.841x speedup, test set 3.659x speedup, val set 3.568x speedup, step: 1
Epoch 4/300 |loss: 0.004772| train set 3.593x speedup, test set 3.481x speedup, val set 3.343x speedup, step: 2
Epoch 5/300 |loss: 0.003747| train set 3.600x speedup, test set 3.492x speedup, val set 3.348x speedup, step: 3
Epoch 6/300 |loss: 0.004243| train set 4.736x speedup, test set 4.487x speedup, val set 4.462x speedup, step: 1
Epoch 7/300 |loss: 0.003400| train set 4.965x speedup, test set 4.703x speedup, val set 4.838x speedup, step: 1
Epoch 8/300 |loss: 0.002583| train set 4.015x speedup, test set 3.842x speedup, val set 3.717x speedup, step: 2
Epoch 9/300 |loss: 0.002183| train set 5.272x speedup, test set 5.055x speedup, val set 5.028x speedup, step: 1
Epoch 10/300 |loss: 0.002048| train set 4.928x speedup, test set 5.283x speedup, val set 5.006x speedup, step: 2
Epoch 11/300 |loss: 0.002063| train set 5.380x speedup, test set 5.303x speedup, val set 5.008x speedup, step: 3
Epoch 12/300 |loss: 0.002258| train set 4.957x speedup, test set 5.358x speedup, val set 4.959x speedup, step: 4
Epoch 13/300 |loss: 0.002448| train set 4.971x speedup, test set 5.394x speedup, val set 4.951x speedup, step: 5
Epoch 14/300 |loss: 0.001876| train set 3.704x speedup, test set 3.477x speedup, val set 3.360x speedup, step: 6
Epoch 15/300 |loss: 0.002048| train set 4.853x speedup, test set 5.206x speedup, val set 4.825x speedup, step: 7
Epoch 16/300 |loss: 0.001437| train set 5.177x speedup, test set 5.336x speedup, val set 5.026x speedup, step: 8
Epoch 17/300 |loss: 0.001476| train set 4.220x speedup, test set 4.103x speedup, val set 3.845x speedup, step: 9
Epoch 18/300 |loss: 0.001570| train set 5.491x speedup, test set 5.420x speedup, val set 5.099x speedup, step: 1
Epoch 19/300 |loss: 0.001339| train set 5.488x speedup, test set 5.408x speedup, val set 5.090x speedup, step: 2
Epoch 20/300 |loss: 0.001080| train set 5.448x speedup, test set 5.332x speedup, val set 5.067x speedup, step: 3
Epoch 21/300 |loss: 0.000933| train set 5.031x speedup, test set 5.412x speedup, val set 5.094x speedup, step: 4
Epoch 22/300 |loss: 0.001145| train set 4.909x speedup, test set 5.227x speedup, val set 4.968x speedup, step: 5
Epoch 23/300 |loss: 0.001115| train set 5.249x speedup, test set 5.423x speedup, val set 5.100x speedup, step: 1
Epoch 24/300 |loss: 0.000800| train set 4.934x speedup, test set 5.249x speedup, val set 4.972x speedup, step: 2
Epoch 25/300 |loss: 0.000901| train set 5.485x speedup, test set 5.415x speedup, val set 5.096x speedup, step: 3
Epoch 26/300 |loss: 0.000866| train set 5.445x speedup, test set 5.317x speedup, val set 5.059x speedup, step: 4
Epoch 27/300 |loss: 0.000851| train set 5.495x speedup, test set 5.418x speedup, val set 5.104x speedup, step: 1
Epoch 28/300 |loss: 0.000773| train set 5.443x speedup, test set 5.214x speedup, val set 5.049x speedup, step: 2
Epoch 29/300 |loss: 0.000871| train set 5.443x speedup, test set 5.353x speedup, val set 5.005x speedup, step: 3
Epoch 30/300 |loss: 0.000699| train set 5.448x speedup, test set 5.332x speedup, val set 5.067x speedup, step: 4
Epoch 31/300 |loss: 0.000766| train set 5.495x speedup, test set 5.418x speedup, val set 5.104x speedup, step: 1
Epoch 32/300 |loss: 0.000754| train set 5.497x speedup, test set 5.421x speedup, val set 5.106x speedup, step: 1
Epoch 33/300 |loss: 0.000692| train set 5.497x speedup, test set 5.421x speedup, val set 5.106x speedup, step: 1
Epoch 34/300 |loss: 0.000724| train set 5.496x speedup, test set 5.421x speedup, val set 5.107x speedup, step: 1
Epoch 35/300 |loss: 0.000676| train set 5.449x speedup, test set 5.221x speedup, val set 5.055x speedup, step: 2
Epoch 36/300 |loss: 0.000684| train set 5.496x speedup, test set 5.421x speedup, val set 5.107x speedup, step: 3
Epoch 37/300 |loss: 0.000785| train set 5.447x speedup, test set 5.330x speedup, val set 5.067x speedup, step: 4
Epoch 38/300 |loss: 0.000609| train set 5.495x speedup, test set 5.408x speedup, val set 5.100x speedup, step: 5
Epoch 39/300 |loss: 0.000781| train set 5.491x speedup, test set 5.415x speedup, val set 5.097x speedup, step: 6
Epoch 40/300 |loss: 0.000984| train set 5.450x speedup, test set 5.315x speedup, val set 5.069x speedup, step: 7
early stopping at epoch 40
Training per epoch cost 0.407 s
Optimal speedup on test set is 5.508x
01, opt runtime 18.665s, model runtime 18.665s, pg runtime 18.665s, speedup 1.000x
02, opt runtime 25.356s, model runtime 25.356s, pg runtime 25.356s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 29.763s, model runtime 29.763s, pg runtime 91.648s, speedup 3.079x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 19.263s, model runtime 19.263s, pg runtime 19.263s, speedup 1.000x
07, opt runtime 7.110s, model runtime 7.110s, pg runtime 14.286s, speedup 2.009x
08, opt runtime 7.237s, model runtime 7.237s, pg runtime 17.708s, speedup 2.447x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 25.043s, model runtime 25.043s, pg runtime 73.019s, speedup 2.916x
12, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 2.995s, model runtime 2.995s, pg runtime 14.646s, speedup 4.890x
15, opt runtime 47.518s, model runtime 47.518s, pg runtime 75.736s, speedup 1.594x
16, opt runtime 48.784s, model runtime 48.784s, pg runtime 78.349s, speedup 1.606x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 7.469s, model runtime 7.469s, pg runtime 23.223s, speedup 3.109x
19, opt runtime 1.309s, model runtime 1.309s, pg runtime 1.356s, speedup 1.036x
20, opt runtime 1.340s, model runtime 1.490s, pg runtime 1.340s, speedup 0.899x
21, opt runtime 6.281s, model runtime 6.281s, pg runtime 6.281s, speedup 1.000x
22, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
23, opt runtime 5.961s, model runtime 5.961s, pg runtime 31.210s, speedup 5.236x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.306s, model runtime 1.306s, pg runtime 1.306s, speedup 1.000x
26, opt runtime 1.342s, model runtime 1.342s, pg runtime 1.342s, speedup 1.000x
27, opt runtime 7.066s, model runtime 7.355s, pg runtime 7.533s, speedup 1.024x
28, opt runtime 7.268s, model runtime 7.333s, pg runtime 7.268s, speedup 0.991x
29, opt runtime 5.414s, model runtime 5.414s, pg runtime 5.414s, speedup 1.000x
30, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
31, opt runtime 25.363s, model runtime 25.363s, pg runtime 611.327s, speedup 24.103x
32, opt runtime 24.706s, model runtime 24.706s, pg runtime 610.808s, speedup 24.723x
33, opt runtime 35.538s, model runtime 35.538s, pg runtime 70.116s, speedup 1.973x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 16.138s, model runtime 16.138s, pg runtime 501.793s, speedup 31.094x
36, opt runtime 16.438s, model runtime 16.438s, pg runtime 546.887s, speedup 33.269x
37, opt runtime 15.754s, model runtime 15.754s, pg runtime 15.754s, speedup 1.000x
38, opt runtime 13.961s, model runtime 13.961s, pg runtime 13.961s, speedup 1.000x
39, opt runtime 1.098s, model runtime 1.098s, pg runtime 1.100s, speedup 1.001x
40, opt runtime 1.084s, model runtime 1.084s, pg runtime 1.155s, speedup 1.065x
====================
best train speedup epoch: 32, train speedup 5.497, test speedup 5.421, val speedup 5.106
best test speedup epoch: 23, train speedup 5.249, test speedup 5.423, val speedup 5.100
best validation speedup epoch: 34, train speedup 5.496, test speedup 5.421, val speedup 5.107
last model at epoch 40, train speedup 5.450, test speedup 5.315, val speedup 5.069
execution cost 0:00:40.187497
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1c.sql' '10b.sql' '11b.sql' '12a.sql' '13d.sql' '14c.sql' '15d.sql'
 '16a.sql' '17a.sql' '18a.sql' '19a.sql' '2b.sql' '20b.sql' '21a.sql'
 '22b.sql' '23c.sql' '24a.sql' '25a.sql' '26c.sql' '27a.sql' '28a.sql'
 '29a.sql' '3c.sql' '30b.sql' '31b.sql' '32a.sql' '33a.sql' '4c.sql'
 '5b.sql' '6c.sql' '7a.sql' '8a.sql' '9a.sql']
load JOB succ
load TPCH...
[0, 1, 3, 6, 7, 9] [4, 2] [5, 8]
[0, 3, 6, 7, 8, 9] [5, 1] [2, 4]
[0, 2, 3, 4, 8, 9] [1, 5] [7, 6]
[1, 2, 3, 5, 7, 8] [4, 0] [9, 6]
[0, 3, 4, 7, 8, 9] [1, 6] [2, 5]
[0, 1, 2, 6, 8, 9] [4, 5] [3, 7]
[2, 3, 4, 6, 7, 9] [1, 0] [5, 8]
[0, 2, 3, 6, 7, 9] [4, 1] [5, 8]
[0, 2, 3, 7, 8, 9] [1, 6] [5, 4]
[0, 1, 4, 6, 8, 9] [5, 2] [7, 3]
[0, 2, 5, 7, 8, 9] [3, 4] [1, 6]
[0, 3, 5, 6, 7, 9] [2, 8] [4, 1]
[0, 1, 2, 3, 8, 9] [7, 6] [4, 5]
[0, 1, 2, 4, 5, 9] [8, 3] [6, 7]
[2, 4, 5, 6, 7, 9] [0, 3] [1, 8]
[1, 2, 3, 7, 8, 9] [5, 6] [4, 0]
[0, 1, 2, 6, 8, 9] [3, 5] [4, 7]
[0, 2, 3, 4, 5, 8] [7, 6] [9, 1]
[0, 1, 3, 6, 8, 9] [4, 2] [5, 7]
[0, 1, 2, 3, 6, 7] [8, 9] [4, 5]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.935245, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.049662| train set 2.636x speedup, test set 2.555x speedup, val set 2.435x speedup, step: 1
Epoch 1/300 |loss: 0.020790| train set 2.944x speedup, test set 2.779x speedup, val set 2.627x speedup, step: 1
Epoch 2/300 |loss: 0.010599| train set 3.374x speedup, test set 3.149x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006414| train set 3.841x speedup, test set 3.659x speedup, val set 3.568x speedup, step: 1
Epoch 4/300 |loss: 0.004772| train set 3.593x speedup, test set 3.481x speedup, val set 3.343x speedup, step: 2
Epoch 5/300 |loss: 0.003747| train set 3.600x speedup, test set 3.492x speedup, val set 3.348x speedup, step: 3
Epoch 6/300 |loss: 0.004243| train set 4.736x speedup, test set 4.487x speedup, val set 4.462x speedup, step: 1
Epoch 7/300 |loss: 0.003400| train set 4.965x speedup, test set 4.703x speedup, val set 4.838x speedup, step: 1
Epoch 8/300 |loss: 0.002588| train set 4.015x speedup, test set 3.842x speedup, val set 3.717x speedup, step: 2
Epoch 9/300 |loss: 0.002174| train set 5.274x speedup, test set 4.992x speedup, val set 5.028x speedup, step: 1
Epoch 10/300 |loss: 0.002058| train set 4.721x speedup, test set 4.116x speedup, val set 4.292x speedup, step: 2
Epoch 11/300 |loss: 0.002048| train set 5.365x speedup, test set 5.280x speedup, val set 4.997x speedup, step: 3
Epoch 12/300 |loss: 0.002180| train set 4.977x speedup, test set 5.395x speedup, val set 4.948x speedup, step: 4
Epoch 13/300 |loss: 0.002161| train set 5.096x speedup, test set 5.245x speedup, val set 4.946x speedup, step: 5
Epoch 14/300 |loss: 0.001947| train set 4.560x speedup, test set 4.734x speedup, val set 4.604x speedup, step: 6
Epoch 15/300 |loss: 0.001995| train set 4.163x speedup, test set 4.070x speedup, val set 3.744x speedup, step: 7
Epoch 16/300 |loss: 0.001541| train set 5.180x speedup, test set 5.351x speedup, val set 5.032x speedup, step: 1
Epoch 17/300 |loss: 0.001608| train set 4.007x speedup, test set 3.797x speedup, val set 3.698x speedup, step: 2
Epoch 18/300 |loss: 0.001576| train set 5.445x speedup, test set 5.223x speedup, val set 5.048x speedup, step: 1
Epoch 19/300 |loss: 0.001353| train set 5.419x speedup, test set 5.338x speedup, val set 5.033x speedup, step: 2
Epoch 20/300 |loss: 0.001087| train set 5.448x speedup, test set 5.332x speedup, val set 5.068x speedup, step: 1
Epoch 21/300 |loss: 0.000877| train set 5.247x speedup, test set 5.414x speedup, val set 5.098x speedup, step: 1
Epoch 22/300 |loss: 0.001250| train set 4.856x speedup, test set 5.204x speedup, val set 4.830x speedup, step: 2
Epoch 23/300 |loss: 0.001174| train set 5.246x speedup, test set 5.420x speedup, val set 5.096x speedup, step: 3
Epoch 24/300 |loss: 0.000799| train set 4.976x speedup, test set 5.294x speedup, val set 5.065x speedup, step: 4
Epoch 25/300 |loss: 0.000838| train set 5.492x speedup, test set 5.422x speedup, val set 5.101x speedup, step: 1
Epoch 26/300 |loss: 0.000798| train set 5.347x speedup, test set 5.226x speedup, val set 4.966x speedup, step: 2
Epoch 27/300 |loss: 0.000858| train set 5.495x speedup, test set 5.418x speedup, val set 5.104x speedup, step: 1
Epoch 28/300 |loss: 0.000855| train set 5.424x speedup, test set 5.184x speedup, val set 5.051x speedup, step: 2
Epoch 29/300 |loss: 0.000851| train set 5.495x speedup, test set 5.410x speedup, val set 5.100x speedup, step: 3
Epoch 30/300 |loss: 0.000726| train set 5.447x speedup, test set 5.320x speedup, val set 5.066x speedup, step: 4
Epoch 31/300 |loss: 0.000755| train set 5.495x speedup, test set 5.418x speedup, val set 5.104x speedup, step: 5
Epoch 32/300 |loss: 0.000721| train set 5.491x speedup, test set 5.422x speedup, val set 5.100x speedup, step: 6
Epoch 33/300 |loss: 0.000702| train set 5.497x speedup, test set 5.421x speedup, val set 5.106x speedup, step: 1
Epoch 34/300 |loss: 0.000731| train set 5.448x speedup, test set 5.331x speedup, val set 5.067x speedup, step: 2
Epoch 35/300 |loss: 0.000704| train set 5.495x speedup, test set 5.410x speedup, val set 5.100x speedup, step: 3
Epoch 36/300 |loss: 0.000761| train set 5.445x speedup, test set 5.318x speedup, val set 5.060x speedup, step: 4
Epoch 37/300 |loss: 0.000746| train set 5.441x speedup, test set 5.322x speedup, val set 5.061x speedup, step: 5
Epoch 38/300 |loss: 0.000625| train set 5.496x speedup, test set 5.410x speedup, val set 5.107x speedup, step: 1
Epoch 39/300 |loss: 0.000703| train set 5.492x speedup, test set 5.423x speedup, val set 5.100x speedup, step: 2
Epoch 40/300 |loss: 0.000716| train set 5.450x speedup, test set 5.315x speedup, val set 5.070x speedup, step: 3
Epoch 41/300 |loss: 0.000687| train set 5.492x speedup, test set 5.422x speedup, val set 5.101x speedup, step: 4
Epoch 42/300 |loss: 0.000676| train set 5.497x speedup, test set 5.422x speedup, val set 5.106x speedup, step: 5
Epoch 43/300 |loss: 0.000699| train set 5.412x speedup, test set 5.174x speedup, val set 5.049x speedup, step: 6
Epoch 44/300 |loss: 0.001754| train set 5.352x speedup, test set 5.223x speedup, val set 4.976x speedup, step: 7
Epoch 45/300 |loss: 0.000834| train set 5.498x speedup, test set 5.402x speedup, val set 5.107x speedup, step: 1
early stopping at epoch 45
Training per epoch cost 0.414 s
Optimal speedup on test set is 5.508x
01, opt runtime 18.665s, model runtime 18.665s, pg runtime 18.665s, speedup 1.000x
02, opt runtime 25.356s, model runtime 25.356s, pg runtime 25.356s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 29.763s, model runtime 29.763s, pg runtime 91.648s, speedup 3.079x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 19.263s, model runtime 19.263s, pg runtime 19.263s, speedup 1.000x
07, opt runtime 7.110s, model runtime 7.841s, pg runtime 14.286s, speedup 1.822x
08, opt runtime 7.237s, model runtime 8.427s, pg runtime 17.708s, speedup 2.101x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 25.043s, model runtime 25.043s, pg runtime 73.019s, speedup 2.916x
12, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 2.995s, model runtime 2.995s, pg runtime 14.646s, speedup 4.890x
15, opt runtime 47.518s, model runtime 47.518s, pg runtime 75.736s, speedup 1.594x
16, opt runtime 48.784s, model runtime 48.784s, pg runtime 78.349s, speedup 1.606x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 7.469s, model runtime 7.469s, pg runtime 23.223s, speedup 3.109x
19, opt runtime 1.309s, model runtime 1.453s, pg runtime 1.356s, speedup 0.934x
20, opt runtime 1.340s, model runtime 1.558s, pg runtime 1.340s, speedup 0.860x
21, opt runtime 6.281s, model runtime 6.281s, pg runtime 6.281s, speedup 1.000x
22, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
23, opt runtime 5.961s, model runtime 5.961s, pg runtime 31.210s, speedup 5.236x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.306s, model runtime 1.306s, pg runtime 1.306s, speedup 1.000x
26, opt runtime 1.342s, model runtime 1.342s, pg runtime 1.342s, speedup 1.000x
27, opt runtime 7.066s, model runtime 7.355s, pg runtime 7.533s, speedup 1.024x
28, opt runtime 7.268s, model runtime 7.333s, pg runtime 7.268s, speedup 0.991x
29, opt runtime 5.414s, model runtime 5.414s, pg runtime 5.414s, speedup 1.000x
30, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
31, opt runtime 25.363s, model runtime 25.363s, pg runtime 611.327s, speedup 24.103x
32, opt runtime 24.706s, model runtime 24.706s, pg runtime 610.808s, speedup 24.723x
33, opt runtime 35.538s, model runtime 35.538s, pg runtime 70.116s, speedup 1.973x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 16.138s, model runtime 16.138s, pg runtime 501.793s, speedup 31.094x
36, opt runtime 16.438s, model runtime 16.438s, pg runtime 546.887s, speedup 33.269x
37, opt runtime 15.754s, model runtime 15.754s, pg runtime 15.754s, speedup 1.000x
38, opt runtime 13.961s, model runtime 13.961s, pg runtime 13.961s, speedup 1.000x
39, opt runtime 1.098s, model runtime 1.098s, pg runtime 1.100s, speedup 1.001x
40, opt runtime 1.084s, model runtime 1.084s, pg runtime 1.155s, speedup 1.065x
====================
best train speedup epoch: 45, train speedup 5.498, test speedup 5.402, val speedup 5.107
best test speedup epoch: 39, train speedup 5.492, test speedup 5.423, val speedup 5.100
best validation speedup epoch: 45, train speedup 5.498, test speedup 5.402, val speedup 5.107
last model at epoch 45, train speedup 5.498, test speedup 5.402, val speedup 5.107
execution cost 0:00:44.730808
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1c.sql' '10b.sql' '11b.sql' '12a.sql' '13d.sql' '14c.sql' '15d.sql'
 '16a.sql' '17a.sql' '18a.sql' '19a.sql' '2b.sql' '20b.sql' '21a.sql'
 '22b.sql' '23c.sql' '24a.sql' '25a.sql' '26c.sql' '27a.sql' '28a.sql'
 '29a.sql' '3c.sql' '30b.sql' '31b.sql' '32a.sql' '33a.sql' '4c.sql'
 '5b.sql' '6c.sql' '7a.sql' '8a.sql' '9a.sql']
load JOB succ
load TPCH...
[0, 1, 3, 6, 7, 9] [4, 2] [5, 8]
[0, 3, 6, 7, 8, 9] [5, 1] [2, 4]
[0, 2, 3, 4, 8, 9] [1, 5] [7, 6]
[1, 2, 3, 5, 7, 8] [4, 0] [9, 6]
[0, 3, 4, 7, 8, 9] [1, 6] [2, 5]
[0, 1, 2, 6, 8, 9] [4, 5] [3, 7]
[2, 3, 4, 6, 7, 9] [1, 0] [5, 8]
[0, 2, 3, 6, 7, 9] [4, 1] [5, 8]
[0, 2, 3, 7, 8, 9] [1, 6] [5, 4]
[0, 1, 4, 6, 8, 9] [5, 2] [7, 3]
[0, 2, 5, 7, 8, 9] [3, 4] [1, 6]
[0, 3, 5, 6, 7, 9] [2, 8] [4, 1]
[0, 1, 2, 3, 8, 9] [7, 6] [4, 5]
[0, 1, 2, 4, 5, 9] [8, 3] [6, 7]
[2, 4, 5, 6, 7, 9] [0, 3] [1, 8]
[1, 2, 3, 7, 8, 9] [5, 6] [4, 0]
[0, 1, 2, 6, 8, 9] [3, 5] [4, 7]
[0, 2, 3, 4, 5, 8] [7, 6] [9, 1]
[0, 1, 3, 6, 8, 9] [4, 2] [5, 7]
[0, 1, 2, 3, 6, 7] [8, 9] [4, 5]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.726352, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.049662| train set 2.636x speedup, test set 2.555x speedup, val set 2.435x speedup, step: 1
Epoch 1/300 |loss: 0.020790| train set 2.944x speedup, test set 2.779x speedup, val set 2.627x speedup, step: 1
Epoch 2/300 |loss: 0.010599| train set 3.374x speedup, test set 3.149x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006414| train set 3.841x speedup, test set 3.659x speedup, val set 3.568x speedup, step: 1
Epoch 4/300 |loss: 0.004772| train set 3.593x speedup, test set 3.481x speedup, val set 3.343x speedup, step: 2
Epoch 5/300 |loss: 0.003751| train set 3.395x speedup, test set 3.230x speedup, val set 3.130x speedup, step: 3
Epoch 6/300 |loss: 0.004258| train set 4.718x speedup, test set 4.461x speedup, val set 4.461x speedup, step: 1
Epoch 7/300 |loss: 0.003407| train set 4.971x speedup, test set 4.709x speedup, val set 4.842x speedup, step: 1
Epoch 8/300 |loss: 0.002569| train set 4.019x speedup, test set 3.846x speedup, val set 3.720x speedup, step: 2
Epoch 9/300 |loss: 0.002187| train set 5.378x speedup, test set 5.112x speedup, val set 5.065x speedup, step: 1
Epoch 10/300 |loss: 0.002052| train set 4.374x speedup, test set 4.117x speedup, val set 3.848x speedup, step: 2
Epoch 11/300 |loss: 0.002056| train set 5.359x speedup, test set 5.273x speedup, val set 4.992x speedup, step: 3
Epoch 12/300 |loss: 0.002315| train set 4.957x speedup, test set 5.358x speedup, val set 4.959x speedup, step: 4
Epoch 13/300 |loss: 0.002066| train set 4.909x speedup, test set 5.315x speedup, val set 4.885x speedup, step: 5
Epoch 14/300 |loss: 0.001939| train set 5.007x speedup, test set 4.784x speedup, val set 4.757x speedup, step: 6
Epoch 15/300 |loss: 0.002076| train set 4.887x speedup, test set 5.233x speedup, val set 4.888x speedup, step: 7
Epoch 16/300 |loss: 0.001416| train set 5.216x speedup, test set 5.423x speedup, val set 5.047x speedup, step: 8
Epoch 17/300 |loss: 0.001544| train set 3.989x speedup, test set 3.796x speedup, val set 3.697x speedup, step: 9
Epoch 18/300 |loss: 0.001608| train set 5.444x speedup, test set 5.398x speedup, val set 4.992x speedup, step: 10
Epoch 19/300 |loss: 0.001372| train set 5.472x speedup, test set 5.384x speedup, val set 5.105x speedup, step: 1
Epoch 20/300 |loss: 0.001094| train set 5.448x speedup, test set 5.332x speedup, val set 5.067x speedup, step: 2
Epoch 21/300 |loss: 0.000961| train set 5.031x speedup, test set 5.412x speedup, val set 5.096x speedup, step: 3
Epoch 22/300 |loss: 0.001132| train set 4.428x speedup, test set 4.146x speedup, val set 3.885x speedup, step: 4
Epoch 23/300 |loss: 0.001255| train set 5.496x speedup, test set 5.421x speedup, val set 5.107x speedup, step: 1
Epoch 24/300 |loss: 0.000874| train set 4.955x speedup, test set 5.287x speedup, val set 5.009x speedup, step: 2
Epoch 25/300 |loss: 0.000934| train set 5.454x speedup, test set 5.375x speedup, val set 5.198x speedup, step: 1
Epoch 26/300 |loss: 0.000775| train set 5.447x speedup, test set 5.330x speedup, val set 5.067x speedup, step: 2
Epoch 27/300 |loss: 0.000853| train set 5.495x speedup, test set 5.418x speedup, val set 5.104x speedup, step: 3
Epoch 28/300 |loss: 0.000799| train set 5.348x speedup, test set 5.263x speedup, val set 4.912x speedup, step: 4
Epoch 29/300 |loss: 0.000912| train set 5.395x speedup, test set 5.315x speedup, val set 5.006x speedup, step: 5
Epoch 30/300 |loss: 0.000757| train set 5.448x speedup, test set 5.332x speedup, val set 5.067x speedup, step: 6
Epoch 31/300 |loss: 0.000741| train set 5.495x speedup, test set 5.418x speedup, val set 5.104x speedup, step: 7
Epoch 32/300 |loss: 0.000829| train set 5.489x speedup, test set 5.412x speedup, val set 5.096x speedup, step: 8
Epoch 33/300 |loss: 0.000730| train set 5.491x speedup, test set 5.415x speedup, val set 5.097x speedup, step: 9
Epoch 34/300 |loss: 0.000711| train set 5.405x speedup, test set 5.309x speedup, val set 5.016x speedup, step: 10
Epoch 35/300 |loss: 0.000684| train set 5.447x speedup, test set 5.210x speedup, val set 5.049x speedup, step: 11
Epoch 36/300 |loss: 0.000654| train set 5.495x speedup, test set 5.420x speedup, val set 5.106x speedup, step: 12
Epoch 37/300 |loss: 0.000699| train set 5.483x speedup, test set 5.407x speedup, val set 5.092x speedup, step: 13
Epoch 38/300 |loss: 0.000625| train set 5.492x speedup, test set 5.422x speedup, val set 5.099x speedup, step: 14
Epoch 39/300 |loss: 0.000770| train set 5.491x speedup, test set 5.415x speedup, val set 5.097x speedup, step: 15
Epoch 40/300 |loss: 0.000930| train set 5.449x speedup, test set 5.332x speedup, val set 5.076x speedup, step: 16
early stopping at epoch 40
Training per epoch cost 0.428 s
Optimal speedup on test set is 5.508x
01, opt runtime 18.665s, model runtime 18.665s, pg runtime 18.665s, speedup 1.000x
02, opt runtime 25.356s, model runtime 25.356s, pg runtime 25.356s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 29.763s, model runtime 29.763s, pg runtime 91.648s, speedup 3.079x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 19.263s, model runtime 19.263s, pg runtime 19.263s, speedup 1.000x
07, opt runtime 7.110s, model runtime 7.110s, pg runtime 14.286s, speedup 2.009x
08, opt runtime 7.237s, model runtime 7.237s, pg runtime 17.708s, speedup 2.447x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 25.043s, model runtime 25.043s, pg runtime 73.019s, speedup 2.916x
12, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 2.995s, model runtime 2.995s, pg runtime 14.646s, speedup 4.890x
15, opt runtime 47.518s, model runtime 47.518s, pg runtime 75.736s, speedup 1.594x
16, opt runtime 48.784s, model runtime 48.784s, pg runtime 78.349s, speedup 1.606x
17, opt runtime 10.788s, model runtime 16.078s, pg runtime 32.939s, speedup 2.049x
18, opt runtime 7.469s, model runtime 7.469s, pg runtime 23.223s, speedup 3.109x
19, opt runtime 1.309s, model runtime 1.309s, pg runtime 1.356s, speedup 1.036x
20, opt runtime 1.340s, model runtime 1.490s, pg runtime 1.340s, speedup 0.899x
21, opt runtime 6.281s, model runtime 6.281s, pg runtime 6.281s, speedup 1.000x
22, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
23, opt runtime 5.961s, model runtime 5.961s, pg runtime 31.210s, speedup 5.236x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.306s, model runtime 1.306s, pg runtime 1.306s, speedup 1.000x
26, opt runtime 1.342s, model runtime 1.342s, pg runtime 1.342s, speedup 1.000x
27, opt runtime 7.066s, model runtime 7.066s, pg runtime 7.533s, speedup 1.066x
28, opt runtime 7.268s, model runtime 7.507s, pg runtime 7.268s, speedup 0.968x
29, opt runtime 5.414s, model runtime 5.414s, pg runtime 5.414s, speedup 1.000x
30, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
31, opt runtime 25.363s, model runtime 25.363s, pg runtime 611.327s, speedup 24.103x
32, opt runtime 24.706s, model runtime 24.706s, pg runtime 610.808s, speedup 24.723x
33, opt runtime 35.538s, model runtime 35.538s, pg runtime 70.116s, speedup 1.973x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 16.138s, model runtime 16.138s, pg runtime 501.793s, speedup 31.094x
36, opt runtime 16.438s, model runtime 16.438s, pg runtime 546.887s, speedup 33.269x
37, opt runtime 15.754s, model runtime 15.754s, pg runtime 15.754s, speedup 1.000x
38, opt runtime 13.961s, model runtime 13.961s, pg runtime 13.961s, speedup 1.000x
39, opt runtime 1.098s, model runtime 1.100s, pg runtime 1.100s, speedup 1.000x
40, opt runtime 1.084s, model runtime 1.155s, pg runtime 1.155s, speedup 1.000x
====================
best train speedup epoch: 23, train speedup 5.496, test speedup 5.421, val speedup 5.107
best test speedup epoch: 16, train speedup 5.216, test speedup 5.423, val speedup 5.047
best validation speedup epoch: 25, train speedup 5.454, test speedup 5.375, val speedup 5.198
last model at epoch 40, train speedup 5.449, test speedup 5.332, val speedup 5.076
execution cost 0:00:40.452408
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1c.sql' '10b.sql' '11b.sql' '12a.sql' '13d.sql' '14c.sql' '15d.sql'
 '16a.sql' '17a.sql' '18a.sql' '19a.sql' '2b.sql' '20b.sql' '21a.sql'
 '22b.sql' '23c.sql' '24a.sql' '25a.sql' '26c.sql' '27a.sql' '28a.sql'
 '29a.sql' '3c.sql' '30b.sql' '31b.sql' '32a.sql' '33a.sql' '4c.sql'
 '5b.sql' '6c.sql' '7a.sql' '8a.sql' '9a.sql']
load JOB succ
load TPCH...
[0, 1, 3, 6, 7, 9] [4, 2] [5, 8]
[0, 3, 6, 7, 8, 9] [5, 1] [2, 4]
[0, 2, 3, 4, 8, 9] [1, 5] [7, 6]
[1, 2, 3, 5, 7, 8] [4, 0] [9, 6]
[0, 3, 4, 7, 8, 9] [1, 6] [2, 5]
[0, 1, 2, 6, 8, 9] [4, 5] [3, 7]
[2, 3, 4, 6, 7, 9] [1, 0] [5, 8]
[0, 2, 3, 6, 7, 9] [4, 1] [5, 8]
[0, 2, 3, 7, 8, 9] [1, 6] [5, 4]
[0, 1, 4, 6, 8, 9] [5, 2] [7, 3]
[0, 2, 5, 7, 8, 9] [3, 4] [1, 6]
[0, 3, 5, 6, 7, 9] [2, 8] [4, 1]
[0, 1, 2, 3, 8, 9] [7, 6] [4, 5]
[0, 1, 2, 4, 5, 9] [8, 3] [6, 7]
[2, 4, 5, 6, 7, 9] [0, 3] [1, 8]
[1, 2, 3, 7, 8, 9] [5, 6] [4, 0]
[0, 1, 2, 6, 8, 9] [3, 5] [4, 7]
[0, 2, 3, 4, 5, 8] [7, 6] [9, 1]
[0, 1, 3, 6, 8, 9] [4, 2] [5, 7]
[0, 1, 2, 3, 6, 7] [8, 9] [4, 5]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.782660, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.049662| train set 2.636x speedup, test set 2.555x speedup, val set 2.435x speedup, step: 1
Epoch 1/300 |loss: 0.020790| train set 2.944x speedup, test set 2.779x speedup, val set 2.627x speedup, step: 1
Epoch 2/300 |loss: 0.010599| train set 3.374x speedup, test set 3.149x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006414| train set 3.841x speedup, test set 3.659x speedup, val set 3.568x speedup, step: 1
Epoch 4/300 |loss: 0.004772| train set 3.593x speedup, test set 3.481x speedup, val set 3.343x speedup, step: 2
Epoch 5/300 |loss: 0.003758| train set 3.477x speedup, test set 3.492x speedup, val set 3.238x speedup, step: 3
Epoch 6/300 |loss: 0.004067| train set 4.662x speedup, test set 4.421x speedup, val set 4.390x speedup, step: 1
Epoch 7/300 |loss: 0.003615| train set 4.965x speedup, test set 4.703x speedup, val set 4.838x speedup, step: 1
Epoch 8/300 |loss: 0.002747| train set 4.012x speedup, test set 3.839x speedup, val set 3.714x speedup, step: 2
Epoch 9/300 |loss: 0.002212| train set 5.365x speedup, test set 5.071x speedup, val set 5.121x speedup, step: 1
Epoch 10/300 |loss: 0.002082| train set 4.721x speedup, test set 4.645x speedup, val set 4.292x speedup, step: 2
Epoch 11/300 |loss: 0.002098| train set 5.395x speedup, test set 5.310x speedup, val set 5.033x speedup, step: 3
Epoch 12/300 |loss: 0.002533| train set 4.957x speedup, test set 5.358x speedup, val set 4.959x speedup, step: 4
Epoch 13/300 |loss: 0.001697| train set 4.889x speedup, test set 5.229x speedup, val set 4.884x speedup, step: 5
Epoch 14/300 |loss: 0.002014| train set 5.024x speedup, test set 4.818x speedup, val set 4.746x speedup, step: 6
Epoch 15/300 |loss: 0.002047| train set 4.541x speedup, test set 4.104x speedup, val set 3.846x speedup, step: 7
Epoch 16/300 |loss: 0.001531| train set 5.184x speedup, test set 5.349x speedup, val set 5.038x speedup, step: 8
Epoch 17/300 |loss: 0.001517| train set 3.976x speedup, test set 3.784x speedup, val set 3.682x speedup, step: 9
Epoch 18/300 |loss: 0.001597| train set 5.492x speedup, test set 5.423x speedup, val set 5.100x speedup, step: 10
Epoch 19/300 |loss: 0.001328| train set 5.470x speedup, test set 5.421x speedup, val set 5.071x speedup, step: 11
Epoch 20/300 |loss: 0.001014| train set 5.446x speedup, test set 5.329x speedup, val set 5.064x speedup, step: 12
Epoch 21/300 |loss: 0.000893| train set 5.247x speedup, test set 5.415x speedup, val set 5.097x speedup, step: 13
Epoch 22/300 |loss: 0.000981| train set 4.995x speedup, test set 5.320x speedup, val set 5.061x speedup, step: 14
Epoch 23/300 |loss: 0.000902| train set 5.488x speedup, test set 5.402x speedup, val set 5.092x speedup, step: 15
Epoch 24/300 |loss: 0.000826| train set 4.996x speedup, test set 5.329x speedup, val set 5.066x speedup, step: 16
Epoch 25/300 |loss: 0.000949| train set 5.494x speedup, test set 5.409x speedup, val set 5.101x speedup, step: 17
Epoch 26/300 |loss: 0.000909| train set 5.446x speedup, test set 5.320x speedup, val set 5.062x speedup, step: 18
Epoch 27/300 |loss: 0.000815| train set 5.496x speedup, test set 5.420x speedup, val set 5.106x speedup, step: 19
Epoch 28/300 |loss: 0.000804| train set 5.412x speedup, test set 5.252x speedup, val set 5.051x speedup, step: 20
Epoch 29/300 |loss: 0.001109| train set 5.493x speedup, test set 5.408x speedup, val set 5.100x speedup, step: 21
Epoch 30/300 |loss: 0.000827| train set 5.497x speedup, test set 5.422x speedup, val set 5.106x speedup, step: 22
Epoch 31/300 |loss: 0.000714| train set 5.493x speedup, test set 5.407x speedup, val set 5.098x speedup, step: 23
Epoch 32/300 |loss: 0.000774| train set 5.489x speedup, test set 5.412x speedup, val set 5.096x speedup, step: 24
Epoch 33/300 |loss: 0.000726| train set 5.497x speedup, test set 5.421x speedup, val set 5.106x speedup, step: 25
Epoch 34/300 |loss: 0.000672| train set 5.448x speedup, test set 5.331x speedup, val set 5.067x speedup, step: 26
Epoch 35/300 |loss: 0.000660| train set 5.494x speedup, test set 5.410x speedup, val set 5.099x speedup, step: 27
Epoch 36/300 |loss: 0.000708| train set 5.446x speedup, test set 5.319x speedup, val set 5.058x speedup, step: 28
Epoch 37/300 |loss: 0.000697| train set 5.451x speedup, test set 5.316x speedup, val set 5.069x speedup, step: 29
Epoch 38/300 |loss: 0.000608| train set 5.485x speedup, test set 5.391x speedup, val set 5.091x speedup, step: 30
Epoch 39/300 |loss: 0.000710| train set 5.492x speedup, test set 5.423x speedup, val set 5.100x speedup, step: 31
Epoch 40/300 |loss: 0.000774| train set 5.448x speedup, test set 5.320x speedup, val set 5.058x speedup, step: 32
Epoch 41/300 |loss: 0.000658| train set 5.496x speedup, test set 5.421x speedup, val set 5.107x speedup, step: 33
Epoch 42/300 |loss: 0.000713| train set 5.491x speedup, test set 5.415x speedup, val set 5.097x speedup, step: 34
Epoch 43/300 |loss: 0.000730| train set 5.490x speedup, test set 5.411x speedup, val set 5.093x speedup, step: 35
early stopping at epoch 43
Training per epoch cost 0.402 s
Optimal speedup on test set is 5.508x
01, opt runtime 18.665s, model runtime 18.665s, pg runtime 18.665s, speedup 1.000x
02, opt runtime 25.356s, model runtime 25.356s, pg runtime 25.356s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 29.763s, model runtime 29.763s, pg runtime 91.648s, speedup 3.079x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 19.263s, model runtime 19.263s, pg runtime 19.263s, speedup 1.000x
07, opt runtime 7.110s, model runtime 7.110s, pg runtime 14.286s, speedup 2.009x
08, opt runtime 7.237s, model runtime 7.237s, pg runtime 17.708s, speedup 2.447x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 25.043s, model runtime 25.043s, pg runtime 73.019s, speedup 2.916x
12, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 2.995s, model runtime 2.995s, pg runtime 14.646s, speedup 4.890x
15, opt runtime 47.518s, model runtime 47.518s, pg runtime 75.736s, speedup 1.594x
16, opt runtime 48.784s, model runtime 48.784s, pg runtime 78.349s, speedup 1.606x
17, opt runtime 10.788s, model runtime 16.078s, pg runtime 32.939s, speedup 2.049x
18, opt runtime 7.469s, model runtime 14.931s, pg runtime 23.223s, speedup 1.555x
19, opt runtime 1.309s, model runtime 1.525s, pg runtime 1.356s, speedup 0.889x
20, opt runtime 1.340s, model runtime 1.540s, pg runtime 1.340s, speedup 0.870x
21, opt runtime 6.281s, model runtime 22.977s, pg runtime 6.281s, speedup 0.273x
22, opt runtime 25.034s, model runtime 31.752s, pg runtime 25.034s, speedup 0.788x
23, opt runtime 5.961s, model runtime 5.961s, pg runtime 31.210s, speedup 5.236x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.306s, model runtime 1.306s, pg runtime 1.306s, speedup 1.000x
26, opt runtime 1.342s, model runtime 1.342s, pg runtime 1.342s, speedup 1.000x
27, opt runtime 7.066s, model runtime 8.012s, pg runtime 7.533s, speedup 0.940x
28, opt runtime 7.268s, model runtime 7.497s, pg runtime 7.268s, speedup 0.969x
29, opt runtime 5.414s, model runtime 5.780s, pg runtime 5.414s, speedup 0.937x
30, opt runtime 5.572s, model runtime 5.971s, pg runtime 5.572s, speedup 0.933x
31, opt runtime 25.363s, model runtime 25.363s, pg runtime 611.327s, speedup 24.103x
32, opt runtime 24.706s, model runtime 24.706s, pg runtime 610.808s, speedup 24.723x
33, opt runtime 35.538s, model runtime 35.538s, pg runtime 70.116s, speedup 1.973x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 16.138s, model runtime 17.327s, pg runtime 501.793s, speedup 28.960x
36, opt runtime 16.438s, model runtime 19.535s, pg runtime 546.887s, speedup 27.995x
37, opt runtime 15.754s, model runtime 15.754s, pg runtime 15.754s, speedup 1.000x
38, opt runtime 13.961s, model runtime 13.961s, pg runtime 13.961s, speedup 1.000x
39, opt runtime 1.098s, model runtime 1.098s, pg runtime 1.100s, speedup 1.001x
40, opt runtime 1.084s, model runtime 1.084s, pg runtime 1.155s, speedup 1.065x
====================
best train speedup epoch: 33, train speedup 5.497, test speedup 5.421, val speedup 5.106
best test speedup epoch: 18, train speedup 5.492, test speedup 5.423, val speedup 5.100
best validation speedup epoch: 9, train speedup 5.365, test speedup 5.071, val speedup 5.121
last model at epoch 43, train speedup 5.490, test speedup 5.411, val speedup 5.093
execution cost 0:00:42.372377
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1c.sql' '10b.sql' '11b.sql' '12a.sql' '13d.sql' '14c.sql' '15d.sql'
 '16a.sql' '17a.sql' '18a.sql' '19a.sql' '2b.sql' '20b.sql' '21a.sql'
 '22b.sql' '23c.sql' '24a.sql' '25a.sql' '26c.sql' '27a.sql' '28a.sql'
 '29a.sql' '3c.sql' '30b.sql' '31b.sql' '32a.sql' '33a.sql' '4c.sql'
 '5b.sql' '6c.sql' '7a.sql' '8a.sql' '9a.sql']
load JOB succ
load TPCH...
[0, 1, 3, 6, 7, 9] [4, 2] [5, 8]
[0, 3, 6, 7, 8, 9] [5, 1] [2, 4]
[0, 2, 3, 4, 8, 9] [1, 5] [7, 6]
[1, 2, 3, 5, 7, 8] [4, 0] [9, 6]
[0, 3, 4, 7, 8, 9] [1, 6] [2, 5]
[0, 1, 2, 6, 8, 9] [4, 5] [3, 7]
[2, 3, 4, 6, 7, 9] [1, 0] [5, 8]
[0, 2, 3, 6, 7, 9] [4, 1] [5, 8]
[0, 2, 3, 7, 8, 9] [1, 6] [5, 4]
[0, 1, 4, 6, 8, 9] [5, 2] [7, 3]
[0, 2, 5, 7, 8, 9] [3, 4] [1, 6]
[0, 3, 5, 6, 7, 9] [2, 8] [4, 1]
[0, 1, 2, 3, 8, 9] [7, 6] [4, 5]
[0, 1, 2, 4, 5, 9] [8, 3] [6, 7]
[2, 4, 5, 6, 7, 9] [0, 3] [1, 8]
[1, 2, 3, 7, 8, 9] [5, 6] [4, 0]
[0, 1, 2, 6, 8, 9] [3, 5] [4, 7]
[0, 2, 3, 4, 5, 8] [7, 6] [9, 1]
[0, 1, 3, 6, 8, 9] [4, 2] [5, 7]
[0, 1, 2, 3, 6, 7] [8, 9] [4, 5]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.740521, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.049662| train set 2.636x speedup, test set 2.555x speedup, val set 2.435x speedup, step: 1
Epoch 1/300 |loss: 0.020790| train set 2.944x speedup, test set 2.779x speedup, val set 2.627x speedup, step: 1
Epoch 2/300 |loss: 0.010599| train set 3.374x speedup, test set 3.149x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006414| train set 3.841x speedup, test set 3.659x speedup, val set 3.568x speedup, step: 1
Epoch 4/300 |loss: 0.004772| train set 3.593x speedup, test set 3.481x speedup, val set 3.343x speedup, step: 2
Epoch 5/300 |loss: 0.003753| train set 3.429x speedup, test set 3.230x speedup, val set 3.130x speedup, step: 3
Epoch 6/300 |loss: 0.004355| train set 5.306x speedup, test set 5.058x speedup, val set 4.982x speedup, step: 1
Epoch 7/300 |loss: 0.003335| train set 4.966x speedup, test set 4.704x speedup, val set 4.838x speedup, step: 2
Epoch 8/300 |loss: 0.002572| train set 4.014x speedup, test set 3.841x speedup, val set 3.716x speedup, step: 3
Epoch 9/300 |loss: 0.002179| train set 5.211x speedup, test set 4.972x speedup, val set 4.888x speedup, step: 4
Epoch 10/300 |loss: 0.002095| train set 4.374x speedup, test set 4.116x speedup, val set 3.848x speedup, step: 5
Epoch 11/300 |loss: 0.002102| train set 5.352x speedup, test set 5.207x speedup, val set 5.122x speedup, step: 1
Epoch 12/300 |loss: 0.002373| train set 5.187x speedup, test set 5.395x speedup, val set 4.960x speedup, step: 2
Epoch 13/300 |loss: 0.001865| train set 5.426x speedup, test set 5.396x speedup, val set 4.960x speedup, step: 3
Epoch 14/300 |loss: 0.001963| train set 4.310x speedup, test set 3.492x speedup, val set 3.937x speedup, step: 4
Epoch 15/300 |loss: 0.002065| train set 4.682x speedup, test set 4.118x speedup, val set 4.182x speedup, step: 5
Epoch 16/300 |loss: 0.001650| train set 5.393x speedup, test set 5.311x speedup, val set 5.001x speedup, step: 6
Epoch 17/300 |loss: 0.001499| train set 4.192x speedup, test set 3.988x speedup, val set 3.815x speedup, step: 7
Epoch 18/300 |loss: 0.001524| train set 5.444x speedup, test set 5.221x speedup, val set 5.047x speedup, step: 8
Epoch 19/300 |loss: 0.001215| train set 5.469x speedup, test set 5.381x speedup, val set 5.100x speedup, step: 9
Epoch 20/300 |loss: 0.001043| train set 5.448x speedup, test set 5.332x speedup, val set 5.067x speedup, step: 10
Epoch 21/300 |loss: 0.000868| train set 5.032x speedup, test set 5.413x speedup, val set 5.097x speedup, step: 11
Epoch 22/300 |loss: 0.001256| train set 4.704x speedup, test set 4.663x speedup, val set 4.196x speedup, step: 12
Epoch 23/300 |loss: 0.001038| train set 5.252x speedup, test set 5.421x speedup, val set 5.107x speedup, step: 13
Epoch 24/300 |loss: 0.000757| train set 4.991x speedup, test set 5.323x speedup, val set 5.063x speedup, step: 14
Epoch 25/300 |loss: 0.000842| train set 5.485x speedup, test set 5.415x speedup, val set 5.096x speedup, step: 15
Epoch 26/300 |loss: 0.000812| train set 5.421x speedup, test set 5.283x speedup, val set 5.060x speedup, step: 16
Epoch 27/300 |loss: 0.000781| train set 5.495x speedup, test set 5.418x speedup, val set 5.104x speedup, step: 17
Epoch 28/300 |loss: 0.000809| train set 5.377x speedup, test set 5.102x speedup, val set 5.013x speedup, step: 18
Epoch 29/300 |loss: 0.000812| train set 5.494x speedup, test set 5.409x speedup, val set 5.100x speedup, step: 19
Epoch 30/300 |loss: 0.000757| train set 5.443x speedup, test set 5.333x speedup, val set 5.062x speedup, step: 20
Epoch 31/300 |loss: 0.000758| train set 5.495x speedup, test set 5.418x speedup, val set 5.104x speedup, step: 21
Epoch 32/300 |loss: 0.000789| train set 5.486x speedup, test set 5.416x speedup, val set 5.095x speedup, step: 22
Epoch 33/300 |loss: 0.000730| train set 5.497x speedup, test set 5.421x speedup, val set 5.106x speedup, step: 23
Epoch 34/300 |loss: 0.000808| train set 5.450x speedup, test set 5.331x speedup, val set 5.076x speedup, step: 24
Epoch 35/300 |loss: 0.000714| train set 5.496x speedup, test set 5.421x speedup, val set 5.107x speedup, step: 25
Epoch 36/300 |loss: 0.000687| train set 5.495x speedup, test set 5.419x speedup, val set 5.105x speedup, step: 26
Epoch 37/300 |loss: 0.000702| train set 5.442x speedup, test set 5.325x speedup, val set 5.062x speedup, step: 27
Epoch 38/300 |loss: 0.000634| train set 5.491x speedup, test set 5.417x speedup, val set 5.117x speedup, step: 28
Epoch 39/300 |loss: 0.000750| train set 5.492x speedup, test set 5.423x speedup, val set 5.100x speedup, step: 29
Epoch 40/300 |loss: 0.000797| train set 5.451x speedup, test set 5.316x speedup, val set 5.069x speedup, step: 30
Epoch 41/300 |loss: 0.000668| train set 5.491x speedup, test set 5.422x speedup, val set 5.100x speedup, step: 31
Epoch 42/300 |loss: 0.000692| train set 5.491x speedup, test set 5.415x speedup, val set 5.097x speedup, step: 32
Epoch 43/300 |loss: 0.000691| train set 5.418x speedup, test set 5.172x speedup, val set 5.055x speedup, step: 33
Epoch 44/300 |loss: 0.001810| train set 5.346x speedup, test set 5.220x speedup, val set 4.986x speedup, step: 34
Epoch 45/300 |loss: 0.000874| train set 5.498x speedup, test set 5.402x speedup, val set 5.107x speedup, step: 35
early stopping at epoch 45
Training per epoch cost 0.399 s
Optimal speedup on test set is 5.508x
01, opt runtime 18.665s, model runtime 18.665s, pg runtime 18.665s, speedup 1.000x
02, opt runtime 25.356s, model runtime 25.356s, pg runtime 25.356s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 29.763s, model runtime 29.763s, pg runtime 91.648s, speedup 3.079x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 19.263s, model runtime 19.263s, pg runtime 19.263s, speedup 1.000x
07, opt runtime 7.110s, model runtime 7.110s, pg runtime 14.286s, speedup 2.009x
08, opt runtime 7.237s, model runtime 7.237s, pg runtime 17.708s, speedup 2.447x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 25.043s, model runtime 25.043s, pg runtime 73.019s, speedup 2.916x
12, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 2.995s, model runtime 2.995s, pg runtime 14.646s, speedup 4.890x
15, opt runtime 47.518s, model runtime 47.518s, pg runtime 75.736s, speedup 1.594x
16, opt runtime 48.784s, model runtime 48.784s, pg runtime 78.349s, speedup 1.606x
17, opt runtime 10.788s, model runtime 16.078s, pg runtime 32.939s, speedup 2.049x
18, opt runtime 7.469s, model runtime 14.931s, pg runtime 23.223s, speedup 1.555x
19, opt runtime 1.309s, model runtime 1.356s, pg runtime 1.356s, speedup 1.000x
20, opt runtime 1.340s, model runtime 1.340s, pg runtime 1.340s, speedup 1.000x
21, opt runtime 6.281s, model runtime 6.281s, pg runtime 6.281s, speedup 1.000x
22, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
23, opt runtime 5.961s, model runtime 9.875s, pg runtime 31.210s, speedup 3.161x
24, opt runtime 6.234s, model runtime 10.545s, pg runtime 32.540s, speedup 3.086x
25, opt runtime 1.306s, model runtime 1.306s, pg runtime 1.306s, speedup 1.000x
26, opt runtime 1.342s, model runtime 1.342s, pg runtime 1.342s, speedup 1.000x
27, opt runtime 7.066s, model runtime 7.355s, pg runtime 7.533s, speedup 1.024x
28, opt runtime 7.268s, model runtime 7.333s, pg runtime 7.268s, speedup 0.991x
29, opt runtime 5.414s, model runtime 5.414s, pg runtime 5.414s, speedup 1.000x
30, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
31, opt runtime 25.363s, model runtime 25.363s, pg runtime 611.327s, speedup 24.103x
32, opt runtime 24.706s, model runtime 24.706s, pg runtime 610.808s, speedup 24.723x
33, opt runtime 35.538s, model runtime 35.538s, pg runtime 70.116s, speedup 1.973x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 16.138s, model runtime 17.327s, pg runtime 501.793s, speedup 28.960x
36, opt runtime 16.438s, model runtime 19.535s, pg runtime 546.887s, speedup 27.995x
37, opt runtime 15.754s, model runtime 15.754s, pg runtime 15.754s, speedup 1.000x
38, opt runtime 13.961s, model runtime 13.961s, pg runtime 13.961s, speedup 1.000x
39, opt runtime 1.098s, model runtime 1.100s, pg runtime 1.100s, speedup 1.000x
40, opt runtime 1.084s, model runtime 1.155s, pg runtime 1.155s, speedup 1.000x
====================
best train speedup epoch: 45, train speedup 5.498, test speedup 5.402, val speedup 5.107
best test speedup epoch: 39, train speedup 5.492, test speedup 5.423, val speedup 5.100
best validation speedup epoch: 11, train speedup 5.352, test speedup 5.207, val speedup 5.122
last model at epoch 45, train speedup 5.498, test speedup 5.402, val speedup 5.107
execution cost 0:00:44.091738
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1c.sql' '10b.sql' '11b.sql' '12a.sql' '13d.sql' '14c.sql' '15d.sql'
 '16a.sql' '17a.sql' '18a.sql' '19a.sql' '2b.sql' '20b.sql' '21a.sql'
 '22b.sql' '23c.sql' '24a.sql' '25a.sql' '26c.sql' '27a.sql' '28a.sql'
 '29a.sql' '3c.sql' '30b.sql' '31b.sql' '32a.sql' '33a.sql' '4c.sql'
 '5b.sql' '6c.sql' '7a.sql' '8a.sql' '9a.sql']
load JOB succ
load TPCH...
[0, 1, 3, 6, 7, 9] [4, 2] [5, 8]
[0, 3, 6, 7, 8, 9] [5, 1] [2, 4]
[0, 2, 3, 4, 8, 9] [1, 5] [7, 6]
[1, 2, 3, 5, 7, 8] [4, 0] [9, 6]
[0, 3, 4, 7, 8, 9] [1, 6] [2, 5]
[0, 1, 2, 6, 8, 9] [4, 5] [3, 7]
[2, 3, 4, 6, 7, 9] [1, 0] [5, 8]
[0, 2, 3, 6, 7, 9] [4, 1] [5, 8]
[0, 2, 3, 7, 8, 9] [1, 6] [5, 4]
[0, 1, 4, 6, 8, 9] [5, 2] [7, 3]
[0, 2, 5, 7, 8, 9] [3, 4] [1, 6]
[0, 3, 5, 6, 7, 9] [2, 8] [4, 1]
[0, 1, 2, 3, 8, 9] [7, 6] [4, 5]
[0, 1, 2, 4, 5, 9] [8, 3] [6, 7]
[2, 4, 5, 6, 7, 9] [0, 3] [1, 8]
[1, 2, 3, 7, 8, 9] [5, 6] [4, 0]
[0, 1, 2, 6, 8, 9] [3, 5] [4, 7]
[0, 2, 3, 4, 5, 8] [7, 6] [9, 1]
[0, 1, 3, 6, 8, 9] [4, 2] [5, 7]
[0, 1, 2, 3, 6, 7] [8, 9] [4, 5]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.759064, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.049662| train set 2.636x speedup, test set 2.555x speedup, val set 2.435x speedup, step: 1
Epoch 1/300 |loss: 0.020790| train set 2.944x speedup, test set 2.779x speedup, val set 2.627x speedup, step: 1
Epoch 2/300 |loss: 0.010599| train set 3.374x speedup, test set 3.149x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006414| train set 3.841x speedup, test set 3.659x speedup, val set 3.568x speedup, step: 1
Epoch 4/300 |loss: 0.004772| train set 3.593x speedup, test set 3.481x speedup, val set 3.343x speedup, step: 2
Epoch 5/300 |loss: 0.003750| train set 3.395x speedup, test set 3.230x speedup, val set 3.130x speedup, step: 3
Epoch 6/300 |loss: 0.004294| train set 4.866x speedup, test set 4.636x speedup, val set 4.631x speedup, step: 1
Epoch 7/300 |loss: 0.003372| train set 4.969x speedup, test set 4.706x speedup, val set 4.839x speedup, step: 1
Epoch 8/300 |loss: 0.002517| train set 4.015x speedup, test set 3.842x speedup, val set 3.719x speedup, step: 2
Epoch 9/300 |loss: 0.002183| train set 5.295x speedup, test set 5.022x speedup, val set 5.031x speedup, step: 1
Epoch 10/300 |loss: 0.002047| train set 4.216x speedup, test set 4.117x speedup, val set 3.848x speedup, step: 2
Epoch 11/300 |loss: 0.002044| train set 5.395x speedup, test set 5.310x speedup, val set 5.033x speedup, step: 1
Epoch 12/300 |loss: 0.002108| train set 5.165x speedup, test set 5.358x speedup, val set 4.959x speedup, step: 2
Epoch 13/300 |loss: 0.002286| train set 5.342x speedup, test set 5.315x speedup, val set 4.888x speedup, step: 3
Epoch 14/300 |loss: 0.002028| train set 3.718x speedup, test set 3.480x speedup, val set 3.359x speedup, step: 4
Epoch 15/300 |loss: 0.002118| train set 4.872x speedup, test set 5.217x speedup, val set 4.867x speedup, step: 5
Epoch 16/300 |loss: 0.001392| train set 5.032x speedup, test set 5.411x speedup, val set 5.093x speedup, step: 1
Epoch 17/300 |loss: 0.001580| train set 3.993x speedup, test set 3.800x speedup, val set 3.701x speedup, step: 2
Epoch 18/300 |loss: 0.001665| train set 5.450x speedup, test set 5.222x speedup, val set 5.054x speedup, step: 3
Epoch 19/300 |loss: 0.001305| train set 5.496x speedup, test set 5.421x speedup, val set 5.107x speedup, step: 1
Epoch 20/300 |loss: 0.001042| train set 5.497x speedup, test set 5.421x speedup, val set 5.106x speedup, step: 2
Epoch 21/300 |loss: 0.000896| train set 5.031x speedup, test set 5.412x speedup, val set 5.094x speedup, step: 3
Epoch 22/300 |loss: 0.001208| train set 4.856x speedup, test set 5.204x speedup, val set 4.830x speedup, step: 4
Epoch 23/300 |loss: 0.001099| train set 5.418x speedup, test set 5.387x speedup, val set 4.948x speedup, step: 5
Epoch 24/300 |loss: 0.000788| train set 4.976x speedup, test set 5.294x speedup, val set 5.065x speedup, step: 6
Epoch 25/300 |loss: 0.000854| train set 5.492x speedup, test set 5.422x speedup, val set 5.101x speedup, step: 7
Epoch 26/300 |loss: 0.000800| train set 5.442x speedup, test set 5.322x speedup, val set 5.055x speedup, step: 8
Epoch 27/300 |loss: 0.000864| train set 5.495x speedup, test set 5.418x speedup, val set 5.104x speedup, step: 9
Epoch 28/300 |loss: 0.000780| train set 5.448x speedup, test set 5.220x speedup, val set 5.054x speedup, step: 10
Epoch 29/300 |loss: 0.000925| train set 5.397x speedup, test set 5.326x speedup, val set 5.012x speedup, step: 11
Epoch 30/300 |loss: 0.000765| train set 5.448x speedup, test set 5.332x speedup, val set 5.067x speedup, step: 12
Epoch 31/300 |loss: 0.000744| train set 5.494x speedup, test set 5.408x speedup, val set 5.100x speedup, step: 13
Epoch 32/300 |loss: 0.000714| train set 5.489x speedup, test set 5.411x speedup, val set 5.095x speedup, step: 14
Epoch 33/300 |loss: 0.000690| train set 5.497x speedup, test set 5.421x speedup, val set 5.106x speedup, step: 15
Epoch 34/300 |loss: 0.000741| train set 5.445x speedup, test set 5.328x speedup, val set 5.064x speedup, step: 16
Epoch 35/300 |loss: 0.000667| train set 5.449x speedup, test set 5.221x speedup, val set 5.055x speedup, step: 17
Epoch 36/300 |loss: 0.000673| train set 5.471x speedup, test set 5.383x speedup, val set 5.105x speedup, step: 18
Epoch 37/300 |loss: 0.000748| train set 5.441x speedup, test set 5.323x speedup, val set 5.062x speedup, step: 19
Epoch 38/300 |loss: 0.000638| train set 5.484x speedup, test set 5.410x speedup, val set 5.108x speedup, step: 1
Epoch 39/300 |loss: 0.000801| train set 5.488x speedup, test set 5.420x speedup, val set 5.097x speedup, step: 2
Epoch 40/300 |loss: 0.000829| train set 5.451x speedup, test set 5.316x speedup, val set 5.069x speedup, step: 3
early stopping at epoch 40
Training per epoch cost 0.412 s
Optimal speedup on test set is 5.508x
01, opt runtime 18.665s, model runtime 18.665s, pg runtime 18.665s, speedup 1.000x
02, opt runtime 25.356s, model runtime 25.356s, pg runtime 25.356s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 29.763s, model runtime 29.763s, pg runtime 91.648s, speedup 3.079x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 19.263s, model runtime 19.263s, pg runtime 19.263s, speedup 1.000x
07, opt runtime 7.110s, model runtime 7.110s, pg runtime 14.286s, speedup 2.009x
08, opt runtime 7.237s, model runtime 7.237s, pg runtime 17.708s, speedup 2.447x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 25.043s, model runtime 25.043s, pg runtime 73.019s, speedup 2.916x
12, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
13, opt runtime 3.332s, model runtime 3.332s, pg runtime 21.298s, speedup 6.391x
14, opt runtime 2.995s, model runtime 4.213s, pg runtime 14.646s, speedup 3.477x
15, opt runtime 47.518s, model runtime 47.518s, pg runtime 75.736s, speedup 1.594x
16, opt runtime 48.784s, model runtime 48.784s, pg runtime 78.349s, speedup 1.606x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 7.469s, model runtime 7.469s, pg runtime 23.223s, speedup 3.109x
19, opt runtime 1.309s, model runtime 1.309s, pg runtime 1.356s, speedup 1.036x
20, opt runtime 1.340s, model runtime 1.490s, pg runtime 1.340s, speedup 0.899x
21, opt runtime 6.281s, model runtime 6.281s, pg runtime 6.281s, speedup 1.000x
22, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
23, opt runtime 5.961s, model runtime 5.961s, pg runtime 31.210s, speedup 5.236x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.306s, model runtime 1.306s, pg runtime 1.306s, speedup 1.000x
26, opt runtime 1.342s, model runtime 1.342s, pg runtime 1.342s, speedup 1.000x
27, opt runtime 7.066s, model runtime 8.012s, pg runtime 7.533s, speedup 0.940x
28, opt runtime 7.268s, model runtime 7.497s, pg runtime 7.268s, speedup 0.969x
29, opt runtime 5.414s, model runtime 5.414s, pg runtime 5.414s, speedup 1.000x
30, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
31, opt runtime 25.363s, model runtime 25.363s, pg runtime 611.327s, speedup 24.103x
32, opt runtime 24.706s, model runtime 24.706s, pg runtime 610.808s, speedup 24.723x
33, opt runtime 35.538s, model runtime 35.538s, pg runtime 70.116s, speedup 1.973x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 16.138s, model runtime 16.138s, pg runtime 501.793s, speedup 31.094x
36, opt runtime 16.438s, model runtime 16.438s, pg runtime 546.887s, speedup 33.269x
37, opt runtime 15.754s, model runtime 15.754s, pg runtime 15.754s, speedup 1.000x
38, opt runtime 13.961s, model runtime 13.961s, pg runtime 13.961s, speedup 1.000x
39, opt runtime 1.098s, model runtime 1.098s, pg runtime 1.100s, speedup 1.001x
40, opt runtime 1.084s, model runtime 1.084s, pg runtime 1.155s, speedup 1.065x
====================
best train speedup epoch: 20, train speedup 5.497, test speedup 5.421, val speedup 5.106
best test speedup epoch: 25, train speedup 5.492, test speedup 5.422, val speedup 5.101
best validation speedup epoch: 38, train speedup 5.484, test speedup 5.410, val speedup 5.108
last model at epoch 40, train speedup 5.451, test speedup 5.316, val speedup 5.069
execution cost 0:00:40.311677
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1c.sql' '10b.sql' '11b.sql' '12a.sql' '13d.sql' '14c.sql' '15d.sql'
 '16a.sql' '17a.sql' '18a.sql' '19a.sql' '2b.sql' '20b.sql' '21a.sql'
 '22b.sql' '23c.sql' '24a.sql' '25a.sql' '26c.sql' '27a.sql' '28a.sql'
 '29a.sql' '3c.sql' '30b.sql' '31b.sql' '32a.sql' '33a.sql' '4c.sql'
 '5b.sql' '6c.sql' '7a.sql' '8a.sql' '9a.sql']
load JOB succ
load TPCH...
[0, 1, 3, 6, 7, 9] [4, 2] [5, 8]
[0, 3, 6, 7, 8, 9] [5, 1] [2, 4]
[0, 2, 3, 4, 8, 9] [1, 5] [7, 6]
[1, 2, 3, 5, 7, 8] [4, 0] [9, 6]
[0, 3, 4, 7, 8, 9] [1, 6] [2, 5]
[0, 1, 2, 6, 8, 9] [4, 5] [3, 7]
[2, 3, 4, 6, 7, 9] [1, 0] [5, 8]
[0, 2, 3, 6, 7, 9] [4, 1] [5, 8]
[0, 2, 3, 7, 8, 9] [1, 6] [5, 4]
[0, 1, 4, 6, 8, 9] [5, 2] [7, 3]
[0, 2, 5, 7, 8, 9] [3, 4] [1, 6]
[0, 3, 5, 6, 7, 9] [2, 8] [4, 1]
[0, 1, 2, 3, 8, 9] [7, 6] [4, 5]
[0, 1, 2, 4, 5, 9] [8, 3] [6, 7]
[2, 4, 5, 6, 7, 9] [0, 3] [1, 8]
[1, 2, 3, 7, 8, 9] [5, 6] [4, 0]
[0, 1, 2, 6, 8, 9] [3, 5] [4, 7]
[0, 2, 3, 4, 5, 8] [7, 6] [9, 1]
[0, 1, 3, 6, 8, 9] [4, 2] [5, 7]
[0, 1, 2, 3, 6, 7] [8, 9] [4, 5]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.735818, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.049662| train set 2.636x speedup, test set 2.555x speedup, val set 2.435x speedup, step: 1
Epoch 1/300 |loss: 0.020790| train set 2.944x speedup, test set 2.779x speedup, val set 2.627x speedup, step: 1
Epoch 2/300 |loss: 0.010599| train set 3.374x speedup, test set 3.149x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006414| train set 3.841x speedup, test set 3.659x speedup, val set 3.568x speedup, step: 1
Epoch 4/300 |loss: 0.004772| train set 3.593x speedup, test set 3.481x speedup, val set 3.343x speedup, step: 2
Epoch 5/300 |loss: 0.003753| train set 3.429x speedup, test set 3.230x speedup, val set 3.130x speedup, step: 3
Epoch 6/300 |loss: 0.004328| train set 5.306x speedup, test set 5.058x speedup, val set 4.982x speedup, step: 1
Epoch 7/300 |loss: 0.003357| train set 4.971x speedup, test set 4.709x speedup, val set 4.842x speedup, step: 2
Epoch 8/300 |loss: 0.002553| train set 4.016x speedup, test set 3.842x speedup, val set 3.712x speedup, step: 3
Epoch 9/300 |loss: 0.002179| train set 5.299x speedup, test set 5.025x speedup, val set 5.032x speedup, step: 1
Epoch 10/300 |loss: 0.002044| train set 4.469x speedup, test set 4.116x speedup, val set 3.694x speedup, step: 2
Epoch 11/300 |loss: 0.002120| train set 5.356x speedup, test set 5.310x speedup, val set 5.128x speedup, step: 1
Epoch 12/300 |loss: 0.002412| train set 4.977x speedup, test set 5.395x speedup, val set 4.960x speedup, step: 2
Epoch 13/300 |loss: 0.001799| train set 4.911x speedup, test set 5.318x speedup, val set 4.893x speedup, step: 3
Epoch 14/300 |loss: 0.002049| train set 5.010x speedup, test set 4.794x speedup, val set 4.766x speedup, step: 4
Epoch 15/300 |loss: 0.002071| train set 4.258x speedup, test set 3.785x speedup, val set 3.682x speedup, step: 5
Epoch 16/300 |loss: 0.001530| train set 4.973x speedup, test set 5.339x speedup, val set 5.032x speedup, step: 6
Epoch 17/300 |loss: 0.001537| train set 4.216x speedup, test set 4.100x speedup, val set 3.840x speedup, step: 7
Epoch 18/300 |loss: 0.001615| train set 5.491x speedup, test set 5.422x speedup, val set 5.100x speedup, step: 8
Epoch 19/300 |loss: 0.001317| train set 5.421x speedup, test set 5.349x speedup, val set 5.040x speedup, step: 9
Epoch 20/300 |loss: 0.001024| train set 5.396x speedup, test set 5.133x speedup, val set 5.008x speedup, step: 10
Epoch 21/300 |loss: 0.000863| train set 5.245x speedup, test set 5.412x speedup, val set 5.094x speedup, step: 11
Epoch 22/300 |loss: 0.001239| train set 4.856x speedup, test set 5.213x speedup, val set 4.832x speedup, step: 12
Epoch 23/300 |loss: 0.001235| train set 5.496x speedup, test set 5.421x speedup, val set 5.106x speedup, step: 13
Epoch 24/300 |loss: 0.000830| train set 4.893x speedup, test set 5.193x speedup, val set 4.965x speedup, step: 14
Epoch 25/300 |loss: 0.000942| train set 5.490x speedup, test set 5.414x speedup, val set 5.102x speedup, step: 15
Epoch 26/300 |loss: 0.000807| train set 5.445x speedup, test set 5.317x speedup, val set 5.059x speedup, step: 16
Epoch 27/300 |loss: 0.000966| train set 5.446x speedup, test set 5.328x speedup, val set 5.065x speedup, step: 17
Epoch 28/300 |loss: 0.000761| train set 5.448x speedup, test set 5.219x speedup, val set 5.053x speedup, step: 18
Epoch 29/300 |loss: 0.000944| train set 5.486x speedup, test set 5.408x speedup, val set 5.094x speedup, step: 19
Epoch 30/300 |loss: 0.000731| train set 5.448x speedup, test set 5.331x speedup, val set 5.067x speedup, step: 20
Epoch 31/300 |loss: 0.000690| train set 5.495x speedup, test set 5.418x speedup, val set 5.104x speedup, step: 21
Epoch 32/300 |loss: 0.000794| train set 5.490x speedup, test set 5.413x speedup, val set 5.097x speedup, step: 22
Epoch 33/300 |loss: 0.000747| train set 5.497x speedup, test set 5.410x speedup, val set 5.106x speedup, step: 23
Epoch 34/300 |loss: 0.000698| train set 5.445x speedup, test set 5.319x speedup, val set 5.061x speedup, step: 24
Epoch 35/300 |loss: 0.000680| train set 5.449x speedup, test set 5.222x speedup, val set 5.056x speedup, step: 25
Epoch 36/300 |loss: 0.000740| train set 5.493x speedup, test set 5.407x speedup, val set 5.098x speedup, step: 26
Epoch 37/300 |loss: 0.000763| train set 5.486x speedup, test set 5.416x speedup, val set 5.095x speedup, step: 27
Epoch 38/300 |loss: 0.000685| train set 5.485x speedup, test set 5.403x speedup, val set 5.098x speedup, step: 28
Epoch 39/300 |loss: 0.000724| train set 5.491x speedup, test set 5.415x speedup, val set 5.097x speedup, step: 29
Epoch 40/300 |loss: 0.000721| train set 5.497x speedup, test set 5.422x speedup, val set 5.106x speedup, step: 30
early stopping at epoch 40
Training per epoch cost 0.405 s
Optimal speedup on test set is 5.508x
01, opt runtime 18.665s, model runtime 18.665s, pg runtime 18.665s, speedup 1.000x
02, opt runtime 25.356s, model runtime 25.356s, pg runtime 25.356s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 29.763s, model runtime 29.763s, pg runtime 91.648s, speedup 3.079x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 19.263s, model runtime 19.263s, pg runtime 19.263s, speedup 1.000x
07, opt runtime 7.110s, model runtime 7.110s, pg runtime 14.286s, speedup 2.009x
08, opt runtime 7.237s, model runtime 7.237s, pg runtime 17.708s, speedup 2.447x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 25.043s, model runtime 25.043s, pg runtime 73.019s, speedup 2.916x
12, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 2.995s, model runtime 2.995s, pg runtime 14.646s, speedup 4.890x
15, opt runtime 47.518s, model runtime 47.518s, pg runtime 75.736s, speedup 1.594x
16, opt runtime 48.784s, model runtime 48.784s, pg runtime 78.349s, speedup 1.606x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 7.469s, model runtime 7.469s, pg runtime 23.223s, speedup 3.109x
19, opt runtime 1.309s, model runtime 1.525s, pg runtime 1.356s, speedup 0.889x
20, opt runtime 1.340s, model runtime 1.540s, pg runtime 1.340s, speedup 0.870x
21, opt runtime 6.281s, model runtime 6.281s, pg runtime 6.281s, speedup 1.000x
22, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
23, opt runtime 5.961s, model runtime 9.875s, pg runtime 31.210s, speedup 3.161x
24, opt runtime 6.234s, model runtime 10.545s, pg runtime 32.540s, speedup 3.086x
25, opt runtime 1.306s, model runtime 1.306s, pg runtime 1.306s, speedup 1.000x
26, opt runtime 1.342s, model runtime 1.342s, pg runtime 1.342s, speedup 1.000x
27, opt runtime 7.066s, model runtime 7.355s, pg runtime 7.533s, speedup 1.024x
28, opt runtime 7.268s, model runtime 7.333s, pg runtime 7.268s, speedup 0.991x
29, opt runtime 5.414s, model runtime 5.414s, pg runtime 5.414s, speedup 1.000x
30, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
31, opt runtime 25.363s, model runtime 25.363s, pg runtime 611.327s, speedup 24.103x
32, opt runtime 24.706s, model runtime 24.706s, pg runtime 610.808s, speedup 24.723x
33, opt runtime 35.538s, model runtime 35.538s, pg runtime 70.116s, speedup 1.973x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 16.138s, model runtime 17.327s, pg runtime 501.793s, speedup 28.960x
36, opt runtime 16.438s, model runtime 19.535s, pg runtime 546.887s, speedup 27.995x
37, opt runtime 15.754s, model runtime 15.754s, pg runtime 15.754s, speedup 1.000x
38, opt runtime 13.961s, model runtime 13.961s, pg runtime 13.961s, speedup 1.000x
39, opt runtime 1.098s, model runtime 1.100s, pg runtime 1.100s, speedup 1.000x
40, opt runtime 1.084s, model runtime 1.155s, pg runtime 1.155s, speedup 1.000x
====================
best train speedup epoch: 33, train speedup 5.497, test speedup 5.410, val speedup 5.106
best test speedup epoch: 40, train speedup 5.497, test speedup 5.422, val speedup 5.106
best validation speedup epoch: 11, train speedup 5.356, test speedup 5.310, val speedup 5.128
last model at epoch 40, train speedup 5.497, test speedup 5.422, val speedup 5.106
execution cost 0:00:39.925670
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1c.sql' '10b.sql' '11b.sql' '12a.sql' '13d.sql' '14c.sql' '15d.sql'
 '16a.sql' '17a.sql' '18a.sql' '19a.sql' '2b.sql' '20b.sql' '21a.sql'
 '22b.sql' '23c.sql' '24a.sql' '25a.sql' '26c.sql' '27a.sql' '28a.sql'
 '29a.sql' '3c.sql' '30b.sql' '31b.sql' '32a.sql' '33a.sql' '4c.sql'
 '5b.sql' '6c.sql' '7a.sql' '8a.sql' '9a.sql']
load JOB succ
load TPCH...
[0, 1, 3, 6, 7, 9] [4, 2] [5, 8]
[0, 3, 6, 7, 8, 9] [5, 1] [2, 4]
[0, 2, 3, 4, 8, 9] [1, 5] [7, 6]
[1, 2, 3, 5, 7, 8] [4, 0] [9, 6]
[0, 3, 4, 7, 8, 9] [1, 6] [2, 5]
[0, 1, 2, 6, 8, 9] [4, 5] [3, 7]
[2, 3, 4, 6, 7, 9] [1, 0] [5, 8]
[0, 2, 3, 6, 7, 9] [4, 1] [5, 8]
[0, 2, 3, 7, 8, 9] [1, 6] [5, 4]
[0, 1, 4, 6, 8, 9] [5, 2] [7, 3]
[0, 2, 5, 7, 8, 9] [3, 4] [1, 6]
[0, 3, 5, 6, 7, 9] [2, 8] [4, 1]
[0, 1, 2, 3, 8, 9] [7, 6] [4, 5]
[0, 1, 2, 4, 5, 9] [8, 3] [6, 7]
[2, 4, 5, 6, 7, 9] [0, 3] [1, 8]
[1, 2, 3, 7, 8, 9] [5, 6] [4, 0]
[0, 1, 2, 6, 8, 9] [3, 5] [4, 7]
[0, 2, 3, 4, 5, 8] [7, 6] [9, 1]
[0, 1, 3, 6, 8, 9] [4, 2] [5, 7]
[0, 1, 2, 3, 6, 7] [8, 9] [4, 5]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.751674, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.049662| train set 2.636x speedup, test set 2.555x speedup, val set 2.435x speedup, step: 1
Epoch 1/300 |loss: 0.020790| train set 2.944x speedup, test set 2.779x speedup, val set 2.627x speedup, step: 1
Epoch 2/300 |loss: 0.010599| train set 3.374x speedup, test set 3.149x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006414| train set 3.841x speedup, test set 3.659x speedup, val set 3.568x speedup, step: 1
Epoch 4/300 |loss: 0.004772| train set 3.593x speedup, test set 3.481x speedup, val set 3.343x speedup, step: 2
Epoch 5/300 |loss: 0.003758| train set 3.477x speedup, test set 3.492x speedup, val set 3.238x speedup, step: 3
Epoch 6/300 |loss: 0.004069| train set 4.662x speedup, test set 4.421x speedup, val set 4.390x speedup, step: 1
Epoch 7/300 |loss: 0.003609| train set 4.965x speedup, test set 4.703x speedup, val set 4.838x speedup, step: 1
Epoch 8/300 |loss: 0.002732| train set 4.016x speedup, test set 3.842x speedup, val set 3.719x speedup, step: 2
Epoch 9/300 |loss: 0.002184| train set 5.327x speedup, test set 5.088x speedup, val set 4.968x speedup, step: 1
Epoch 10/300 |loss: 0.002055| train set 4.721x speedup, test set 4.644x speedup, val set 4.292x speedup, step: 2
Epoch 11/300 |loss: 0.002036| train set 5.157x speedup, test set 5.307x speedup, val set 5.028x speedup, step: 1
Epoch 12/300 |loss: 0.002292| train set 5.356x speedup, test set 5.250x speedup, val set 5.042x speedup, step: 1
Epoch 13/300 |loss: 0.002199| train set 4.929x speedup, test set 5.254x speedup, val set 4.992x speedup, step: 2
Epoch 14/300 |loss: 0.002031| train set 3.634x speedup, test set 3.411x speedup, val set 3.282x speedup, step: 3
Epoch 15/300 |loss: 0.002080| train set 4.931x speedup, test set 5.263x speedup, val set 4.996x speedup, step: 4
Epoch 16/300 |loss: 0.001420| train set 5.177x speedup, test set 5.347x speedup, val set 5.029x speedup, step: 5
Epoch 17/300 |loss: 0.001468| train set 4.220x speedup, test set 4.103x speedup, val set 3.845x speedup, step: 6
Epoch 18/300 |loss: 0.001675| train set 5.450x speedup, test set 5.222x speedup, val set 5.054x speedup, step: 1
Epoch 19/300 |loss: 0.001320| train set 5.449x speedup, test set 5.222x speedup, val set 5.056x speedup, step: 1
Epoch 20/300 |loss: 0.001029| train set 5.496x speedup, test set 5.421x speedup, val set 5.107x speedup, step: 1
Epoch 21/300 |loss: 0.000861| train set 5.033x speedup, test set 5.415x speedup, val set 5.097x speedup, step: 2
Epoch 22/300 |loss: 0.001100| train set 4.938x speedup, test set 5.307x speedup, val set 4.924x speedup, step: 3
Epoch 23/300 |loss: 0.000894| train set 5.489x speedup, test set 5.410x speedup, val set 5.094x speedup, step: 4
Epoch 24/300 |loss: 0.000834| train set 4.890x speedup, test set 5.195x speedup, val set 4.960x speedup, step: 5
Epoch 25/300 |loss: 0.000850| train set 5.490x speedup, test set 5.410x speedup, val set 5.094x speedup, step: 6
Epoch 26/300 |loss: 0.000850| train set 5.422x speedup, test set 5.284x speedup, val set 5.059x speedup, step: 7
Epoch 27/300 |loss: 0.000840| train set 5.496x speedup, test set 5.420x speedup, val set 5.107x speedup, step: 8
Epoch 28/300 |loss: 0.000772| train set 5.448x speedup, test set 5.220x speedup, val set 5.054x speedup, step: 9
Epoch 29/300 |loss: 0.000827| train set 5.495x speedup, test set 5.410x speedup, val set 5.100x speedup, step: 10
Epoch 30/300 |loss: 0.000781| train set 5.497x speedup, test set 5.422x speedup, val set 5.106x speedup, step: 11
Epoch 31/300 |loss: 0.000800| train set 5.496x speedup, test set 5.420x speedup, val set 5.106x speedup, step: 12
Epoch 32/300 |loss: 0.000757| train set 5.491x speedup, test set 5.411x speedup, val set 5.099x speedup, step: 13
Epoch 33/300 |loss: 0.000649| train set 5.497x speedup, test set 5.421x speedup, val set 5.106x speedup, step: 14
Epoch 34/300 |loss: 0.000724| train set 5.442x speedup, test set 5.322x speedup, val set 5.055x speedup, step: 15
Epoch 35/300 |loss: 0.000725| train set 5.449x speedup, test set 5.311x speedup, val set 5.194x speedup, step: 1
Epoch 36/300 |loss: 0.000676| train set 5.447x speedup, test set 5.331x speedup, val set 5.068x speedup, step: 2
Epoch 37/300 |loss: 0.000700| train set 5.497x speedup, test set 5.421x speedup, val set 5.106x speedup, step: 3
Epoch 38/300 |loss: 0.000602| train set 5.487x speedup, test set 5.393x speedup, val set 5.110x speedup, step: 4
Epoch 39/300 |loss: 0.000731| train set 5.492x speedup, test set 5.423x speedup, val set 5.100x speedup, step: 5
Epoch 40/300 |loss: 0.000798| train set 5.448x speedup, test set 5.332x speedup, val set 5.067x speedup, step: 6
Epoch 41/300 |loss: 0.000694| train set 5.496x speedup, test set 5.420x speedup, val set 5.106x speedup, step: 7
Epoch 42/300 |loss: 0.000687| train set 5.491x speedup, test set 5.415x speedup, val set 5.100x speedup, step: 8
early stopping at epoch 42
Training per epoch cost 0.429 s
Optimal speedup on test set is 5.508x
01, opt runtime 18.665s, model runtime 18.665s, pg runtime 18.665s, speedup 1.000x
02, opt runtime 25.356s, model runtime 25.356s, pg runtime 25.356s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 29.763s, model runtime 29.763s, pg runtime 91.648s, speedup 3.079x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 19.263s, model runtime 19.263s, pg runtime 19.263s, speedup 1.000x
07, opt runtime 7.110s, model runtime 7.110s, pg runtime 14.286s, speedup 2.009x
08, opt runtime 7.237s, model runtime 7.237s, pg runtime 17.708s, speedup 2.447x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 25.043s, model runtime 25.043s, pg runtime 73.019s, speedup 2.916x
12, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 2.995s, model runtime 2.995s, pg runtime 14.646s, speedup 4.890x
15, opt runtime 47.518s, model runtime 47.518s, pg runtime 75.736s, speedup 1.594x
16, opt runtime 48.784s, model runtime 48.784s, pg runtime 78.349s, speedup 1.606x
17, opt runtime 10.788s, model runtime 16.078s, pg runtime 32.939s, speedup 2.049x
18, opt runtime 7.469s, model runtime 14.931s, pg runtime 23.223s, speedup 1.555x
19, opt runtime 1.309s, model runtime 1.356s, pg runtime 1.356s, speedup 1.000x
20, opt runtime 1.340s, model runtime 1.340s, pg runtime 1.340s, speedup 1.000x
21, opt runtime 6.281s, model runtime 6.281s, pg runtime 6.281s, speedup 1.000x
22, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
23, opt runtime 5.961s, model runtime 5.961s, pg runtime 31.210s, speedup 5.236x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.306s, model runtime 1.306s, pg runtime 1.306s, speedup 1.000x
26, opt runtime 1.342s, model runtime 1.342s, pg runtime 1.342s, speedup 1.000x
27, opt runtime 7.066s, model runtime 7.355s, pg runtime 7.533s, speedup 1.024x
28, opt runtime 7.268s, model runtime 7.333s, pg runtime 7.268s, speedup 0.991x
29, opt runtime 5.414s, model runtime 5.414s, pg runtime 5.414s, speedup 1.000x
30, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
31, opt runtime 25.363s, model runtime 25.363s, pg runtime 611.327s, speedup 24.103x
32, opt runtime 24.706s, model runtime 24.706s, pg runtime 610.808s, speedup 24.723x
33, opt runtime 35.538s, model runtime 35.538s, pg runtime 70.116s, speedup 1.973x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 16.138s, model runtime 16.138s, pg runtime 501.793s, speedup 31.094x
36, opt runtime 16.438s, model runtime 16.438s, pg runtime 546.887s, speedup 33.269x
37, opt runtime 15.754s, model runtime 15.754s, pg runtime 15.754s, speedup 1.000x
38, opt runtime 13.961s, model runtime 13.961s, pg runtime 13.961s, speedup 1.000x
39, opt runtime 1.098s, model runtime 1.100s, pg runtime 1.100s, speedup 1.000x
40, opt runtime 1.084s, model runtime 1.155s, pg runtime 1.155s, speedup 1.000x
====================
best train speedup epoch: 33, train speedup 5.497, test speedup 5.421, val speedup 5.106
best test speedup epoch: 39, train speedup 5.492, test speedup 5.423, val speedup 5.100
best validation speedup epoch: 35, train speedup 5.449, test speedup 5.311, val speedup 5.194
last model at epoch 42, train speedup 5.491, test speedup 5.415, val speedup 5.100
execution cost 0:00:42.687630
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1c.sql' '10b.sql' '11b.sql' '12a.sql' '13d.sql' '14c.sql' '15d.sql'
 '16a.sql' '17a.sql' '18a.sql' '19a.sql' '2b.sql' '20b.sql' '21a.sql'
 '22b.sql' '23c.sql' '24a.sql' '25a.sql' '26c.sql' '27a.sql' '28a.sql'
 '29a.sql' '3c.sql' '30b.sql' '31b.sql' '32a.sql' '33a.sql' '4c.sql'
 '5b.sql' '6c.sql' '7a.sql' '8a.sql' '9a.sql']
load JOB succ
load TPCH...
[0, 1, 3, 6, 7, 9] [4, 2] [5, 8]
[0, 3, 6, 7, 8, 9] [5, 1] [2, 4]
[0, 2, 3, 4, 8, 9] [1, 5] [7, 6]
[1, 2, 3, 5, 7, 8] [4, 0] [9, 6]
[0, 3, 4, 7, 8, 9] [1, 6] [2, 5]
[0, 1, 2, 6, 8, 9] [4, 5] [3, 7]
[2, 3, 4, 6, 7, 9] [1, 0] [5, 8]
[0, 2, 3, 6, 7, 9] [4, 1] [5, 8]
[0, 2, 3, 7, 8, 9] [1, 6] [5, 4]
[0, 1, 4, 6, 8, 9] [5, 2] [7, 3]
[0, 2, 5, 7, 8, 9] [3, 4] [1, 6]
[0, 3, 5, 6, 7, 9] [2, 8] [4, 1]
[0, 1, 2, 3, 8, 9] [7, 6] [4, 5]
[0, 1, 2, 4, 5, 9] [8, 3] [6, 7]
[2, 4, 5, 6, 7, 9] [0, 3] [1, 8]
[1, 2, 3, 7, 8, 9] [5, 6] [4, 0]
[0, 1, 2, 6, 8, 9] [3, 5] [4, 7]
[0, 2, 3, 4, 5, 8] [7, 6] [9, 1]
[0, 1, 3, 6, 8, 9] [4, 2] [5, 7]
[0, 1, 2, 3, 6, 7] [8, 9] [4, 5]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.758768, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.049662| train set 2.636x speedup, test set 2.555x speedup, val set 2.435x speedup, step: 1
Epoch 1/300 |loss: 0.020790| train set 2.944x speedup, test set 2.779x speedup, val set 2.627x speedup, step: 1
Epoch 2/300 |loss: 0.010599| train set 3.374x speedup, test set 3.149x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006414| train set 3.841x speedup, test set 3.659x speedup, val set 3.568x speedup, step: 1
Epoch 4/300 |loss: 0.004772| train set 3.593x speedup, test set 3.481x speedup, val set 3.343x speedup, step: 2
Epoch 5/300 |loss: 0.003757| train set 3.418x speedup, test set 3.239x speedup, val set 3.141x speedup, step: 3
Epoch 6/300 |loss: 0.004334| train set 5.306x speedup, test set 5.058x speedup, val set 4.982x speedup, step: 1
Epoch 7/300 |loss: 0.003328| train set 4.966x speedup, test set 4.704x speedup, val set 4.838x speedup, step: 2
Epoch 8/300 |loss: 0.002516| train set 3.786x speedup, test set 3.538x speedup, val set 3.457x speedup, step: 3
Epoch 9/300 |loss: 0.002185| train set 5.279x speedup, test set 5.002x speedup, val set 5.037x speedup, step: 1
Epoch 10/300 |loss: 0.002031| train set 4.539x speedup, test set 4.120x speedup, val set 3.851x speedup, step: 2
Epoch 11/300 |loss: 0.002054| train set 5.346x speedup, test set 5.200x speedup, val set 5.113x speedup, step: 1
Epoch 12/300 |loss: 0.002234| train set 4.957x speedup, test set 5.358x speedup, val set 4.959x speedup, step: 2
Epoch 13/300 |loss: 0.002133| train set 5.408x speedup, test set 5.335x speedup, val set 5.025x speedup, step: 3
Epoch 14/300 |loss: 0.002034| train set 4.605x speedup, test set 4.743x speedup, val set 4.726x speedup, step: 4
Epoch 15/300 |loss: 0.002128| train set 4.908x speedup, test set 5.222x speedup, val set 4.960x speedup, step: 5
Epoch 16/300 |loss: 0.001427| train set 5.245x speedup, test set 5.420x speedup, val set 5.097x speedup, step: 6
Epoch 17/300 |loss: 0.001509| train set 4.246x speedup, test set 4.142x speedup, val set 3.853x speedup, step: 7
Epoch 18/300 |loss: 0.001599| train set 5.393x speedup, test set 5.328x speedup, val set 5.005x speedup, step: 8
Epoch 19/300 |loss: 0.001321| train set 5.450x speedup, test set 5.223x speedup, val set 5.055x speedup, step: 9
Epoch 20/300 |loss: 0.001016| train set 5.448x speedup, test set 5.332x speedup, val set 5.067x speedup, step: 10
Epoch 21/300 |loss: 0.000886| train set 5.245x speedup, test set 5.412x speedup, val set 5.094x speedup, step: 11
Epoch 22/300 |loss: 0.001061| train set 4.708x speedup, test set 4.611x speedup, val set 4.270x speedup, step: 12
Epoch 23/300 |loss: 0.000987| train set 5.247x speedup, test set 5.415x speedup, val set 5.097x speedup, step: 13
Epoch 24/300 |loss: 0.000775| train set 4.978x speedup, test set 5.278x speedup, val set 5.068x speedup, step: 14
Epoch 25/300 |loss: 0.000863| train set 5.483x speedup, test set 5.404x speedup, val set 5.089x speedup, step: 15
Epoch 26/300 |loss: 0.000809| train set 5.421x speedup, test set 5.283x speedup, val set 5.058x speedup, step: 16
Epoch 27/300 |loss: 0.001014| train set 5.495x speedup, test set 5.418x speedup, val set 5.104x speedup, step: 17
Epoch 28/300 |loss: 0.000815| train set 5.425x speedup, test set 5.393x speedup, val set 4.947x speedup, step: 18
Epoch 29/300 |loss: 0.000898| train set 5.459x speedup, test set 5.409x speedup, val set 5.048x speedup, step: 19
Epoch 30/300 |loss: 0.000713| train set 5.448x speedup, test set 5.332x speedup, val set 5.067x speedup, step: 20
Epoch 31/300 |loss: 0.000788| train set 5.495x speedup, test set 5.418x speedup, val set 5.104x speedup, step: 21
Epoch 32/300 |loss: 0.000805| train set 5.491x speedup, test set 5.420x speedup, val set 5.099x speedup, step: 22
Epoch 33/300 |loss: 0.000705| train set 5.497x speedup, test set 5.422x speedup, val set 5.103x speedup, step: 23
Epoch 34/300 |loss: 0.000697| train set 5.449x speedup, test set 5.312x speedup, val set 5.067x speedup, step: 24
Epoch 35/300 |loss: 0.000659| train set 5.447x speedup, test set 5.210x speedup, val set 5.049x speedup, step: 25
Epoch 36/300 |loss: 0.000720| train set 5.496x speedup, test set 5.391x speedup, val set 5.100x speedup, step: 26
Epoch 37/300 |loss: 0.000761| train set 5.441x speedup, test set 5.324x speedup, val set 5.062x speedup, step: 27
Epoch 38/300 |loss: 0.000622| train set 5.490x speedup, test set 5.403x speedup, val set 5.098x speedup, step: 28
Epoch 39/300 |loss: 0.000742| train set 5.492x speedup, test set 5.422x speedup, val set 5.101x speedup, step: 29
Epoch 40/300 |loss: 0.000823| train set 5.451x speedup, test set 5.316x speedup, val set 5.069x speedup, step: 30
Epoch 41/300 |loss: 0.000656| train set 5.498x speedup, test set 5.402x speedup, val set 5.107x speedup, step: 31
Epoch 42/300 |loss: 0.000705| train set 5.442x speedup, test set 5.325x speedup, val set 5.058x speedup, step: 32
Epoch 43/300 |loss: 0.000675| train set 5.442x speedup, test set 5.206x speedup, val set 5.058x speedup, step: 33
Epoch 44/300 |loss: 0.001944| train set 5.304x speedup, test set 5.039x speedup, val set 4.922x speedup, step: 34
early stopping at epoch 44
Training per epoch cost 0.404 s
Optimal speedup on test set is 5.508x
01, opt runtime 18.665s, model runtime 18.665s, pg runtime 18.665s, speedup 1.000x
02, opt runtime 25.356s, model runtime 25.356s, pg runtime 25.356s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 29.763s, model runtime 29.763s, pg runtime 91.648s, speedup 3.079x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 19.263s, model runtime 19.263s, pg runtime 19.263s, speedup 1.000x
07, opt runtime 7.110s, model runtime 7.110s, pg runtime 14.286s, speedup 2.009x
08, opt runtime 7.237s, model runtime 7.237s, pg runtime 17.708s, speedup 2.447x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 25.043s, model runtime 25.043s, pg runtime 73.019s, speedup 2.916x
12, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 2.995s, model runtime 2.995s, pg runtime 14.646s, speedup 4.890x
15, opt runtime 47.518s, model runtime 47.518s, pg runtime 75.736s, speedup 1.594x
16, opt runtime 48.784s, model runtime 48.784s, pg runtime 78.349s, speedup 1.606x
17, opt runtime 10.788s, model runtime 16.078s, pg runtime 32.939s, speedup 2.049x
18, opt runtime 7.469s, model runtime 14.931s, pg runtime 23.223s, speedup 1.555x
19, opt runtime 1.309s, model runtime 1.356s, pg runtime 1.356s, speedup 1.000x
20, opt runtime 1.340s, model runtime 1.340s, pg runtime 1.340s, speedup 1.000x
21, opt runtime 6.281s, model runtime 6.281s, pg runtime 6.281s, speedup 1.000x
22, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
23, opt runtime 5.961s, model runtime 9.875s, pg runtime 31.210s, speedup 3.161x
24, opt runtime 6.234s, model runtime 10.545s, pg runtime 32.540s, speedup 3.086x
25, opt runtime 1.306s, model runtime 1.306s, pg runtime 1.306s, speedup 1.000x
26, opt runtime 1.342s, model runtime 1.342s, pg runtime 1.342s, speedup 1.000x
27, opt runtime 7.066s, model runtime 8.012s, pg runtime 7.533s, speedup 0.940x
28, opt runtime 7.268s, model runtime 7.497s, pg runtime 7.268s, speedup 0.969x
29, opt runtime 5.414s, model runtime 5.414s, pg runtime 5.414s, speedup 1.000x
30, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
31, opt runtime 25.363s, model runtime 25.363s, pg runtime 611.327s, speedup 24.103x
32, opt runtime 24.706s, model runtime 24.706s, pg runtime 610.808s, speedup 24.723x
33, opt runtime 35.538s, model runtime 35.538s, pg runtime 70.116s, speedup 1.973x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 16.138s, model runtime 17.327s, pg runtime 501.793s, speedup 28.960x
36, opt runtime 16.438s, model runtime 19.535s, pg runtime 546.887s, speedup 27.995x
37, opt runtime 15.754s, model runtime 15.754s, pg runtime 15.754s, speedup 1.000x
38, opt runtime 13.961s, model runtime 13.961s, pg runtime 13.961s, speedup 1.000x
39, opt runtime 1.098s, model runtime 1.100s, pg runtime 1.100s, speedup 1.000x
40, opt runtime 1.084s, model runtime 1.155s, pg runtime 1.155s, speedup 1.000x
====================
best train speedup epoch: 41, train speedup 5.498, test speedup 5.402, val speedup 5.107
best test speedup epoch: 39, train speedup 5.492, test speedup 5.422, val speedup 5.101
best validation speedup epoch: 11, train speedup 5.346, test speedup 5.200, val speedup 5.113
last model at epoch 44, train speedup 5.304, test speedup 5.039, val speedup 4.922
execution cost 0:00:43.287571
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1c.sql' '10b.sql' '11b.sql' '12a.sql' '13d.sql' '14c.sql' '15d.sql'
 '16a.sql' '17a.sql' '18a.sql' '19a.sql' '2b.sql' '20b.sql' '21a.sql'
 '22b.sql' '23c.sql' '24a.sql' '25a.sql' '26c.sql' '27a.sql' '28a.sql'
 '29a.sql' '3c.sql' '30b.sql' '31b.sql' '32a.sql' '33a.sql' '4c.sql'
 '5b.sql' '6c.sql' '7a.sql' '8a.sql' '9a.sql']
load JOB succ
load TPCH...
[0, 1, 3, 6, 7, 9] [4, 2] [5, 8]
[0, 3, 6, 7, 8, 9] [5, 1] [2, 4]
[0, 2, 3, 4, 8, 9] [1, 5] [7, 6]
[1, 2, 3, 5, 7, 8] [4, 0] [9, 6]
[0, 3, 4, 7, 8, 9] [1, 6] [2, 5]
[0, 1, 2, 6, 8, 9] [4, 5] [3, 7]
[2, 3, 4, 6, 7, 9] [1, 0] [5, 8]
[0, 2, 3, 6, 7, 9] [4, 1] [5, 8]
[0, 2, 3, 7, 8, 9] [1, 6] [5, 4]
[0, 1, 4, 6, 8, 9] [5, 2] [7, 3]
[0, 2, 5, 7, 8, 9] [3, 4] [1, 6]
[0, 3, 5, 6, 7, 9] [2, 8] [4, 1]
[0, 1, 2, 3, 8, 9] [7, 6] [4, 5]
[0, 1, 2, 4, 5, 9] [8, 3] [6, 7]
[2, 4, 5, 6, 7, 9] [0, 3] [1, 8]
[1, 2, 3, 7, 8, 9] [5, 6] [4, 0]
[0, 1, 2, 6, 8, 9] [3, 5] [4, 7]
[0, 2, 3, 4, 5, 8] [7, 6] [9, 1]
[0, 1, 3, 6, 8, 9] [4, 2] [5, 7]
[0, 1, 2, 3, 6, 7] [8, 9] [4, 5]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.805755, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.049662| train set 2.636x speedup, test set 2.555x speedup, val set 2.435x speedup, step: 1
Epoch 1/300 |loss: 0.020790| train set 2.944x speedup, test set 2.779x speedup, val set 2.627x speedup, step: 1
Epoch 2/300 |loss: 0.010599| train set 3.374x speedup, test set 3.149x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006414| train set 3.841x speedup, test set 3.659x speedup, val set 3.568x speedup, step: 1
Epoch 4/300 |loss: 0.004772| train set 3.593x speedup, test set 3.481x speedup, val set 3.343x speedup, step: 2
Epoch 5/300 |loss: 0.003747| train set 3.600x speedup, test set 3.492x speedup, val set 3.348x speedup, step: 3
Epoch 6/300 |loss: 0.004243| train set 4.736x speedup, test set 4.487x speedup, val set 4.462x speedup, step: 1
Epoch 7/300 |loss: 0.003400| train set 4.965x speedup, test set 4.703x speedup, val set 4.838x speedup, step: 1
Epoch 8/300 |loss: 0.002586| train set 4.015x speedup, test set 3.842x speedup, val set 3.717x speedup, step: 2
Epoch 9/300 |loss: 0.002185| train set 5.370x speedup, test set 5.076x speedup, val set 5.126x speedup, step: 1
Epoch 10/300 |loss: 0.002048| train set 4.929x speedup, test set 5.282x speedup, val set 5.005x speedup, step: 2
Epoch 11/300 |loss: 0.002037| train set 5.160x speedup, test set 5.310x speedup, val set 5.033x speedup, step: 3
Epoch 12/300 |loss: 0.002250| train set 4.978x speedup, test set 5.396x speedup, val set 4.961x speedup, step: 4
Epoch 13/300 |loss: 0.002272| train set 5.177x speedup, test set 5.341x speedup, val set 5.030x speedup, step: 5
Epoch 14/300 |loss: 0.001992| train set 3.704x speedup, test set 3.477x speedup, val set 3.360x speedup, step: 6
Epoch 15/300 |loss: 0.002047| train set 4.911x speedup, test set 5.240x speedup, val set 4.969x speedup, step: 7
Epoch 16/300 |loss: 0.001468| train set 4.967x speedup, test set 5.336x speedup, val set 5.022x speedup, step: 8
Epoch 17/300 |loss: 0.001559| train set 4.216x speedup, test set 4.099x speedup, val set 3.842x speedup, step: 9
Epoch 18/300 |loss: 0.001625| train set 5.445x speedup, test set 5.223x speedup, val set 5.048x speedup, step: 10
Epoch 19/300 |loss: 0.001321| train set 5.449x speedup, test set 5.221x speedup, val set 5.055x speedup, step: 11
Epoch 20/300 |loss: 0.001041| train set 5.496x speedup, test set 5.421x speedup, val set 5.107x speedup, step: 12
Epoch 21/300 |loss: 0.000892| train set 5.247x speedup, test set 5.414x speedup, val set 5.098x speedup, step: 13
Epoch 22/300 |loss: 0.001230| train set 4.655x speedup, test set 4.584x speedup, val set 4.162x speedup, step: 14
Epoch 23/300 |loss: 0.001211| train set 5.490x speedup, test set 5.421x speedup, val set 5.098x speedup, step: 15
Epoch 24/300 |loss: 0.000886| train set 4.663x speedup, test set 4.799x speedup, val set 4.817x speedup, step: 16
Epoch 25/300 |loss: 0.000960| train set 5.490x speedup, test set 5.414x speedup, val set 5.102x speedup, step: 17
Epoch 26/300 |loss: 0.000795| train set 5.447x speedup, test set 5.330x speedup, val set 5.067x speedup, step: 18
Epoch 27/300 |loss: 0.000899| train set 5.447x speedup, test set 5.329x speedup, val set 5.066x speedup, step: 19
Epoch 28/300 |loss: 0.000786| train set 5.379x speedup, test set 5.196x speedup, val set 4.910x speedup, step: 20
Epoch 29/300 |loss: 0.000899| train set 5.496x speedup, test set 5.421x speedup, val set 5.107x speedup, step: 21
Epoch 30/300 |loss: 0.000766| train set 5.442x speedup, test set 5.326x speedup, val set 5.062x speedup, step: 22
Epoch 31/300 |loss: 0.000729| train set 5.495x speedup, test set 5.418x speedup, val set 5.104x speedup, step: 23
Epoch 32/300 |loss: 0.000747| train set 5.489x speedup, test set 5.411x speedup, val set 5.095x speedup, step: 24
Epoch 33/300 |loss: 0.000718| train set 5.497x speedup, test set 5.421x speedup, val set 5.106x speedup, step: 25
Epoch 34/300 |loss: 0.000719| train set 5.443x speedup, test set 5.314x speedup, val set 5.060x speedup, step: 26
Epoch 35/300 |loss: 0.000678| train set 5.441x speedup, test set 5.208x speedup, val set 5.058x speedup, step: 27
Epoch 36/300 |loss: 0.000689| train set 5.419x speedup, test set 5.282x speedup, val set 5.052x speedup, step: 28
Epoch 37/300 |loss: 0.000723| train set 5.443x speedup, test set 5.307x speedup, val set 5.064x speedup, step: 29
Epoch 38/300 |loss: 0.000619| train set 5.488x speedup, test set 5.403x speedup, val set 5.090x speedup, step: 30
Epoch 39/300 |loss: 0.000775| train set 5.491x speedup, test set 5.415x speedup, val set 5.097x speedup, step: 31
Epoch 40/300 |loss: 0.000951| train set 5.448x speedup, test set 5.332x speedup, val set 5.068x speedup, step: 32
early stopping at epoch 40
Training per epoch cost 0.414 s
Optimal speedup on test set is 5.508x
01, opt runtime 18.665s, model runtime 18.665s, pg runtime 18.665s, speedup 1.000x
02, opt runtime 25.356s, model runtime 25.356s, pg runtime 25.356s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 29.763s, model runtime 29.763s, pg runtime 91.648s, speedup 3.079x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 19.263s, model runtime 19.263s, pg runtime 19.263s, speedup 1.000x
07, opt runtime 7.110s, model runtime 7.110s, pg runtime 14.286s, speedup 2.009x
08, opt runtime 7.237s, model runtime 7.237s, pg runtime 17.708s, speedup 2.447x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 25.043s, model runtime 25.043s, pg runtime 73.019s, speedup 2.916x
12, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 2.995s, model runtime 2.995s, pg runtime 14.646s, speedup 4.890x
15, opt runtime 47.518s, model runtime 47.518s, pg runtime 75.736s, speedup 1.594x
16, opt runtime 48.784s, model runtime 48.784s, pg runtime 78.349s, speedup 1.606x
17, opt runtime 10.788s, model runtime 16.078s, pg runtime 32.939s, speedup 2.049x
18, opt runtime 7.469s, model runtime 14.931s, pg runtime 23.223s, speedup 1.555x
19, opt runtime 1.309s, model runtime 1.548s, pg runtime 1.356s, speedup 0.876x
20, opt runtime 1.340s, model runtime 1.530s, pg runtime 1.340s, speedup 0.876x
21, opt runtime 6.281s, model runtime 22.977s, pg runtime 6.281s, speedup 0.273x
22, opt runtime 25.034s, model runtime 31.752s, pg runtime 25.034s, speedup 0.788x
23, opt runtime 5.961s, model runtime 5.961s, pg runtime 31.210s, speedup 5.236x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.306s, model runtime 1.306s, pg runtime 1.306s, speedup 1.000x
26, opt runtime 1.342s, model runtime 1.342s, pg runtime 1.342s, speedup 1.000x
27, opt runtime 7.066s, model runtime 8.012s, pg runtime 7.533s, speedup 0.940x
28, opt runtime 7.268s, model runtime 7.497s, pg runtime 7.268s, speedup 0.969x
29, opt runtime 5.414s, model runtime 5.414s, pg runtime 5.414s, speedup 1.000x
30, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
31, opt runtime 25.363s, model runtime 25.363s, pg runtime 611.327s, speedup 24.103x
32, opt runtime 24.706s, model runtime 24.706s, pg runtime 610.808s, speedup 24.723x
33, opt runtime 35.538s, model runtime 35.538s, pg runtime 70.116s, speedup 1.973x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 16.138s, model runtime 17.327s, pg runtime 501.793s, speedup 28.960x
36, opt runtime 16.438s, model runtime 19.535s, pg runtime 546.887s, speedup 27.995x
37, opt runtime 15.754s, model runtime 15.754s, pg runtime 15.754s, speedup 1.000x
38, opt runtime 13.961s, model runtime 13.961s, pg runtime 13.961s, speedup 1.000x
39, opt runtime 1.098s, model runtime 1.100s, pg runtime 1.100s, speedup 1.000x
40, opt runtime 1.084s, model runtime 1.155s, pg runtime 1.155s, speedup 1.000x
====================
best train speedup epoch: 33, train speedup 5.497, test speedup 5.421, val speedup 5.106
best test speedup epoch: 20, train speedup 5.496, test speedup 5.421, val speedup 5.107
best validation speedup epoch: 9, train speedup 5.370, test speedup 5.076, val speedup 5.126
last model at epoch 40, train speedup 5.448, test speedup 5.332, val speedup 5.068
execution cost 0:00:40.228702
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1c.sql' '10b.sql' '11b.sql' '12a.sql' '13d.sql' '14c.sql' '15d.sql'
 '16a.sql' '17a.sql' '18a.sql' '19a.sql' '2b.sql' '20b.sql' '21a.sql'
 '22b.sql' '23c.sql' '24a.sql' '25a.sql' '26c.sql' '27a.sql' '28a.sql'
 '29a.sql' '3c.sql' '30b.sql' '31b.sql' '32a.sql' '33a.sql' '4c.sql'
 '5b.sql' '6c.sql' '7a.sql' '8a.sql' '9a.sql']
load JOB succ
load TPCH...
[0, 1, 3, 6, 7, 9] [4, 2] [5, 8]
[0, 3, 6, 7, 8, 9] [5, 1] [2, 4]
[0, 2, 3, 4, 8, 9] [1, 5] [7, 6]
[1, 2, 3, 5, 7, 8] [4, 0] [9, 6]
[0, 3, 4, 7, 8, 9] [1, 6] [2, 5]
[0, 1, 2, 6, 8, 9] [4, 5] [3, 7]
[2, 3, 4, 6, 7, 9] [1, 0] [5, 8]
[0, 2, 3, 6, 7, 9] [4, 1] [5, 8]
[0, 2, 3, 7, 8, 9] [1, 6] [5, 4]
[0, 1, 4, 6, 8, 9] [5, 2] [7, 3]
[0, 2, 5, 7, 8, 9] [3, 4] [1, 6]
[0, 3, 5, 6, 7, 9] [2, 8] [4, 1]
[0, 1, 2, 3, 8, 9] [7, 6] [4, 5]
[0, 1, 2, 4, 5, 9] [8, 3] [6, 7]
[2, 4, 5, 6, 7, 9] [0, 3] [1, 8]
[1, 2, 3, 7, 8, 9] [5, 6] [4, 0]
[0, 1, 2, 6, 8, 9] [3, 5] [4, 7]
[0, 2, 3, 4, 5, 8] [7, 6] [9, 1]
[0, 1, 3, 6, 8, 9] [4, 2] [5, 7]
[0, 1, 2, 3, 6, 7] [8, 9] [4, 5]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.738137, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.049662| train set 2.636x speedup, test set 2.555x speedup, val set 2.435x speedup, step: 1
Epoch 1/300 |loss: 0.020790| train set 2.944x speedup, test set 2.779x speedup, val set 2.627x speedup, step: 1
Epoch 2/300 |loss: 0.010599| train set 3.374x speedup, test set 3.149x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006414| train set 3.841x speedup, test set 3.659x speedup, val set 3.568x speedup, step: 1
Epoch 4/300 |loss: 0.004772| train set 3.593x speedup, test set 3.481x speedup, val set 3.343x speedup, step: 2
Epoch 5/300 |loss: 0.003758| train set 3.477x speedup, test set 3.492x speedup, val set 3.238x speedup, step: 3
Epoch 6/300 |loss: 0.004082| train set 4.807x speedup, test set 4.593x speedup, val set 4.554x speedup, step: 1
Epoch 7/300 |loss: 0.003604| train set 4.986x speedup, test set 4.731x speedup, val set 4.828x speedup, step: 1
Epoch 8/300 |loss: 0.002668| train set 4.016x speedup, test set 3.843x speedup, val set 3.719x speedup, step: 2
Epoch 9/300 |loss: 0.002180| train set 5.351x speedup, test set 5.090x speedup, val set 5.023x speedup, step: 1
Epoch 10/300 |loss: 0.002064| train set 4.374x speedup, test set 4.117x speedup, val set 3.848x speedup, step: 2
Epoch 11/300 |loss: 0.002015| train set 5.395x speedup, test set 5.310x speedup, val set 5.033x speedup, step: 1
Epoch 12/300 |loss: 0.002382| train set 5.356x speedup, test set 5.250x speedup, val set 5.042x speedup, step: 1
Epoch 13/300 |loss: 0.002061| train set 5.173x speedup, test set 5.336x speedup, val set 5.024x speedup, step: 2
Epoch 14/300 |loss: 0.002152| train set 3.634x speedup, test set 3.396x speedup, val set 3.298x speedup, step: 3
Epoch 15/300 |loss: 0.001990| train set 4.874x speedup, test set 5.239x speedup, val set 4.856x speedup, step: 4
Epoch 16/300 |loss: 0.001440| train set 4.973x speedup, test set 5.338x speedup, val set 5.032x speedup, step: 5
Epoch 17/300 |loss: 0.001509| train set 4.188x speedup, test set 3.984x speedup, val set 3.812x speedup, step: 6
Epoch 18/300 |loss: 0.001770| train set 5.392x speedup, test set 5.326x speedup, val set 5.006x speedup, step: 7
Epoch 19/300 |loss: 0.001381| train set 5.421x speedup, test set 5.210x speedup, val set 5.013x speedup, step: 8
Epoch 20/300 |loss: 0.001048| train set 5.442x speedup, test set 5.325x speedup, val set 5.059x speedup, step: 1
Epoch 21/300 |loss: 0.000904| train set 5.246x speedup, test set 5.420x speedup, val set 5.096x speedup, step: 1
Epoch 22/300 |loss: 0.001113| train set 4.856x speedup, test set 5.204x speedup, val set 4.830x speedup, step: 2
Epoch 23/300 |loss: 0.001167| train set 5.488x speedup, test set 5.412x speedup, val set 5.095x speedup, step: 3
Epoch 24/300 |loss: 0.000801| train set 4.971x speedup, test set 5.291x speedup, val set 5.065x speedup, step: 4
Epoch 25/300 |loss: 0.000813| train set 5.445x speedup, test set 5.312x speedup, val set 5.189x speedup, step: 1
Epoch 26/300 |loss: 0.000761| train set 5.446x speedup, test set 5.319x speedup, val set 5.061x speedup, step: 2
Epoch 27/300 |loss: 0.000819| train set 5.495x speedup, test set 5.418x speedup, val set 5.104x speedup, step: 3
Epoch 28/300 |loss: 0.000752| train set 5.448x speedup, test set 5.219x speedup, val set 5.053x speedup, step: 4
Epoch 29/300 |loss: 0.001010| train set 5.490x speedup, test set 5.414x speedup, val set 5.102x speedup, step: 5
Epoch 30/300 |loss: 0.000727| train set 5.495x speedup, test set 5.410x speedup, val set 5.100x speedup, step: 6
Epoch 31/300 |loss: 0.000699| train set 5.491x speedup, test set 5.420x speedup, val set 5.099x speedup, step: 7
Epoch 32/300 |loss: 0.000764| train set 5.495x speedup, test set 5.418x speedup, val set 5.104x speedup, step: 8
Epoch 33/300 |loss: 0.000688| train set 5.497x speedup, test set 5.421x speedup, val set 5.106x speedup, step: 9
Epoch 34/300 |loss: 0.000700| train set 5.446x speedup, test set 5.320x speedup, val set 5.060x speedup, step: 10
Epoch 35/300 |loss: 0.000666| train set 5.449x speedup, test set 5.222x speedup, val set 5.056x speedup, step: 11
Epoch 36/300 |loss: 0.000669| train set 5.444x speedup, test set 5.321x speedup, val set 5.058x speedup, step: 12
Epoch 37/300 |loss: 0.000712| train set 5.443x speedup, test set 5.307x speedup, val set 5.064x speedup, step: 13
Epoch 38/300 |loss: 0.000616| train set 5.490x speedup, test set 5.403x speedup, val set 5.098x speedup, step: 14
Epoch 39/300 |loss: 0.000722| train set 5.497x speedup, test set 5.421x speedup, val set 5.106x speedup, step: 15
Epoch 40/300 |loss: 0.000830| train set 5.451x speedup, test set 5.316x speedup, val set 5.069x speedup, step: 16
early stopping at epoch 40
Training per epoch cost 0.423 s
Optimal speedup on test set is 5.508x
01, opt runtime 18.665s, model runtime 18.665s, pg runtime 18.665s, speedup 1.000x
02, opt runtime 25.356s, model runtime 25.356s, pg runtime 25.356s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 29.763s, model runtime 29.763s, pg runtime 91.648s, speedup 3.079x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 19.263s, model runtime 19.263s, pg runtime 19.263s, speedup 1.000x
07, opt runtime 7.110s, model runtime 7.110s, pg runtime 14.286s, speedup 2.009x
08, opt runtime 7.237s, model runtime 7.237s, pg runtime 17.708s, speedup 2.447x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 25.043s, model runtime 25.043s, pg runtime 73.019s, speedup 2.916x
12, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 2.995s, model runtime 2.995s, pg runtime 14.646s, speedup 4.890x
15, opt runtime 47.518s, model runtime 47.518s, pg runtime 75.736s, speedup 1.594x
16, opt runtime 48.784s, model runtime 48.784s, pg runtime 78.349s, speedup 1.606x
17, opt runtime 10.788s, model runtime 16.078s, pg runtime 32.939s, speedup 2.049x
18, opt runtime 7.469s, model runtime 14.931s, pg runtime 23.223s, speedup 1.555x
19, opt runtime 1.309s, model runtime 1.309s, pg runtime 1.356s, speedup 1.036x
20, opt runtime 1.340s, model runtime 1.490s, pg runtime 1.340s, speedup 0.899x
21, opt runtime 6.281s, model runtime 6.281s, pg runtime 6.281s, speedup 1.000x
22, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
23, opt runtime 5.961s, model runtime 5.961s, pg runtime 31.210s, speedup 5.236x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.306s, model runtime 1.306s, pg runtime 1.306s, speedup 1.000x
26, opt runtime 1.342s, model runtime 1.342s, pg runtime 1.342s, speedup 1.000x
27, opt runtime 7.066s, model runtime 7.066s, pg runtime 7.533s, speedup 1.066x
28, opt runtime 7.268s, model runtime 7.507s, pg runtime 7.268s, speedup 0.968x
29, opt runtime 5.414s, model runtime 5.414s, pg runtime 5.414s, speedup 1.000x
30, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
31, opt runtime 25.363s, model runtime 25.363s, pg runtime 611.327s, speedup 24.103x
32, opt runtime 24.706s, model runtime 24.706s, pg runtime 610.808s, speedup 24.723x
33, opt runtime 35.538s, model runtime 35.538s, pg runtime 70.116s, speedup 1.973x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 16.138s, model runtime 16.138s, pg runtime 501.793s, speedup 31.094x
36, opt runtime 16.438s, model runtime 16.438s, pg runtime 546.887s, speedup 33.269x
37, opt runtime 15.754s, model runtime 15.754s, pg runtime 15.754s, speedup 1.000x
38, opt runtime 13.961s, model runtime 13.961s, pg runtime 13.961s, speedup 1.000x
39, opt runtime 1.098s, model runtime 1.098s, pg runtime 1.100s, speedup 1.001x
40, opt runtime 1.084s, model runtime 1.084s, pg runtime 1.155s, speedup 1.065x
====================
best train speedup epoch: 33, train speedup 5.497, test speedup 5.421, val speedup 5.106
best test speedup epoch: 33, train speedup 5.497, test speedup 5.421, val speedup 5.106
best validation speedup epoch: 25, train speedup 5.445, test speedup 5.312, val speedup 5.189
last model at epoch 40, train speedup 5.451, test speedup 5.316, val speedup 5.069
execution cost 0:00:40.389092
==================================================
all print will write to path record/postgresql/TPCH/TCNN/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/point
seed: 42
shuffle_num: 1
slow: 0
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1c.sql' '10b.sql' '11b.sql' '12a.sql' '13d.sql' '14c.sql' '15d.sql'
 '16a.sql' '17a.sql' '18a.sql' '19a.sql' '2b.sql' '20b.sql' '21a.sql'
 '22b.sql' '23c.sql' '24a.sql' '25a.sql' '26c.sql' '27a.sql' '28a.sql'
 '29a.sql' '3c.sql' '30b.sql' '31b.sql' '32a.sql' '33a.sql' '4c.sql'
 '5b.sql' '6c.sql' '7a.sql' '8a.sql' '9a.sql']
load JOB succ
load TPCH...
[0, 1, 3, 6, 7, 9] [4, 2] [5, 8]
[0, 3, 6, 7, 8, 9] [5, 1] [2, 4]
[0, 2, 3, 4, 8, 9] [1, 5] [7, 6]
[1, 2, 3, 5, 7, 8] [4, 0] [9, 6]
[0, 3, 4, 7, 8, 9] [1, 6] [2, 5]
[0, 1, 2, 6, 8, 9] [4, 5] [3, 7]
[2, 3, 4, 6, 7, 9] [1, 0] [5, 8]
[0, 2, 3, 6, 7, 9] [4, 1] [5, 8]
[0, 2, 3, 7, 8, 9] [1, 6] [5, 4]
[0, 1, 4, 6, 8, 9] [5, 2] [7, 3]
[0, 2, 5, 7, 8, 9] [3, 4] [1, 6]
[0, 3, 5, 6, 7, 9] [2, 8] [4, 1]
[0, 1, 2, 3, 8, 9] [7, 6] [4, 5]
[0, 1, 2, 4, 5, 9] [8, 3] [6, 7]
[2, 4, 5, 6, 7, 9] [0, 3] [1, 8]
[1, 2, 3, 7, 8, 9] [5, 6] [4, 0]
[0, 1, 2, 6, 8, 9] [3, 5] [4, 7]
[0, 2, 3, 4, 5, 8] [7, 6] [9, 1]
[0, 1, 3, 6, 8, 9] [4, 2] [5, 7]
[0, 1, 2, 3, 6, 7] [8, 9] [4, 5]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.875354, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.049662| train set 2.636x speedup, test set 2.555x speedup, val set 2.435x speedup, step: 1
Epoch 1/300 |loss: 0.020790| train set 2.944x speedup, test set 2.779x speedup, val set 2.627x speedup, step: 1
Epoch 2/300 |loss: 0.010599| train set 3.374x speedup, test set 3.149x speedup, val set 3.117x speedup, step: 1
Epoch 3/300 |loss: 0.006414| train set 3.841x speedup, test set 3.659x speedup, val set 3.568x speedup, step: 1
Epoch 4/300 |loss: 0.004772| train set 3.593x speedup, test set 3.481x speedup, val set 3.343x speedup, step: 2
Epoch 5/300 |loss: 0.003751| train set 3.395x speedup, test set 3.230x speedup, val set 3.130x speedup, step: 3
Epoch 6/300 |loss: 0.004258| train set 4.718x speedup, test set 4.461x speedup, val set 4.461x speedup, step: 1
Epoch 7/300 |loss: 0.003407| train set 4.971x speedup, test set 4.709x speedup, val set 4.842x speedup, step: 1
Epoch 8/300 |loss: 0.002569| train set 4.020x speedup, test set 3.846x speedup, val set 3.720x speedup, step: 2
Epoch 9/300 |loss: 0.002190| train set 5.277x speedup, test set 4.994x speedup, val set 5.034x speedup, step: 1
Epoch 10/300 |loss: 0.002049| train set 4.216x speedup, test set 4.116x speedup, val set 3.848x speedup, step: 2
Epoch 11/300 |loss: 0.002067| train set 5.138x speedup, test set 5.287x speedup, val set 5.006x speedup, step: 3
Epoch 12/300 |loss: 0.002362| train set 4.957x speedup, test set 5.358x speedup, val set 4.959x speedup, step: 4
Epoch 13/300 |loss: 0.001955| train set 4.962x speedup, test set 5.333x speedup, val set 5.024x speedup, step: 5
Epoch 14/300 |loss: 0.002029| train set 4.787x speedup, test set 4.745x speedup, val set 4.728x speedup, step: 6
Epoch 15/300 |loss: 0.002023| train set 4.893x speedup, test set 5.303x speedup, val set 4.866x speedup, step: 7
Epoch 16/300 |loss: 0.001420| train set 5.415x speedup, test set 5.339x speedup, val set 5.026x speedup, step: 8
Epoch 17/300 |loss: 0.001598| train set 4.188x speedup, test set 3.984x speedup, val set 3.812x speedup, step: 9
Epoch 18/300 |loss: 0.001632| train set 5.393x speedup, test set 5.327x speedup, val set 5.006x speedup, step: 10
Epoch 19/300 |loss: 0.001297| train set 5.496x speedup, test set 5.421x speedup, val set 5.107x speedup, step: 1
Epoch 20/300 |loss: 0.001011| train set 5.448x speedup, test set 5.331x speedup, val set 5.068x speedup, step: 2
Epoch 21/300 |loss: 0.000920| train set 5.033x speedup, test set 5.415x speedup, val set 5.097x speedup, step: 3
Epoch 22/300 |loss: 0.001092| train set 4.593x speedup, test set 4.146x speedup, val set 3.885x speedup, step: 4
Epoch 23/300 |loss: 0.000974| train set 5.248x speedup, test set 5.422x speedup, val set 5.100x speedup, step: 5
Epoch 24/300 |loss: 0.000852| train set 4.995x speedup, test set 5.319x speedup, val set 5.061x speedup, step: 6
Epoch 25/300 |loss: 0.000903| train set 5.485x speedup, test set 5.415x speedup, val set 5.096x speedup, step: 7
Epoch 26/300 |loss: 0.001030| train set 5.344x speedup, test set 5.229x speedup, val set 4.963x speedup, step: 8
Epoch 27/300 |loss: 0.000885| train set 5.447x speedup, test set 5.329x speedup, val set 5.066x speedup, step: 9
Epoch 28/300 |loss: 0.000787| train set 5.401x speedup, test set 5.136x speedup, val set 5.015x speedup, step: 10
Epoch 29/300 |loss: 0.000900| train set 5.496x speedup, test set 5.411x speedup, val set 5.105x speedup, step: 11
Epoch 30/300 |loss: 0.000743| train set 5.494x speedup, test set 5.423x speedup, val set 5.103x speedup, step: 12
Epoch 31/300 |loss: 0.000769| train set 5.493x speedup, test set 5.407x speedup, val set 5.098x speedup, step: 13
Epoch 32/300 |loss: 0.000803| train set 5.489x speedup, test set 5.412x speedup, val set 5.096x speedup, step: 14
Epoch 33/300 |loss: 0.000771| train set 5.497x speedup, test set 5.421x speedup, val set 5.106x speedup, step: 15
Epoch 34/300 |loss: 0.000713| train set 5.450x speedup, test set 5.314x speedup, val set 5.070x speedup, step: 16
Epoch 35/300 |loss: 0.000684| train set 5.450x speedup, test set 5.223x speedup, val set 5.055x speedup, step: 17
Epoch 36/300 |loss: 0.000752| train set 5.496x speedup, test set 5.421x speedup, val set 5.107x speedup, step: 18
Epoch 37/300 |loss: 0.000717| train set 5.484x speedup, test set 5.408x speedup, val set 5.092x speedup, step: 19
Epoch 38/300 |loss: 0.000619| train set 5.490x speedup, test set 5.414x speedup, val set 5.098x speedup, step: 20
Epoch 39/300 |loss: 0.000725| train set 5.492x speedup, test set 5.422x speedup, val set 5.099x speedup, step: 21
Epoch 40/300 |loss: 0.000825| train set 5.451x speedup, test set 5.316x speedup, val set 5.069x speedup, step: 22
Epoch 41/300 |loss: 0.000671| train set 5.490x speedup, test set 5.410x speedup, val set 5.106x speedup, step: 23
Epoch 42/300 |loss: 0.000706| train set 5.496x speedup, test set 5.421x speedup, val set 5.107x speedup, step: 24
Epoch 43/300 |loss: 0.000745| train set 5.458x speedup, test set 5.362x speedup, val set 5.106x speedup, step: 25
Epoch 44/300 |loss: 0.002027| train set 5.445x speedup, test set 5.315x speedup, val set 5.063x speedup, step: 26
early stopping at epoch 44
Training per epoch cost 0.419 s
Optimal speedup on test set is 5.508x
01, opt runtime 18.665s, model runtime 18.665s, pg runtime 18.665s, speedup 1.000x
02, opt runtime 25.356s, model runtime 25.356s, pg runtime 25.356s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 29.763s, model runtime 29.763s, pg runtime 91.648s, speedup 3.079x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 19.263s, model runtime 19.263s, pg runtime 19.263s, speedup 1.000x
07, opt runtime 7.110s, model runtime 7.110s, pg runtime 14.286s, speedup 2.009x
08, opt runtime 7.237s, model runtime 7.237s, pg runtime 17.708s, speedup 2.447x
09, opt runtime 4.881s, model runtime 4.881s, pg runtime 4.881s, speedup 1.000x
10, opt runtime 5.086s, model runtime 5.086s, pg runtime 5.086s, speedup 1.000x
11, opt runtime 25.043s, model runtime 25.043s, pg runtime 73.019s, speedup 2.916x
12, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 2.995s, model runtime 2.995s, pg runtime 14.646s, speedup 4.890x
15, opt runtime 47.518s, model runtime 47.518s, pg runtime 75.736s, speedup 1.594x
16, opt runtime 48.784s, model runtime 48.784s, pg runtime 78.349s, speedup 1.606x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 7.469s, model runtime 7.469s, pg runtime 23.223s, speedup 3.109x
19, opt runtime 1.309s, model runtime 1.309s, pg runtime 1.356s, speedup 1.036x
20, opt runtime 1.340s, model runtime 1.490s, pg runtime 1.340s, speedup 0.899x
21, opt runtime 6.281s, model runtime 6.281s, pg runtime 6.281s, speedup 1.000x
22, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
23, opt runtime 5.961s, model runtime 5.961s, pg runtime 31.210s, speedup 5.236x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.306s, model runtime 1.306s, pg runtime 1.306s, speedup 1.000x
26, opt runtime 1.342s, model runtime 1.342s, pg runtime 1.342s, speedup 1.000x
27, opt runtime 7.066s, model runtime 7.355s, pg runtime 7.533s, speedup 1.024x
28, opt runtime 7.268s, model runtime 7.333s, pg runtime 7.268s, speedup 0.991x
29, opt runtime 5.414s, model runtime 5.414s, pg runtime 5.414s, speedup 1.000x
30, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
31, opt runtime 25.363s, model runtime 25.363s, pg runtime 611.327s, speedup 24.103x
32, opt runtime 24.706s, model runtime 24.706s, pg runtime 610.808s, speedup 24.723x
33, opt runtime 35.538s, model runtime 35.538s, pg runtime 70.116s, speedup 1.973x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 16.138s, model runtime 16.138s, pg runtime 501.793s, speedup 31.094x
36, opt runtime 16.438s, model runtime 16.438s, pg runtime 546.887s, speedup 33.269x
37, opt runtime 15.754s, model runtime 15.754s, pg runtime 15.754s, speedup 1.000x
38, opt runtime 13.961s, model runtime 13.961s, pg runtime 13.961s, speedup 1.000x
39, opt runtime 1.098s, model runtime 1.098s, pg runtime 1.100s, speedup 1.001x
40, opt runtime 1.084s, model runtime 1.084s, pg runtime 1.155s, speedup 1.065x
====================
best train speedup epoch: 33, train speedup 5.497, test speedup 5.421, val speedup 5.106
best test speedup epoch: 30, train speedup 5.494, test speedup 5.423, val speedup 5.103
best validation speedup epoch: 19, train speedup 5.496, test speedup 5.421, val speedup 5.107
last model at epoch 44, train speedup 5.445, test speedup 5.315, val speedup 5.063
execution cost 0:00:44.317302
==================================================
