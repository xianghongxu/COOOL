all print will write to path record/postgresql/TPCH/TCNN/slow_split/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/slow_split/point
seed: 42
shuffle_num: 1
slow: 1
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

load TPCH...
[0, 1, 2, 4, 5, 9] [6, 8] [7 3]
[0, 1, 3, 4, 7, 9] [5, 2] [6 8]
[0, 2, 5, 6, 7, 8] [1, 3] [4 9]
[0, 2, 3, 4, 6, 7, 8] [1, 9] [5 5]
[0, 3, 4, 5, 6, 9] [7, 2] [8 1]
[0, 1, 3, 4, 6, 8] [5, 9] [2 7]
[0, 2, 4, 5, 7, 8, 9] [1, 6] [3 3]
[1, 3, 4, 5, 7, 8] [0, 2] [9 6]
[2, 3, 4, 6, 7, 8] [1, 0] [5 9]
[0, 1, 4, 5, 6, 7] [3, 9] [8 2]
[0, 1, 2, 3, 8, 9] [4, 6] [7 5]
[0, 2, 3, 4, 5, 6] [9, 8] [1 7]
[0, 3, 4, 6, 8, 9] [1, 2] [5 7]
[1, 3, 4, 5, 8, 9] [0, 7] [6 2]
[0, 1, 4, 6, 7, 8] [3, 2] [9 5]
[1, 3, 4, 6, 7, 9] [8, 2] [5 0]
[0, 2, 4, 6, 7, 9] [8, 5] [3 1]
[0, 1, 2, 4, 8, 9] [5, 3] [7 6]
[1, 2, 4, 5, 6, 8] [7, 9] [3 0]
[1, 4, 5, 7, 8, 9] [2, 6] [0 3]
load TPCH succ
train, test, validation (122, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.488616, and there are 5978 training samples
in channel 9
Epoch 0/300 |loss: 0.050603| train set 2.344x speedup, test set 2.756x speedup, val set 2.285x speedup, step: 1
Epoch 1/300 |loss: 0.017820| train set 2.851x speedup, test set 3.190x speedup, val set 2.877x speedup, step: 1
Epoch 2/300 |loss: 0.009638| train set 2.790x speedup, test set 3.332x speedup, val set 2.794x speedup, step: 2
Epoch 3/300 |loss: 0.006189| train set 3.475x speedup, test set 3.905x speedup, val set 3.557x speedup, step: 1
Epoch 4/300 |loss: 0.004777| train set 3.049x speedup, test set 3.622x speedup, val set 3.056x speedup, step: 2
Epoch 5/300 |loss: 0.005024| train set 3.611x speedup, test set 3.828x speedup, val set 3.716x speedup, step: 1
Epoch 6/300 |loss: 0.004199| train set 3.289x speedup, test set 3.991x speedup, val set 3.305x speedup, step: 2
Epoch 7/300 |loss: 0.003262| train set 3.748x speedup, test set 4.077x speedup, val set 3.788x speedup, step: 1
Epoch 8/300 |loss: 0.002908| train set 3.688x speedup, test set 4.160x speedup, val set 3.768x speedup, step: 2
Epoch 9/300 |loss: 0.002531| train set 3.551x speedup, test set 4.150x speedup, val set 3.496x speedup, step: 3
Epoch 10/300 |loss: 0.002242| train set 3.767x speedup, test set 4.114x speedup, val set 3.877x speedup, step: 1
Epoch 11/300 |loss: 0.002798| train set 4.825x speedup, test set 4.015x speedup, val set 4.673x speedup, step: 1
Epoch 12/300 |loss: 0.002765| train set 3.643x speedup, test set 4.005x speedup, val set 3.465x speedup, step: 2
Epoch 13/300 |loss: 0.002935| train set 4.931x speedup, test set 4.058x speedup, val set 4.918x speedup, step: 1
Epoch 14/300 |loss: 0.002142| train set 4.081x speedup, test set 4.381x speedup, val set 4.171x speedup, step: 2
Epoch 15/300 |loss: 0.001869| train set 4.921x speedup, test set 4.055x speedup, val set 4.774x speedup, step: 3
Epoch 16/300 |loss: 0.001561| train set 5.214x speedup, test set 4.073x speedup, val set 5.274x speedup, step: 1
Epoch 17/300 |loss: 0.001875| train set 5.244x speedup, test set 4.349x speedup, val set 5.311x speedup, step: 1
Epoch 18/300 |loss: 0.001631| train set 5.268x speedup, test set 4.094x speedup, val set 5.364x speedup, step: 1
Epoch 19/300 |loss: 0.001647| train set 5.249x speedup, test set 4.360x speedup, val set 5.314x speedup, step: 2
Epoch 20/300 |loss: 0.001104| train set 4.914x speedup, test set 3.919x speedup, val set 4.774x speedup, step: 3
Epoch 21/300 |loss: 0.001087| train set 5.325x speedup, test set 4.274x speedup, val set 5.403x speedup, step: 1
Epoch 22/300 |loss: 0.001088| train set 5.320x speedup, test set 4.403x speedup, val set 5.393x speedup, step: 2
Epoch 23/300 |loss: 0.000938| train set 5.255x speedup, test set 4.342x speedup, val set 5.320x speedup, step: 3
Epoch 24/300 |loss: 0.000907| train set 5.311x speedup, test set 4.379x speedup, val set 5.358x speedup, step: 4
Epoch 25/300 |loss: 0.000782| train set 5.322x speedup, test set 4.400x speedup, val set 5.397x speedup, step: 5
Epoch 26/300 |loss: 0.000656| train set 5.320x speedup, test set 4.131x speedup, val set 5.394x speedup, step: 6
Epoch 27/300 |loss: 0.000617| train set 5.324x speedup, test set 4.274x speedup, val set 5.402x speedup, step: 7
Epoch 28/300 |loss: 0.000693| train set 5.325x speedup, test set 4.280x speedup, val set 5.400x speedup, step: 8
Epoch 29/300 |loss: 0.000675| train set 5.320x speedup, test set 4.273x speedup, val set 5.395x speedup, step: 9
Epoch 30/300 |loss: 0.000672| train set 5.304x speedup, test set 4.112x speedup, val set 5.357x speedup, step: 10
Epoch 31/300 |loss: 0.000709| train set 5.326x speedup, test set 4.274x speedup, val set 5.404x speedup, step: 1
Epoch 32/300 |loss: 0.000762| train set 5.267x speedup, test set 4.099x speedup, val set 5.360x speedup, step: 2
Epoch 33/300 |loss: 0.000663| train set 5.302x speedup, test set 4.388x speedup, val set 5.353x speedup, step: 3
Epoch 34/300 |loss: 0.000597| train set 5.325x speedup, test set 4.280x speedup, val set 5.400x speedup, step: 4
Epoch 35/300 |loss: 0.000599| train set 5.325x speedup, test set 4.401x speedup, val set 5.399x speedup, step: 5
Epoch 36/300 |loss: 0.000621| train set 5.246x speedup, test set 4.089x speedup, val set 5.311x speedup, step: 6
Epoch 37/300 |loss: 0.000612| train set 5.306x speedup, test set 4.265x speedup, val set 5.361x speedup, step: 7
Epoch 38/300 |loss: 0.000663| train set 5.262x speedup, test set 4.098x speedup, val set 5.352x speedup, step: 8
Epoch 39/300 |loss: 0.000601| train set 5.246x speedup, test set 4.225x speedup, val set 5.300x speedup, step: 9
Epoch 40/300 |loss: 0.000636| train set 5.307x speedup, test set 4.119x speedup, val set 5.361x speedup, step: 10
Epoch 41/300 |loss: 0.000629| train set 5.326x speedup, test set 4.127x speedup, val set 5.403x speedup, step: 11
Epoch 42/300 |loss: 0.000685| train set 5.325x speedup, test set 4.132x speedup, val set 5.399x speedup, step: 12
Epoch 43/300 |loss: 0.000622| train set 5.326x speedup, test set 4.126x speedup, val set 5.403x speedup, step: 13
early stopping at epoch 43
Training per epoch cost 0.416 s
Optimal speedup on test set is 5.720x
01, opt runtime 34.775s, model runtime 37.830s, pg runtime 37.830s, speedup 1.000x
02, opt runtime 31.109s, model runtime 31.109s, pg runtime 31.109s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 30.267s, model runtime 30.267s, pg runtime 100.885s, speedup 3.333x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.377s, model runtime 8.474s, pg runtime 28.655s, speedup 3.382x
09, opt runtime 5.543s, model runtime 5.543s, pg runtime 5.543s, speedup 1.000x
10, opt runtime 5.237s, model runtime 5.237s, pg runtime 5.237s, speedup 1.000x
11, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.258s, model runtime 3.312s, pg runtime 18.141s, speedup 5.478x
15, opt runtime 53.298s, model runtime 148.707s, pg runtime 148.707s, speedup 1.000x
16, opt runtime 53.440s, model runtime 165.749s, pg runtime 140.742s, speedup 0.849x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.347s, model runtime 1.438s, pg runtime 1.438s, speedup 1.000x
20, opt runtime 1.428s, model runtime 1.428s, pg runtime 1.428s, speedup 1.000x
21, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 6.250s, model runtime 6.250s, pg runtime 32.969s, speedup 5.275x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.642s, model runtime 1.752s, pg runtime 1.752s, speedup 1.000x
26, opt runtime 1.423s, model runtime 1.423s, pg runtime 1.423s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.799s, pg runtime 7.799s, speedup 1.000x
28, opt runtime 7.199s, model runtime 7.619s, pg runtime 7.619s, speedup 1.000x
29, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
30, opt runtime 5.539s, model runtime 5.539s, pg runtime 5.539s, speedup 1.000x
31, opt runtime 24.840s, model runtime 24.840s, pg runtime 626.529s, speedup 25.222x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 18.690s, model runtime 18.690s, pg runtime 651.942s, speedup 34.881x
36, opt runtime 16.280s, model runtime 16.280s, pg runtime 634.990s, speedup 39.005x
37, opt runtime 19.707s, model runtime 19.707s, pg runtime 19.707s, speedup 1.000x
38, opt runtime 18.262s, model runtime 18.262s, pg runtime 18.262s, speedup 1.000x
39, opt runtime 1.088s, model runtime 1.206s, pg runtime 1.206s, speedup 1.000x
40, opt runtime 1.086s, model runtime 1.181s, pg runtime 1.181s, speedup 1.000x
====================
best train speedup epoch: 41, train speedup 5.326, test speedup 4.127, val speedup 5.403
best test speedup epoch: 22, train speedup 5.320, test speedup 4.403, val speedup 5.393
best validation speedup epoch: 31, train speedup 5.326, test speedup 4.274, val speedup 5.404
last model at epoch 43, train speedup 5.326, test speedup 4.126, val speedup 5.403
execution cost 0:00:41.095131
==================================================
all print will write to path record/postgresql/TPCH/TCNN/slow_split/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/slow_split/point
seed: 42
shuffle_num: 1
slow: 1
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

load TPCH...
[0, 1, 2, 4, 5, 9] [6, 8] [7 3]
[0, 1, 3, 4, 7, 9] [5, 2] [6 8]
[0, 2, 5, 6, 7, 8] [1, 3] [4 9]
[0, 2, 3, 4, 6, 7, 8] [1, 9] [5 5]
[0, 3, 4, 5, 6, 9] [7, 2] [8 1]
[0, 1, 3, 4, 6, 8] [5, 9] [2 7]
[0, 2, 4, 5, 7, 8, 9] [1, 6] [3 3]
[1, 3, 4, 5, 7, 8] [0, 2] [9 6]
[2, 3, 4, 6, 7, 8] [1, 0] [5 9]
[0, 1, 4, 5, 6, 7] [3, 9] [8 2]
[0, 1, 2, 3, 8, 9] [4, 6] [7 5]
[0, 2, 3, 4, 5, 6] [9, 8] [1 7]
[0, 3, 4, 6, 8, 9] [1, 2] [5 7]
[1, 3, 4, 5, 8, 9] [0, 7] [6 2]
[0, 1, 4, 6, 7, 8] [3, 2] [9 5]
[1, 3, 4, 6, 7, 9] [8, 2] [5 0]
[0, 2, 4, 6, 7, 9] [8, 5] [3 1]
[0, 1, 2, 4, 8, 9] [5, 3] [7 6]
[1, 2, 4, 5, 6, 8] [7, 9] [3 0]
[1, 4, 5, 7, 8, 9] [2, 6] [0 3]
load TPCH succ
train, test, validation (122, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.494351, and there are 5978 training samples
in channel 9
Epoch 0/300 |loss: 0.050603| train set 2.344x speedup, test set 2.756x speedup, val set 2.285x speedup, step: 1
Epoch 1/300 |loss: 0.017820| train set 2.851x speedup, test set 3.190x speedup, val set 2.877x speedup, step: 1
Epoch 2/300 |loss: 0.009638| train set 2.790x speedup, test set 3.332x speedup, val set 2.794x speedup, step: 2
Epoch 3/300 |loss: 0.006189| train set 3.475x speedup, test set 3.905x speedup, val set 3.557x speedup, step: 1
Epoch 4/300 |loss: 0.004777| train set 3.049x speedup, test set 3.622x speedup, val set 3.056x speedup, step: 2
Epoch 5/300 |loss: 0.005024| train set 3.611x speedup, test set 3.828x speedup, val set 3.716x speedup, step: 1
Epoch 6/300 |loss: 0.004209| train set 3.289x speedup, test set 3.991x speedup, val set 3.305x speedup, step: 2
Epoch 7/300 |loss: 0.003229| train set 3.778x speedup, test set 4.109x speedup, val set 3.741x speedup, step: 1
Epoch 8/300 |loss: 0.002790| train set 3.691x speedup, test set 4.155x speedup, val set 3.773x speedup, step: 1
Epoch 9/300 |loss: 0.002548| train set 3.548x speedup, test set 4.047x speedup, val set 4.742x speedup, step: 1
Epoch 10/300 |loss: 0.002245| train set 3.767x speedup, test set 4.114x speedup, val set 3.877x speedup, step: 2
Epoch 11/300 |loss: 0.002706| train set 4.905x speedup, test set 4.157x speedup, val set 4.744x speedup, step: 1
Epoch 12/300 |loss: 0.002661| train set 3.514x speedup, test set 4.107x speedup, val set 3.467x speedup, step: 2
Epoch 13/300 |loss: 0.002914| train set 4.869x speedup, test set 3.891x speedup, val set 4.852x speedup, step: 1
Epoch 14/300 |loss: 0.002108| train set 4.049x speedup, test set 4.347x speedup, val set 4.148x speedup, step: 2
Epoch 15/300 |loss: 0.001754| train set 4.916x speedup, test set 4.054x speedup, val set 4.773x speedup, step: 3
Epoch 16/300 |loss: 0.001469| train set 5.231x speedup, test set 4.078x speedup, val set 5.275x speedup, step: 1
Epoch 17/300 |loss: 0.001783| train set 4.920x speedup, test set 4.163x speedup, val set 4.777x speedup, step: 2
Epoch 18/300 |loss: 0.001630| train set 5.268x speedup, test set 4.095x speedup, val set 5.364x speedup, step: 1
Epoch 19/300 |loss: 0.001908| train set 5.236x speedup, test set 4.346x speedup, val set 5.282x speedup, step: 2
Epoch 20/300 |loss: 0.001016| train set 4.920x speedup, test set 4.055x speedup, val set 4.778x speedup, step: 3
Epoch 21/300 |loss: 0.000980| train set 5.316x speedup, test set 4.131x speedup, val set 5.393x speedup, step: 1
Epoch 22/300 |loss: 0.001173| train set 5.321x speedup, test set 4.397x speedup, val set 5.403x speedup, step: 1
Epoch 23/300 |loss: 0.000838| train set 5.255x speedup, test set 4.219x speedup, val set 5.323x speedup, step: 2
Epoch 24/300 |loss: 0.000908| train set 5.324x speedup, test set 4.401x speedup, val set 5.399x speedup, step: 3
Epoch 25/300 |loss: 0.000659| train set 5.325x speedup, test set 4.402x speedup, val set 5.399x speedup, step: 4
Epoch 26/300 |loss: 0.000660| train set 5.312x speedup, test set 4.125x speedup, val set 5.385x speedup, step: 5
Epoch 27/300 |loss: 0.000633| train set 5.326x speedup, test set 4.275x speedup, val set 5.403x speedup, step: 1
Epoch 28/300 |loss: 0.000782| train set 5.326x speedup, test set 4.126x speedup, val set 5.403x speedup, step: 2
Epoch 29/300 |loss: 0.000714| train set 5.326x speedup, test set 4.274x speedup, val set 5.403x speedup, step: 3
Epoch 30/300 |loss: 0.000700| train set 5.307x speedup, test set 4.119x speedup, val set 5.360x speedup, step: 4
Epoch 31/300 |loss: 0.000682| train set 5.321x speedup, test set 4.272x speedup, val set 5.396x speedup, step: 5
Epoch 32/300 |loss: 0.000756| train set 5.324x speedup, test set 4.131x speedup, val set 5.380x speedup, step: 6
Epoch 33/300 |loss: 0.000633| train set 5.307x speedup, test set 4.268x speedup, val set 5.361x speedup, step: 7
Epoch 34/300 |loss: 0.000566| train set 5.325x speedup, test set 4.281x speedup, val set 5.381x speedup, step: 8
Epoch 35/300 |loss: 0.000601| train set 5.325x speedup, test set 4.129x speedup, val set 5.400x speedup, step: 9
Epoch 36/300 |loss: 0.000633| train set 5.321x speedup, test set 4.131x speedup, val set 5.392x speedup, step: 10
Epoch 37/300 |loss: 0.000629| train set 5.324x speedup, test set 4.132x speedup, val set 5.380x speedup, step: 11
Epoch 38/300 |loss: 0.000621| train set 5.250x speedup, test set 4.088x speedup, val set 5.322x speedup, step: 12
Epoch 39/300 |loss: 0.000604| train set 5.300x speedup, test set 4.264x speedup, val set 5.328x speedup, step: 13
Epoch 40/300 |loss: 0.000606| train set 5.321x speedup, test set 4.274x speedup, val set 5.404x speedup, step: 1
Epoch 41/300 |loss: 0.000623| train set 5.325x speedup, test set 4.127x speedup, val set 5.400x speedup, step: 2
Epoch 42/300 |loss: 0.000687| train set 5.317x speedup, test set 4.129x speedup, val set 5.394x speedup, step: 3
Epoch 43/300 |loss: 0.000601| train set 5.325x speedup, test set 4.126x speedup, val set 5.403x speedup, step: 4
early stopping at epoch 43
Training per epoch cost 0.410 s
Optimal speedup on test set is 5.720x
01, opt runtime 34.775s, model runtime 37.830s, pg runtime 37.830s, speedup 1.000x
02, opt runtime 31.109s, model runtime 31.109s, pg runtime 31.109s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 30.267s, model runtime 30.267s, pg runtime 100.885s, speedup 3.333x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.377s, model runtime 8.474s, pg runtime 28.655s, speedup 3.382x
09, opt runtime 5.543s, model runtime 5.543s, pg runtime 5.543s, speedup 1.000x
10, opt runtime 5.237s, model runtime 5.237s, pg runtime 5.237s, speedup 1.000x
11, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.258s, model runtime 3.312s, pg runtime 18.141s, speedup 5.478x
15, opt runtime 53.298s, model runtime 148.707s, pg runtime 148.707s, speedup 1.000x
16, opt runtime 53.440s, model runtime 165.749s, pg runtime 140.742s, speedup 0.849x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.347s, model runtime 1.438s, pg runtime 1.438s, speedup 1.000x
20, opt runtime 1.428s, model runtime 1.428s, pg runtime 1.428s, speedup 1.000x
21, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 6.250s, model runtime 6.250s, pg runtime 32.969s, speedup 5.275x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.642s, model runtime 1.752s, pg runtime 1.752s, speedup 1.000x
26, opt runtime 1.423s, model runtime 1.423s, pg runtime 1.423s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.799s, pg runtime 7.799s, speedup 1.000x
28, opt runtime 7.199s, model runtime 7.619s, pg runtime 7.619s, speedup 1.000x
29, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
30, opt runtime 5.539s, model runtime 5.539s, pg runtime 5.539s, speedup 1.000x
31, opt runtime 24.840s, model runtime 24.840s, pg runtime 626.529s, speedup 25.222x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 18.690s, model runtime 18.690s, pg runtime 651.942s, speedup 34.881x
36, opt runtime 16.280s, model runtime 16.280s, pg runtime 634.990s, speedup 39.005x
37, opt runtime 19.707s, model runtime 19.707s, pg runtime 19.707s, speedup 1.000x
38, opt runtime 18.262s, model runtime 18.262s, pg runtime 18.262s, speedup 1.000x
39, opt runtime 1.088s, model runtime 1.206s, pg runtime 1.206s, speedup 1.000x
40, opt runtime 1.086s, model runtime 1.181s, pg runtime 1.181s, speedup 1.000x
====================
best train speedup epoch: 27, train speedup 5.326, test speedup 4.275, val speedup 5.403
best test speedup epoch: 25, train speedup 5.325, test speedup 4.402, val speedup 5.399
best validation speedup epoch: 40, train speedup 5.321, test speedup 4.274, val speedup 5.404
last model at epoch 43, train speedup 5.325, test speedup 4.126, val speedup 5.403
execution cost 0:00:41.084111
==================================================
all print will write to path record/postgresql/TPCH/TCNN/slow_split/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/slow_split/point
seed: 42
shuffle_num: 1
slow: 1
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

load TPCH...
[0, 1, 2, 4, 5, 9] [6, 8] [7 3]
[0, 1, 3, 4, 7, 9] [5, 2] [6 8]
[0, 2, 5, 6, 7, 8] [1, 3] [4 9]
[0, 2, 3, 4, 6, 7, 8] [1, 9] [5 5]
[0, 3, 4, 5, 6, 9] [7, 2] [8 1]
[0, 1, 3, 4, 6, 8] [5, 9] [2 7]
[0, 2, 4, 5, 7, 8, 9] [1, 6] [3 3]
[1, 3, 4, 5, 7, 8] [0, 2] [9 6]
[2, 3, 4, 6, 7, 8] [1, 0] [5 9]
[0, 1, 4, 5, 6, 7] [3, 9] [8 2]
[0, 1, 2, 3, 8, 9] [4, 6] [7 5]
[0, 2, 3, 4, 5, 6] [9, 8] [1 7]
[0, 3, 4, 6, 8, 9] [1, 2] [5 7]
[1, 3, 4, 5, 8, 9] [0, 7] [6 2]
[0, 1, 4, 6, 7, 8] [3, 2] [9 5]
[1, 3, 4, 6, 7, 9] [8, 2] [5 0]
[0, 2, 4, 6, 7, 9] [8, 5] [3 1]
[0, 1, 2, 4, 8, 9] [5, 3] [7 6]
[1, 2, 4, 5, 6, 8] [7, 9] [3 0]
[1, 4, 5, 7, 8, 9] [2, 6] [0 3]
load TPCH succ
train, test, validation (122, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.486462, and there are 5978 training samples
in channel 9
Epoch 0/300 |loss: 0.050603| train set 2.344x speedup, test set 2.756x speedup, val set 2.285x speedup, step: 1
Epoch 1/300 |loss: 0.017820| train set 2.851x speedup, test set 3.190x speedup, val set 2.877x speedup, step: 1
Epoch 2/300 |loss: 0.009638| train set 2.790x speedup, test set 3.332x speedup, val set 2.794x speedup, step: 2
Epoch 3/300 |loss: 0.006189| train set 3.475x speedup, test set 3.905x speedup, val set 3.557x speedup, step: 1
Epoch 4/300 |loss: 0.004777| train set 3.049x speedup, test set 3.622x speedup, val set 3.056x speedup, step: 2
Epoch 5/300 |loss: 0.005024| train set 3.611x speedup, test set 3.828x speedup, val set 3.716x speedup, step: 1
Epoch 6/300 |loss: 0.004210| train set 3.289x speedup, test set 3.991x speedup, val set 3.305x speedup, step: 2
Epoch 7/300 |loss: 0.003230| train set 3.796x speedup, test set 4.118x speedup, val set 3.833x speedup, step: 1
Epoch 8/300 |loss: 0.002831| train set 3.522x speedup, test set 3.980x speedup, val set 3.488x speedup, step: 2
Epoch 9/300 |loss: 0.002577| train set 4.825x speedup, test set 4.002x speedup, val set 4.676x speedup, step: 1
Epoch 10/300 |loss: 0.002269| train set 3.531x speedup, test set 4.157x speedup, val set 3.612x speedup, step: 2
Epoch 11/300 |loss: 0.002547| train set 4.904x speedup, test set 3.915x speedup, val set 4.744x speedup, step: 1
Epoch 12/300 |loss: 0.002754| train set 3.796x speedup, test set 4.008x speedup, val set 3.467x speedup, step: 2
Epoch 13/300 |loss: 0.002773| train set 4.920x speedup, test set 4.054x speedup, val set 4.777x speedup, step: 1
Epoch 14/300 |loss: 0.002158| train set 4.055x speedup, test set 4.244x speedup, val set 4.167x speedup, step: 2
Epoch 15/300 |loss: 0.001863| train set 4.913x speedup, test set 3.923x speedup, val set 4.770x speedup, step: 3
Epoch 16/300 |loss: 0.001594| train set 3.708x speedup, test set 4.070x speedup, val set 5.270x speedup, step: 1
Epoch 17/300 |loss: 0.001806| train set 5.307x speedup, test set 4.117x speedup, val set 5.360x speedup, step: 1
Epoch 18/300 |loss: 0.001521| train set 5.268x speedup, test set 4.094x speedup, val set 5.364x speedup, step: 1
Epoch 19/300 |loss: 0.001765| train set 5.169x speedup, test set 4.307x speedup, val set 5.234x speedup, step: 2
Epoch 20/300 |loss: 0.001098| train set 4.913x speedup, test set 3.923x speedup, val set 4.771x speedup, step: 3
Epoch 21/300 |loss: 0.001025| train set 5.218x speedup, test set 4.114x speedup, val set 5.338x speedup, step: 4
Epoch 22/300 |loss: 0.001060| train set 5.247x speedup, test set 4.351x speedup, val set 5.319x speedup, step: 5
Epoch 23/300 |loss: 0.000911| train set 5.192x speedup, test set 4.315x speedup, val set 5.281x speedup, step: 6
Epoch 24/300 |loss: 0.000870| train set 5.324x speedup, test set 4.401x speedup, val set 5.399x speedup, step: 1
Epoch 25/300 |loss: 0.000707| train set 5.305x speedup, test set 4.389x speedup, val set 5.359x speedup, step: 2
Epoch 26/300 |loss: 0.000656| train set 5.262x speedup, test set 4.244x speedup, val set 5.354x speedup, step: 3
Epoch 27/300 |loss: 0.000615| train set 5.326x speedup, test set 4.397x speedup, val set 5.404x speedup, step: 1
Epoch 28/300 |loss: 0.000835| train set 5.325x speedup, test set 5.568x speedup, val set 5.400x speedup, step: 2
Epoch 29/300 |loss: 0.000717| train set 5.324x speedup, test set 4.127x speedup, val set 5.402x speedup, step: 3
Epoch 30/300 |loss: 0.000677| train set 5.307x speedup, test set 4.119x speedup, val set 5.360x speedup, step: 4
Epoch 31/300 |loss: 0.000731| train set 5.322x speedup, test set 4.126x speedup, val set 5.403x speedup, step: 5
Epoch 32/300 |loss: 0.000821| train set 5.267x speedup, test set 4.095x speedup, val set 5.344x speedup, step: 6
Epoch 33/300 |loss: 0.000637| train set 5.304x speedup, test set 4.118x speedup, val set 5.361x speedup, step: 7
Epoch 34/300 |loss: 0.000596| train set 5.265x speedup, test set 4.099x speedup, val set 5.358x speedup, step: 8
Epoch 35/300 |loss: 0.000577| train set 5.325x speedup, test set 4.279x speedup, val set 5.399x speedup, step: 9
Epoch 36/300 |loss: 0.000611| train set 5.321x speedup, test set 4.130x speedup, val set 5.392x speedup, step: 10
Epoch 37/300 |loss: 0.000594| train set 5.324x speedup, test set 4.132x speedup, val set 5.380x speedup, step: 11
Epoch 38/300 |loss: 0.000618| train set 5.250x speedup, test set 4.088x speedup, val set 5.323x speedup, step: 12
Epoch 39/300 |loss: 0.000605| train set 5.308x speedup, test set 4.117x speedup, val set 5.347x speedup, step: 13
Epoch 40/300 |loss: 0.000647| train set 5.308x speedup, test set 4.115x speedup, val set 5.364x speedup, step: 14
Epoch 41/300 |loss: 0.000643| train set 5.325x speedup, test set 4.131x speedup, val set 5.399x speedup, step: 15
Epoch 42/300 |loss: 0.000707| train set 5.317x speedup, test set 4.129x speedup, val set 5.394x speedup, step: 16
early stopping at epoch 42
Training per epoch cost 0.417 s
Optimal speedup on test set is 5.720x
01, opt runtime 34.775s, model runtime 37.830s, pg runtime 37.830s, speedup 1.000x
02, opt runtime 31.109s, model runtime 31.109s, pg runtime 31.109s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 30.267s, model runtime 30.267s, pg runtime 100.885s, speedup 3.333x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.377s, model runtime 8.474s, pg runtime 28.655s, speedup 3.382x
09, opt runtime 5.543s, model runtime 5.543s, pg runtime 5.543s, speedup 1.000x
10, opt runtime 5.237s, model runtime 5.237s, pg runtime 5.237s, speedup 1.000x
11, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.258s, model runtime 3.312s, pg runtime 18.141s, speedup 5.478x
15, opt runtime 53.298s, model runtime 148.707s, pg runtime 148.707s, speedup 1.000x
16, opt runtime 53.440s, model runtime 140.742s, pg runtime 140.742s, speedup 1.000x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.347s, model runtime 1.438s, pg runtime 1.438s, speedup 1.000x
20, opt runtime 1.428s, model runtime 1.428s, pg runtime 1.428s, speedup 1.000x
21, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 6.250s, model runtime 6.250s, pg runtime 32.969s, speedup 5.275x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.642s, model runtime 1.752s, pg runtime 1.752s, speedup 1.000x
26, opt runtime 1.423s, model runtime 1.423s, pg runtime 1.423s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.799s, pg runtime 7.799s, speedup 1.000x
28, opt runtime 7.199s, model runtime 7.619s, pg runtime 7.619s, speedup 1.000x
29, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
30, opt runtime 5.539s, model runtime 5.539s, pg runtime 5.539s, speedup 1.000x
31, opt runtime 24.840s, model runtime 24.840s, pg runtime 626.529s, speedup 25.222x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 18.690s, model runtime 18.690s, pg runtime 651.942s, speedup 34.881x
36, opt runtime 16.280s, model runtime 16.280s, pg runtime 634.990s, speedup 39.005x
37, opt runtime 19.707s, model runtime 19.707s, pg runtime 19.707s, speedup 1.000x
38, opt runtime 18.262s, model runtime 18.262s, pg runtime 18.262s, speedup 1.000x
39, opt runtime 1.088s, model runtime 1.206s, pg runtime 1.206s, speedup 1.000x
40, opt runtime 1.086s, model runtime 1.181s, pg runtime 1.181s, speedup 1.000x
====================
best train speedup epoch: 27, train speedup 5.326, test speedup 4.397, val speedup 5.404
best test speedup epoch: 28, train speedup 5.325, test speedup 5.568, val speedup 5.400
best validation speedup epoch: 27, train speedup 5.326, test speedup 4.397, val speedup 5.404
last model at epoch 42, train speedup 5.317, test speedup 4.129, val speedup 5.394
execution cost 0:00:40.342491
==================================================
all print will write to path record/postgresql/TPCH/TCNN/slow_split/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/slow_split/point
seed: 42
shuffle_num: 1
slow: 1
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

load TPCH...
[0, 1, 2, 4, 5, 9] [6, 8] [7 3]
[0, 1, 3, 4, 7, 9] [5, 2] [6 8]
[0, 2, 5, 6, 7, 8] [1, 3] [4 9]
[0, 2, 3, 4, 6, 7, 8] [1, 9] [5 5]
[0, 3, 4, 5, 6, 9] [7, 2] [8 1]
[0, 1, 3, 4, 6, 8] [5, 9] [2 7]
[0, 2, 4, 5, 7, 8, 9] [1, 6] [3 3]
[1, 3, 4, 5, 7, 8] [0, 2] [9 6]
[2, 3, 4, 6, 7, 8] [1, 0] [5 9]
[0, 1, 4, 5, 6, 7] [3, 9] [8 2]
[0, 1, 2, 3, 8, 9] [4, 6] [7 5]
[0, 2, 3, 4, 5, 6] [9, 8] [1 7]
[0, 3, 4, 6, 8, 9] [1, 2] [5 7]
[1, 3, 4, 5, 8, 9] [0, 7] [6 2]
[0, 1, 4, 6, 7, 8] [3, 2] [9 5]
[1, 3, 4, 6, 7, 9] [8, 2] [5 0]
[0, 2, 4, 6, 7, 9] [8, 5] [3 1]
[0, 1, 2, 4, 8, 9] [5, 3] [7 6]
[1, 2, 4, 5, 6, 8] [7, 9] [3 0]
[1, 4, 5, 7, 8, 9] [2, 6] [0 3]
load TPCH succ
train, test, validation (122, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.503331, and there are 5978 training samples
in channel 9
Epoch 0/300 |loss: 0.050603| train set 2.344x speedup, test set 2.756x speedup, val set 2.285x speedup, step: 1
Epoch 1/300 |loss: 0.017820| train set 2.851x speedup, test set 3.190x speedup, val set 2.877x speedup, step: 1
Epoch 2/300 |loss: 0.009638| train set 2.790x speedup, test set 3.332x speedup, val set 2.794x speedup, step: 2
Epoch 3/300 |loss: 0.006189| train set 3.475x speedup, test set 3.905x speedup, val set 3.557x speedup, step: 1
Epoch 4/300 |loss: 0.004777| train set 3.049x speedup, test set 3.622x speedup, val set 3.056x speedup, step: 2
Epoch 5/300 |loss: 0.005024| train set 3.611x speedup, test set 3.828x speedup, val set 3.716x speedup, step: 1
Epoch 6/300 |loss: 0.004194| train set 3.289x speedup, test set 3.991x speedup, val set 3.305x speedup, step: 2
Epoch 7/300 |loss: 0.003219| train set 3.827x speedup, test set 4.152x speedup, val set 3.787x speedup, step: 1
Epoch 8/300 |loss: 0.002842| train set 3.564x speedup, test set 4.020x speedup, val set 3.528x speedup, step: 2
Epoch 9/300 |loss: 0.002592| train set 4.105x speedup, test set 4.149x speedup, val set 4.743x speedup, step: 1
Epoch 10/300 |loss: 0.002325| train set 3.665x speedup, test set 4.157x speedup, val set 3.612x speedup, step: 2
Epoch 11/300 |loss: 0.002731| train set 4.839x speedup, test set 4.126x speedup, val set 4.703x speedup, step: 3
Epoch 12/300 |loss: 0.002698| train set 3.512x speedup, test set 4.106x speedup, val set 3.466x speedup, step: 4
Epoch 13/300 |loss: 0.002984| train set 4.983x speedup, test set 4.203x speedup, val set 4.841x speedup, step: 1
Epoch 14/300 |loss: 0.002157| train set 4.093x speedup, test set 4.397x speedup, val set 4.197x speedup, step: 2
Epoch 15/300 |loss: 0.001737| train set 4.920x speedup, test set 4.163x speedup, val set 4.777x speedup, step: 3
Epoch 16/300 |loss: 0.001589| train set 5.214x speedup, test set 4.073x speedup, val set 5.274x speedup, step: 1
Epoch 17/300 |loss: 0.001864| train set 5.218x speedup, test set 4.338x speedup, val set 5.287x speedup, step: 1
Epoch 18/300 |loss: 0.001636| train set 5.268x speedup, test set 4.095x speedup, val set 5.364x speedup, step: 1
Epoch 19/300 |loss: 0.001658| train set 5.197x speedup, test set 4.322x speedup, val set 5.282x speedup, step: 2
Epoch 20/300 |loss: 0.001072| train set 4.914x speedup, test set 3.919x speedup, val set 4.774x speedup, step: 3
Epoch 21/300 |loss: 0.001104| train set 5.311x speedup, test set 4.113x speedup, val set 5.359x speedup, step: 4
Epoch 22/300 |loss: 0.001112| train set 5.252x speedup, test set 4.237x speedup, val set 5.317x speedup, step: 5
Epoch 23/300 |loss: 0.000857| train set 5.198x speedup, test set 4.317x speedup, val set 5.286x speedup, step: 6
Epoch 24/300 |loss: 0.000962| train set 5.306x speedup, test set 4.266x speedup, val set 5.360x speedup, step: 7
Epoch 25/300 |loss: 0.000761| train set 5.306x speedup, test set 4.120x speedup, val set 5.361x speedup, step: 8
Epoch 26/300 |loss: 0.000641| train set 5.319x speedup, test set 4.130x speedup, val set 5.393x speedup, step: 1
Epoch 27/300 |loss: 0.000584| train set 5.326x speedup, test set 4.127x speedup, val set 5.404x speedup, step: 1
Epoch 28/300 |loss: 0.000740| train set 5.325x speedup, test set 4.132x speedup, val set 5.399x speedup, step: 2
Epoch 29/300 |loss: 0.000730| train set 5.325x speedup, test set 4.127x speedup, val set 5.403x speedup, step: 3
Epoch 30/300 |loss: 0.000694| train set 5.326x speedup, test set 4.126x speedup, val set 5.403x speedup, step: 4
Epoch 31/300 |loss: 0.000714| train set 5.326x speedup, test set 4.127x speedup, val set 5.404x speedup, step: 1
Epoch 32/300 |loss: 0.000776| train set 5.323x speedup, test set 4.128x speedup, val set 5.381x speedup, step: 2
Epoch 33/300 |loss: 0.000628| train set 5.314x speedup, test set 4.123x speedup, val set 5.392x speedup, step: 3
Epoch 34/300 |loss: 0.000578| train set 5.264x speedup, test set 4.095x speedup, val set 5.360x speedup, step: 4
Epoch 35/300 |loss: 0.000611| train set 5.326x speedup, test set 4.127x speedup, val set 5.404x speedup, step: 1
Epoch 36/300 |loss: 0.000633| train set 5.304x speedup, test set 4.116x speedup, val set 5.365x speedup, step: 2
early stopping at epoch 36
Training per epoch cost 0.418 s
Optimal speedup on test set is 5.720x
01, opt runtime 34.775s, model runtime 37.830s, pg runtime 37.830s, speedup 1.000x
02, opt runtime 31.109s, model runtime 31.109s, pg runtime 31.109s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 30.267s, model runtime 30.267s, pg runtime 100.885s, speedup 3.333x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.377s, model runtime 8.474s, pg runtime 28.655s, speedup 3.382x
09, opt runtime 5.543s, model runtime 5.543s, pg runtime 5.543s, speedup 1.000x
10, opt runtime 5.237s, model runtime 5.237s, pg runtime 5.237s, speedup 1.000x
11, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.258s, model runtime 3.312s, pg runtime 18.141s, speedup 5.478x
15, opt runtime 53.298s, model runtime 180.921s, pg runtime 148.707s, speedup 0.822x
16, opt runtime 53.440s, model runtime 165.749s, pg runtime 140.742s, speedup 0.849x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.347s, model runtime 1.438s, pg runtime 1.438s, speedup 1.000x
20, opt runtime 1.428s, model runtime 1.428s, pg runtime 1.428s, speedup 1.000x
21, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 6.250s, model runtime 6.250s, pg runtime 32.969s, speedup 5.275x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.642s, model runtime 1.752s, pg runtime 1.752s, speedup 1.000x
26, opt runtime 1.423s, model runtime 1.423s, pg runtime 1.423s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.799s, pg runtime 7.799s, speedup 1.000x
28, opt runtime 7.199s, model runtime 7.619s, pg runtime 7.619s, speedup 1.000x
29, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
30, opt runtime 5.539s, model runtime 5.539s, pg runtime 5.539s, speedup 1.000x
31, opt runtime 24.840s, model runtime 24.840s, pg runtime 626.529s, speedup 25.222x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 18.690s, model runtime 18.690s, pg runtime 651.942s, speedup 34.881x
36, opt runtime 16.280s, model runtime 16.280s, pg runtime 634.990s, speedup 39.005x
37, opt runtime 19.707s, model runtime 19.707s, pg runtime 19.707s, speedup 1.000x
38, opt runtime 18.262s, model runtime 18.262s, pg runtime 18.262s, speedup 1.000x
39, opt runtime 1.088s, model runtime 1.206s, pg runtime 1.206s, speedup 1.000x
40, opt runtime 1.086s, model runtime 1.181s, pg runtime 1.181s, speedup 1.000x
====================
best train speedup epoch: 30, train speedup 5.326, test speedup 4.126, val speedup 5.403
best test speedup epoch: 14, train speedup 4.093, test speedup 4.397, val speedup 4.197
best validation speedup epoch: 35, train speedup 5.326, test speedup 4.127, val speedup 5.404
last model at epoch 36, train speedup 5.304, test speedup 4.116, val speedup 5.365
execution cost 0:00:35.446121
==================================================
all print will write to path record/postgresql/TPCH/TCNN/slow_split/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/slow_split/point
seed: 42
shuffle_num: 1
slow: 1
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

load TPCH...
[0, 1, 2, 4, 5, 9] [6, 8] [7 3]
[0, 1, 3, 4, 7, 9] [5, 2] [6 8]
[0, 2, 5, 6, 7, 8] [1, 3] [4 9]
[0, 2, 3, 4, 6, 7, 8] [1, 9] [5 5]
[0, 3, 4, 5, 6, 9] [7, 2] [8 1]
[0, 1, 3, 4, 6, 8] [5, 9] [2 7]
[0, 2, 4, 5, 7, 8, 9] [1, 6] [3 3]
[1, 3, 4, 5, 7, 8] [0, 2] [9 6]
[2, 3, 4, 6, 7, 8] [1, 0] [5 9]
[0, 1, 4, 5, 6, 7] [3, 9] [8 2]
[0, 1, 2, 3, 8, 9] [4, 6] [7 5]
[0, 2, 3, 4, 5, 6] [9, 8] [1 7]
[0, 3, 4, 6, 8, 9] [1, 2] [5 7]
[1, 3, 4, 5, 8, 9] [0, 7] [6 2]
[0, 1, 4, 6, 7, 8] [3, 2] [9 5]
[1, 3, 4, 6, 7, 9] [8, 2] [5 0]
[0, 2, 4, 6, 7, 9] [8, 5] [3 1]
[0, 1, 2, 4, 8, 9] [5, 3] [7 6]
[1, 2, 4, 5, 6, 8] [7, 9] [3 0]
[1, 4, 5, 7, 8, 9] [2, 6] [0 3]
load TPCH succ
train, test, validation (122, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.512803, and there are 5978 training samples
in channel 9
Epoch 0/300 |loss: 0.050603| train set 2.344x speedup, test set 2.756x speedup, val set 2.285x speedup, step: 1
Epoch 1/300 |loss: 0.017820| train set 2.851x speedup, test set 3.190x speedup, val set 2.877x speedup, step: 1
Epoch 2/300 |loss: 0.009638| train set 2.790x speedup, test set 3.332x speedup, val set 2.794x speedup, step: 2
Epoch 3/300 |loss: 0.006189| train set 3.475x speedup, test set 3.905x speedup, val set 3.557x speedup, step: 1
Epoch 4/300 |loss: 0.004777| train set 3.049x speedup, test set 3.622x speedup, val set 3.056x speedup, step: 2
Epoch 5/300 |loss: 0.005024| train set 3.611x speedup, test set 3.828x speedup, val set 3.716x speedup, step: 1
Epoch 6/300 |loss: 0.004209| train set 3.289x speedup, test set 3.991x speedup, val set 3.305x speedup, step: 2
Epoch 7/300 |loss: 0.003229| train set 3.778x speedup, test set 4.109x speedup, val set 3.741x speedup, step: 1
Epoch 8/300 |loss: 0.002797| train set 3.738x speedup, test set 4.199x speedup, val set 3.819x speedup, step: 1
Epoch 9/300 |loss: 0.002517| train set 3.509x speedup, test set 4.058x speedup, val set 3.458x speedup, step: 2
Epoch 10/300 |loss: 0.002282| train set 3.533x speedup, test set 4.159x speedup, val set 3.616x speedup, step: 3
Epoch 11/300 |loss: 0.002990| train set 4.854x speedup, test set 3.967x speedup, val set 4.818x speedup, step: 1
Epoch 12/300 |loss: 0.002637| train set 3.511x speedup, test set 4.005x speedup, val set 3.465x speedup, step: 2
Epoch 13/300 |loss: 0.002868| train set 4.920x speedup, test set 3.920x speedup, val set 4.777x speedup, step: 3
Epoch 14/300 |loss: 0.002236| train set 3.726x speedup, test set 4.085x speedup, val set 3.795x speedup, step: 4
Epoch 15/300 |loss: 0.001875| train set 4.803x speedup, test set 3.865x speedup, val set 4.644x speedup, step: 5
Epoch 16/300 |loss: 0.001529| train set 5.231x speedup, test set 4.084x speedup, val set 5.312x speedup, step: 1
Epoch 17/300 |loss: 0.001825| train set 5.312x speedup, test set 4.122x speedup, val set 5.398x speedup, step: 1
Epoch 18/300 |loss: 0.001544| train set 5.251x speedup, test set 4.083x speedup, val set 5.326x speedup, step: 2
Epoch 19/300 |loss: 0.001794| train set 5.169x speedup, test set 4.047x speedup, val set 5.235x speedup, step: 3
Epoch 20/300 |loss: 0.001149| train set 4.914x speedup, test set 3.919x speedup, val set 4.774x speedup, step: 4
Epoch 21/300 |loss: 0.001094| train set 5.326x speedup, test set 4.127x speedup, val set 5.404x speedup, step: 1
Epoch 22/300 |loss: 0.001077| train set 5.229x speedup, test set 4.080x speedup, val set 5.278x speedup, step: 2
Epoch 23/300 |loss: 0.000930| train set 5.259x speedup, test set 4.089x speedup, val set 5.356x speedup, step: 3
Epoch 24/300 |loss: 0.000892| train set 5.320x speedup, test set 4.126x speedup, val set 5.403x speedup, step: 4
Epoch 25/300 |loss: 0.000718| train set 5.314x speedup, test set 4.123x speedup, val set 5.392x speedup, step: 5
Epoch 26/300 |loss: 0.000653| train set 5.262x speedup, test set 4.098x speedup, val set 5.354x speedup, step: 6
Epoch 27/300 |loss: 0.000639| train set 5.325x speedup, test set 4.126x speedup, val set 5.403x speedup, step: 7
Epoch 28/300 |loss: 0.000721| train set 5.326x speedup, test set 4.127x speedup, val set 5.403x speedup, step: 8
Epoch 29/300 |loss: 0.000832| train set 5.225x speedup, test set 4.076x speedup, val set 5.288x speedup, step: 9
Epoch 30/300 |loss: 0.000815| train set 5.304x speedup, test set 4.112x speedup, val set 5.357x speedup, step: 10
Epoch 31/300 |loss: 0.000808| train set 5.302x speedup, test set 4.120x speedup, val set 5.355x speedup, step: 11
Epoch 32/300 |loss: 0.000727| train set 5.250x speedup, test set 4.089x speedup, val set 5.303x speedup, step: 12
Epoch 33/300 |loss: 0.000612| train set 5.208x speedup, test set 4.064x speedup, val set 5.250x speedup, step: 13
Epoch 34/300 |loss: 0.000574| train set 5.248x speedup, test set 4.088x speedup, val set 5.302x speedup, step: 14
Epoch 35/300 |loss: 0.000608| train set 5.324x speedup, test set 4.131x speedup, val set 5.400x speedup, step: 15
Epoch 36/300 |loss: 0.000624| train set 5.305x speedup, test set 4.120x speedup, val set 5.354x speedup, step: 16
Epoch 37/300 |loss: 0.000601| train set 5.267x speedup, test set 4.100x speedup, val set 5.341x speedup, step: 17
Epoch 38/300 |loss: 0.000635| train set 5.250x speedup, test set 4.088x speedup, val set 5.322x speedup, step: 18
Epoch 39/300 |loss: 0.000589| train set 5.320x speedup, test set 4.130x speedup, val set 5.373x speedup, step: 19
Epoch 40/300 |loss: 0.000637| train set 5.324x speedup, test set 4.131x speedup, val set 5.400x speedup, step: 20
Epoch 41/300 |loss: 0.000636| train set 5.326x speedup, test set 4.127x speedup, val set 5.403x speedup, step: 21
Epoch 42/300 |loss: 0.000692| train set 5.317x speedup, test set 4.129x speedup, val set 5.394x speedup, step: 22
early stopping at epoch 42
Training per epoch cost 0.447 s
Optimal speedup on test set is 5.720x
01, opt runtime 34.775s, model runtime 37.830s, pg runtime 37.830s, speedup 1.000x
02, opt runtime 31.109s, model runtime 31.109s, pg runtime 31.109s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 30.267s, model runtime 30.267s, pg runtime 100.885s, speedup 3.333x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.377s, model runtime 8.474s, pg runtime 28.655s, speedup 3.382x
09, opt runtime 5.543s, model runtime 5.543s, pg runtime 5.543s, speedup 1.000x
10, opt runtime 5.237s, model runtime 5.237s, pg runtime 5.237s, speedup 1.000x
11, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.258s, model runtime 3.312s, pg runtime 18.141s, speedup 5.478x
15, opt runtime 53.298s, model runtime 180.921s, pg runtime 148.707s, speedup 0.822x
16, opt runtime 53.440s, model runtime 165.749s, pg runtime 140.742s, speedup 0.849x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.347s, model runtime 1.438s, pg runtime 1.438s, speedup 1.000x
20, opt runtime 1.428s, model runtime 1.428s, pg runtime 1.428s, speedup 1.000x
21, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 6.250s, model runtime 6.250s, pg runtime 32.969s, speedup 5.275x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.642s, model runtime 1.752s, pg runtime 1.752s, speedup 1.000x
26, opt runtime 1.423s, model runtime 1.423s, pg runtime 1.423s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.799s, pg runtime 7.799s, speedup 1.000x
28, opt runtime 7.199s, model runtime 7.619s, pg runtime 7.619s, speedup 1.000x
29, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
30, opt runtime 5.539s, model runtime 5.539s, pg runtime 5.539s, speedup 1.000x
31, opt runtime 24.840s, model runtime 24.840s, pg runtime 626.529s, speedup 25.222x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 18.690s, model runtime 18.690s, pg runtime 651.942s, speedup 34.881x
36, opt runtime 16.280s, model runtime 16.280s, pg runtime 634.990s, speedup 39.005x
37, opt runtime 19.707s, model runtime 19.707s, pg runtime 19.707s, speedup 1.000x
38, opt runtime 18.262s, model runtime 18.262s, pg runtime 18.262s, speedup 1.000x
39, opt runtime 1.088s, model runtime 1.206s, pg runtime 1.206s, speedup 1.000x
40, opt runtime 1.086s, model runtime 1.181s, pg runtime 1.181s, speedup 1.000x
====================
best train speedup epoch: 28, train speedup 5.326, test speedup 4.127, val speedup 5.403
best test speedup epoch: 8, train speedup 3.738, test speedup 4.199, val speedup 3.819
best validation speedup epoch: 21, train speedup 5.326, test speedup 4.127, val speedup 5.404
last model at epoch 42, train speedup 5.317, test speedup 4.129, val speedup 5.394
execution cost 0:00:41.929286
==================================================
all print will write to path record/postgresql/TPCH/TCNN/slow_split/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/slow_split/point
seed: 42
shuffle_num: 1
slow: 1
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

load TPCH...
[0, 1, 2, 4, 5, 9] [6, 8] [7 3]
[0, 1, 3, 4, 7, 9] [5, 2] [6 8]
[0, 2, 5, 6, 7, 8] [1, 3] [4 9]
[0, 2, 3, 4, 6, 7, 8] [1, 9] [5 5]
[0, 3, 4, 5, 6, 9] [7, 2] [8 1]
[0, 1, 3, 4, 6, 8] [5, 9] [2 7]
[0, 2, 4, 5, 7, 8, 9] [1, 6] [3 3]
[1, 3, 4, 5, 7, 8] [0, 2] [9 6]
[2, 3, 4, 6, 7, 8] [1, 0] [5 9]
[0, 1, 4, 5, 6, 7] [3, 9] [8 2]
[0, 1, 2, 3, 8, 9] [4, 6] [7 5]
[0, 2, 3, 4, 5, 6] [9, 8] [1 7]
[0, 3, 4, 6, 8, 9] [1, 2] [5 7]
[1, 3, 4, 5, 8, 9] [0, 7] [6 2]
[0, 1, 4, 6, 7, 8] [3, 2] [9 5]
[1, 3, 4, 6, 7, 9] [8, 2] [5 0]
[0, 2, 4, 6, 7, 9] [8, 5] [3 1]
[0, 1, 2, 4, 8, 9] [5, 3] [7 6]
[1, 2, 4, 5, 6, 8] [7, 9] [3 0]
[1, 4, 5, 7, 8, 9] [2, 6] [0 3]
load TPCH succ
train, test, validation (122, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.523314, and there are 5978 training samples
in channel 9
Epoch 0/300 |loss: 0.050603| train set 2.344x speedup, test set 2.756x speedup, val set 2.285x speedup, step: 1
Epoch 1/300 |loss: 0.017820| train set 2.851x speedup, test set 3.190x speedup, val set 2.877x speedup, step: 1
Epoch 2/300 |loss: 0.009638| train set 2.790x speedup, test set 3.332x speedup, val set 2.794x speedup, step: 2
Epoch 3/300 |loss: 0.006189| train set 3.475x speedup, test set 3.905x speedup, val set 3.557x speedup, step: 1
Epoch 4/300 |loss: 0.004777| train set 3.049x speedup, test set 3.622x speedup, val set 3.056x speedup, step: 2
Epoch 5/300 |loss: 0.005024| train set 3.611x speedup, test set 3.828x speedup, val set 3.716x speedup, step: 1
Epoch 6/300 |loss: 0.004199| train set 3.289x speedup, test set 3.991x speedup, val set 3.305x speedup, step: 2
Epoch 7/300 |loss: 0.003262| train set 3.748x speedup, test set 4.077x speedup, val set 3.788x speedup, step: 1
Epoch 8/300 |loss: 0.002911| train set 3.688x speedup, test set 4.160x speedup, val set 3.768x speedup, step: 2
Epoch 9/300 |loss: 0.002546| train set 3.516x speedup, test set 4.119x speedup, val set 3.473x speedup, step: 3
Epoch 10/300 |loss: 0.002263| train set 3.766x speedup, test set 4.120x speedup, val set 3.875x speedup, step: 1
Epoch 11/300 |loss: 0.002928| train set 4.904x speedup, test set 4.056x speedup, val set 4.744x speedup, step: 1
Epoch 12/300 |loss: 0.002532| train set 3.678x speedup, test set 4.180x speedup, val set 3.744x speedup, step: 2
Epoch 13/300 |loss: 0.002743| train set 4.869x speedup, test set 4.021x speedup, val set 4.853x speedup, step: 1
Epoch 14/300 |loss: 0.002130| train set 3.764x speedup, test set 4.402x speedup, val set 3.836x speedup, step: 2
Epoch 15/300 |loss: 0.001703| train set 4.919x speedup, test set 4.168x speedup, val set 4.774x speedup, step: 3
Epoch 16/300 |loss: 0.001457| train set 5.325x speedup, test set 4.126x speedup, val set 5.403x speedup, step: 1
Epoch 17/300 |loss: 0.001736| train set 5.244x speedup, test set 4.349x speedup, val set 5.314x speedup, step: 2
Epoch 18/300 |loss: 0.001601| train set 5.268x speedup, test set 4.095x speedup, val set 5.364x speedup, step: 3
Epoch 19/300 |loss: 0.001869| train set 5.173x speedup, test set 4.307x speedup, val set 5.241x speedup, step: 4
Epoch 20/300 |loss: 0.001022| train set 4.913x speedup, test set 4.057x speedup, val set 4.771x speedup, step: 5
Epoch 21/300 |loss: 0.000988| train set 5.312x speedup, test set 4.254x speedup, val set 5.362x speedup, step: 6
Epoch 22/300 |loss: 0.001032| train set 5.237x speedup, test set 4.341x speedup, val set 5.286x speedup, step: 7
Epoch 23/300 |loss: 0.000871| train set 5.268x speedup, test set 4.360x speedup, val set 5.364x speedup, step: 8
Epoch 24/300 |loss: 0.000866| train set 5.213x speedup, test set 4.334x speedup, val set 5.274x speedup, step: 9
Epoch 25/300 |loss: 0.000669| train set 5.307x speedup, test set 4.267x speedup, val set 5.361x speedup, step: 10
Epoch 26/300 |loss: 0.000633| train set 5.320x speedup, test set 4.402x speedup, val set 5.394x speedup, step: 11
Epoch 27/300 |loss: 0.000595| train set 5.326x speedup, test set 4.275x speedup, val set 5.404x speedup, step: 1
Epoch 28/300 |loss: 0.000715| train set 5.325x speedup, test set 4.132x speedup, val set 5.399x speedup, step: 2
Epoch 29/300 |loss: 0.000753| train set 5.321x speedup, test set 4.272x speedup, val set 5.396x speedup, step: 3
Epoch 30/300 |loss: 0.000667| train set 5.320x speedup, test set 4.127x speedup, val set 5.391x speedup, step: 4
Epoch 31/300 |loss: 0.000710| train set 5.326x speedup, test set 4.126x speedup, val set 5.403x speedup, step: 5
Epoch 32/300 |loss: 0.000698| train set 5.324x speedup, test set 4.279x speedup, val set 5.400x speedup, step: 6
Epoch 33/300 |loss: 0.000648| train set 5.302x speedup, test set 4.388x speedup, val set 5.353x speedup, step: 7
Epoch 34/300 |loss: 0.000588| train set 5.319x speedup, test set 4.403x speedup, val set 5.380x speedup, step: 8
Epoch 35/300 |loss: 0.000586| train set 5.324x speedup, test set 4.402x speedup, val set 5.400x speedup, step: 9
Epoch 36/300 |loss: 0.000627| train set 5.321x speedup, test set 4.279x speedup, val set 5.392x speedup, step: 10
Epoch 37/300 |loss: 0.000599| train set 5.268x speedup, test set 4.240x speedup, val set 5.364x speedup, step: 11
Epoch 38/300 |loss: 0.000611| train set 5.239x speedup, test set 4.084x speedup, val set 5.313x speedup, step: 12
Epoch 39/300 |loss: 0.000581| train set 5.321x speedup, test set 4.394x speedup, val set 5.377x speedup, step: 13
Epoch 40/300 |loss: 0.000635| train set 5.326x speedup, test set 4.397x speedup, val set 5.404x speedup, step: 14
Epoch 41/300 |loss: 0.000658| train set 5.325x speedup, test set 4.401x speedup, val set 5.399x speedup, step: 15
Epoch 42/300 |loss: 0.000679| train set 5.325x speedup, test set 4.280x speedup, val set 5.399x speedup, step: 16
early stopping at epoch 42
Training per epoch cost 0.438 s
Optimal speedup on test set is 5.720x
01, opt runtime 34.775s, model runtime 37.830s, pg runtime 37.830s, speedup 1.000x
02, opt runtime 31.109s, model runtime 31.109s, pg runtime 31.109s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 30.267s, model runtime 30.267s, pg runtime 100.885s, speedup 3.333x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.377s, model runtime 8.474s, pg runtime 28.655s, speedup 3.382x
09, opt runtime 5.543s, model runtime 5.543s, pg runtime 5.543s, speedup 1.000x
10, opt runtime 5.237s, model runtime 5.237s, pg runtime 5.237s, speedup 1.000x
11, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.258s, model runtime 3.312s, pg runtime 18.141s, speedup 5.478x
15, opt runtime 53.298s, model runtime 148.707s, pg runtime 148.707s, speedup 1.000x
16, opt runtime 53.440s, model runtime 165.749s, pg runtime 140.742s, speedup 0.849x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.347s, model runtime 1.438s, pg runtime 1.438s, speedup 1.000x
20, opt runtime 1.428s, model runtime 1.428s, pg runtime 1.428s, speedup 1.000x
21, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 6.250s, model runtime 6.250s, pg runtime 32.969s, speedup 5.275x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.642s, model runtime 1.752s, pg runtime 1.752s, speedup 1.000x
26, opt runtime 1.423s, model runtime 1.423s, pg runtime 1.423s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.799s, pg runtime 7.799s, speedup 1.000x
28, opt runtime 7.199s, model runtime 7.619s, pg runtime 7.619s, speedup 1.000x
29, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
30, opt runtime 5.539s, model runtime 5.539s, pg runtime 5.539s, speedup 1.000x
31, opt runtime 24.840s, model runtime 24.840s, pg runtime 626.529s, speedup 25.222x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 18.690s, model runtime 18.690s, pg runtime 651.942s, speedup 34.881x
36, opt runtime 16.280s, model runtime 16.280s, pg runtime 634.990s, speedup 39.005x
37, opt runtime 19.707s, model runtime 19.707s, pg runtime 19.707s, speedup 1.000x
38, opt runtime 18.262s, model runtime 18.262s, pg runtime 18.262s, speedup 1.000x
39, opt runtime 1.088s, model runtime 1.088s, pg runtime 1.206s, speedup 1.109x
40, opt runtime 1.086s, model runtime 1.086s, pg runtime 1.181s, speedup 1.088x
====================
best train speedup epoch: 31, train speedup 5.326, test speedup 4.126, val speedup 5.403
best test speedup epoch: 34, train speedup 5.319, test speedup 4.403, val speedup 5.380
best validation speedup epoch: 27, train speedup 5.326, test speedup 4.275, val speedup 5.404
last model at epoch 42, train speedup 5.325, test speedup 4.280, val speedup 5.399
execution cost 0:00:41.077152
==================================================
all print will write to path record/postgresql/TPCH/TCNN/slow_split/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/slow_split/point
seed: 42
shuffle_num: 1
slow: 1
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

load TPCH...
[0, 1, 2, 4, 5, 9] [6, 8] [7 3]
[0, 1, 3, 4, 7, 9] [5, 2] [6 8]
[0, 2, 5, 6, 7, 8] [1, 3] [4 9]
[0, 2, 3, 4, 6, 7, 8] [1, 9] [5 5]
[0, 3, 4, 5, 6, 9] [7, 2] [8 1]
[0, 1, 3, 4, 6, 8] [5, 9] [2 7]
[0, 2, 4, 5, 7, 8, 9] [1, 6] [3 3]
[1, 3, 4, 5, 7, 8] [0, 2] [9 6]
[2, 3, 4, 6, 7, 8] [1, 0] [5 9]
[0, 1, 4, 5, 6, 7] [3, 9] [8 2]
[0, 1, 2, 3, 8, 9] [4, 6] [7 5]
[0, 2, 3, 4, 5, 6] [9, 8] [1 7]
[0, 3, 4, 6, 8, 9] [1, 2] [5 7]
[1, 3, 4, 5, 8, 9] [0, 7] [6 2]
[0, 1, 4, 6, 7, 8] [3, 2] [9 5]
[1, 3, 4, 6, 7, 9] [8, 2] [5 0]
[0, 2, 4, 6, 7, 9] [8, 5] [3 1]
[0, 1, 2, 4, 8, 9] [5, 3] [7 6]
[1, 2, 4, 5, 6, 8] [7, 9] [3 0]
[1, 4, 5, 7, 8, 9] [2, 6] [0 3]
load TPCH succ
train, test, validation (122, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.525651, and there are 5978 training samples
in channel 9
Epoch 0/300 |loss: 0.050603| train set 2.344x speedup, test set 2.756x speedup, val set 2.285x speedup, step: 1
Epoch 1/300 |loss: 0.017820| train set 2.851x speedup, test set 3.190x speedup, val set 2.877x speedup, step: 1
Epoch 2/300 |loss: 0.009638| train set 2.790x speedup, test set 3.332x speedup, val set 2.794x speedup, step: 2
Epoch 3/300 |loss: 0.006189| train set 3.475x speedup, test set 3.905x speedup, val set 3.557x speedup, step: 1
Epoch 4/300 |loss: 0.004787| train set 3.049x speedup, test set 3.663x speedup, val set 3.056x speedup, step: 2
Epoch 5/300 |loss: 0.004918| train set 3.355x speedup, test set 3.917x speedup, val set 3.434x speedup, step: 3
Epoch 6/300 |loss: 0.004321| train set 3.289x speedup, test set 3.991x speedup, val set 3.305x speedup, step: 4
Epoch 7/300 |loss: 0.003238| train set 3.797x speedup, test set 4.141x speedup, val set 3.821x speedup, step: 1
Epoch 8/300 |loss: 0.002782| train set 3.690x speedup, test set 4.153x speedup, val set 3.771x speedup, step: 2
Epoch 9/300 |loss: 0.002506| train set 3.549x speedup, test set 4.150x speedup, val set 3.495x speedup, step: 3
Epoch 10/300 |loss: 0.002227| train set 3.531x speedup, test set 4.163x speedup, val set 3.611x speedup, step: 4
Epoch 11/300 |loss: 0.002788| train set 4.905x speedup, test set 4.153x speedup, val set 4.747x speedup, step: 1
Epoch 12/300 |loss: 0.002610| train set 3.694x speedup, test set 4.303x speedup, val set 3.760x speedup, step: 2
Epoch 13/300 |loss: 0.003117| train set 4.920x speedup, test set 4.164x speedup, val set 4.777x speedup, step: 1
Epoch 14/300 |loss: 0.002162| train set 4.091x speedup, test set 4.394x speedup, val set 4.194x speedup, step: 2
Epoch 15/300 |loss: 0.001749| train set 4.920x speedup, test set 4.169x speedup, val set 4.774x speedup, step: 3
Epoch 16/300 |loss: 0.001489| train set 5.300x speedup, test set 4.113x speedup, val set 5.360x speedup, step: 1
Epoch 17/300 |loss: 0.001785| train set 5.247x speedup, test set 4.087x speedup, val set 5.319x speedup, step: 2
Epoch 18/300 |loss: 0.001591| train set 5.268x speedup, test set 4.094x speedup, val set 5.364x speedup, step: 1
Epoch 19/300 |loss: 0.001990| train set 5.199x speedup, test set 4.057x speedup, val set 5.285x speedup, step: 2
Epoch 20/300 |loss: 0.001115| train set 4.914x speedup, test set 3.919x speedup, val set 4.773x speedup, step: 3
Epoch 21/300 |loss: 0.001003| train set 5.325x speedup, test set 4.131x speedup, val set 5.399x speedup, step: 1
Epoch 22/300 |loss: 0.001170| train set 5.237x speedup, test set 4.076x speedup, val set 5.286x speedup, step: 2
Epoch 23/300 |loss: 0.000862| train set 5.265x speedup, test set 4.094x speedup, val set 5.364x speedup, step: 3
Epoch 24/300 |loss: 0.000859| train set 5.324x speedup, test set 4.131x speedup, val set 5.399x speedup, step: 1
Epoch 25/300 |loss: 0.000716| train set 5.324x speedup, test set 4.131x speedup, val set 5.399x speedup, step: 1
Epoch 26/300 |loss: 0.000648| train set 5.312x speedup, test set 4.126x speedup, val set 5.385x speedup, step: 2
Epoch 27/300 |loss: 0.000626| train set 5.326x speedup, test set 4.127x speedup, val set 5.403x speedup, step: 1
Epoch 28/300 |loss: 0.000741| train set 5.325x speedup, test set 4.130x speedup, val set 5.400x speedup, step: 2
Epoch 29/300 |loss: 0.000757| train set 5.224x speedup, test set 4.076x speedup, val set 5.287x speedup, step: 3
Epoch 30/300 |loss: 0.000704| train set 5.308x speedup, test set 4.115x speedup, val set 5.364x speedup, step: 4
Epoch 31/300 |loss: 0.000738| train set 5.321x speedup, test set 4.124x speedup, val set 5.396x speedup, step: 5
Epoch 32/300 |loss: 0.000770| train set 5.325x speedup, test set 4.132x speedup, val set 5.399x speedup, step: 6
Epoch 33/300 |loss: 0.000621| train set 5.308x speedup, test set 4.117x speedup, val set 5.360x speedup, step: 7
Epoch 34/300 |loss: 0.000568| train set 5.267x speedup, test set 4.099x speedup, val set 5.361x speedup, step: 8
Epoch 35/300 |loss: 0.000587| train set 5.324x speedup, test set 4.131x speedup, val set 5.400x speedup, step: 9
Epoch 36/300 |loss: 0.000644| train set 5.300x speedup, test set 4.119x speedup, val set 5.349x speedup, step: 10
Epoch 37/300 |loss: 0.000599| train set 5.325x speedup, test set 4.127x speedup, val set 5.403x speedup, step: 1
Epoch 38/300 |loss: 0.000645| train set 5.307x speedup, test set 4.119x speedup, val set 5.361x speedup, step: 2
Epoch 39/300 |loss: 0.000603| train set 5.321x speedup, test set 4.131x speedup, val set 5.373x speedup, step: 3
Epoch 40/300 |loss: 0.000646| train set 5.326x speedup, test set 4.127x speedup, val set 5.404x speedup, step: 1
Epoch 41/300 |loss: 0.000640| train set 5.326x speedup, test set 4.127x speedup, val set 5.403x speedup, step: 2
Epoch 42/300 |loss: 0.000666| train set 5.317x speedup, test set 4.128x speedup, val set 5.394x speedup, step: 3
early stopping at epoch 42
Training per epoch cost 0.414 s
Optimal speedup on test set is 5.720x
01, opt runtime 34.775s, model runtime 37.830s, pg runtime 37.830s, speedup 1.000x
02, opt runtime 31.109s, model runtime 31.109s, pg runtime 31.109s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 30.267s, model runtime 30.267s, pg runtime 100.885s, speedup 3.333x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.377s, model runtime 8.474s, pg runtime 28.655s, speedup 3.382x
09, opt runtime 5.543s, model runtime 5.543s, pg runtime 5.543s, speedup 1.000x
10, opt runtime 5.237s, model runtime 5.237s, pg runtime 5.237s, speedup 1.000x
11, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.258s, model runtime 3.312s, pg runtime 18.141s, speedup 5.478x
15, opt runtime 53.298s, model runtime 180.921s, pg runtime 148.707s, speedup 0.822x
16, opt runtime 53.440s, model runtime 165.749s, pg runtime 140.742s, speedup 0.849x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.347s, model runtime 1.438s, pg runtime 1.438s, speedup 1.000x
20, opt runtime 1.428s, model runtime 1.428s, pg runtime 1.428s, speedup 1.000x
21, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 6.250s, model runtime 6.250s, pg runtime 32.969s, speedup 5.275x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.642s, model runtime 1.752s, pg runtime 1.752s, speedup 1.000x
26, opt runtime 1.423s, model runtime 1.423s, pg runtime 1.423s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.799s, pg runtime 7.799s, speedup 1.000x
28, opt runtime 7.199s, model runtime 7.619s, pg runtime 7.619s, speedup 1.000x
29, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
30, opt runtime 5.539s, model runtime 5.539s, pg runtime 5.539s, speedup 1.000x
31, opt runtime 24.840s, model runtime 24.840s, pg runtime 626.529s, speedup 25.222x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 18.690s, model runtime 18.690s, pg runtime 651.942s, speedup 34.881x
36, opt runtime 16.280s, model runtime 16.280s, pg runtime 634.990s, speedup 39.005x
37, opt runtime 19.707s, model runtime 19.707s, pg runtime 19.707s, speedup 1.000x
38, opt runtime 18.262s, model runtime 18.262s, pg runtime 18.262s, speedup 1.000x
39, opt runtime 1.088s, model runtime 1.206s, pg runtime 1.206s, speedup 1.000x
40, opt runtime 1.086s, model runtime 1.181s, pg runtime 1.181s, speedup 1.000x
====================
best train speedup epoch: 27, train speedup 5.326, test speedup 4.127, val speedup 5.403
best test speedup epoch: 14, train speedup 4.091, test speedup 4.394, val speedup 4.194
best validation speedup epoch: 40, train speedup 5.326, test speedup 4.127, val speedup 5.404
last model at epoch 42, train speedup 5.317, test speedup 4.128, val speedup 5.394
execution cost 0:00:40.549258
==================================================
all print will write to path record/postgresql/TPCH/TCNN/slow_split/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/slow_split/point
seed: 42
shuffle_num: 1
slow: 1
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

load TPCH...
[0, 1, 2, 4, 5, 9] [6, 8] [7 3]
[0, 1, 3, 4, 7, 9] [5, 2] [6 8]
[0, 2, 5, 6, 7, 8] [1, 3] [4 9]
[0, 2, 3, 4, 6, 7, 8] [1, 9] [5 5]
[0, 3, 4, 5, 6, 9] [7, 2] [8 1]
[0, 1, 3, 4, 6, 8] [5, 9] [2 7]
[0, 2, 4, 5, 7, 8, 9] [1, 6] [3 3]
[1, 3, 4, 5, 7, 8] [0, 2] [9 6]
[2, 3, 4, 6, 7, 8] [1, 0] [5 9]
[0, 1, 4, 5, 6, 7] [3, 9] [8 2]
[0, 1, 2, 3, 8, 9] [4, 6] [7 5]
[0, 2, 3, 4, 5, 6] [9, 8] [1 7]
[0, 3, 4, 6, 8, 9] [1, 2] [5 7]
[1, 3, 4, 5, 8, 9] [0, 7] [6 2]
[0, 1, 4, 6, 7, 8] [3, 2] [9 5]
[1, 3, 4, 6, 7, 9] [8, 2] [5 0]
[0, 2, 4, 6, 7, 9] [8, 5] [3 1]
[0, 1, 2, 4, 8, 9] [5, 3] [7 6]
[1, 2, 4, 5, 6, 8] [7, 9] [3 0]
[1, 4, 5, 7, 8, 9] [2, 6] [0 3]
load TPCH succ
train, test, validation (122, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.549648, and there are 5978 training samples
in channel 9
Epoch 0/300 |loss: 0.050603| train set 2.344x speedup, test set 2.756x speedup, val set 2.285x speedup, step: 1
Epoch 1/300 |loss: 0.017820| train set 2.851x speedup, test set 3.190x speedup, val set 2.877x speedup, step: 1
Epoch 2/300 |loss: 0.009639| train set 2.790x speedup, test set 3.332x speedup, val set 2.794x speedup, step: 2
Epoch 3/300 |loss: 0.006159| train set 3.215x speedup, test set 3.647x speedup, val set 3.201x speedup, step: 1
Epoch 4/300 |loss: 0.004855| train set 3.049x speedup, test set 3.703x speedup, val set 3.056x speedup, step: 2
Epoch 5/300 |loss: 0.004916| train set 3.702x speedup, test set 3.983x speedup, val set 3.462x speedup, step: 1
Epoch 6/300 |loss: 0.004300| train set 3.534x speedup, test set 3.989x speedup, val set 3.565x speedup, step: 1
Epoch 7/300 |loss: 0.003282| train set 3.827x speedup, test set 4.152x speedup, val set 3.787x speedup, step: 1
Epoch 8/300 |loss: 0.002883| train set 3.564x speedup, test set 4.020x speedup, val set 3.528x speedup, step: 2
Epoch 9/300 |loss: 0.002586| train set 3.507x speedup, test set 4.107x speedup, val set 4.673x speedup, step: 1
Epoch 10/300 |loss: 0.002204| train set 3.519x speedup, test set 4.153x speedup, val set 3.599x speedup, step: 2
Epoch 11/300 |loss: 0.002908| train set 4.776x speedup, test set 4.079x speedup, val set 4.746x speedup, step: 1
Epoch 12/300 |loss: 0.002474| train set 3.681x speedup, test set 4.175x speedup, val set 3.746x speedup, step: 2
Epoch 13/300 |loss: 0.002585| train set 4.918x speedup, test set 3.919x speedup, val set 4.774x speedup, step: 1
Epoch 14/300 |loss: 0.002105| train set 4.086x speedup, test set 4.130x speedup, val set 4.190x speedup, step: 2
Epoch 15/300 |loss: 0.001764| train set 4.920x speedup, test set 3.925x speedup, val set 4.774x speedup, step: 3
Epoch 16/300 |loss: 0.001514| train set 5.198x speedup, test set 4.057x speedup, val set 5.286x speedup, step: 1
Epoch 17/300 |loss: 0.001792| train set 5.255x speedup, test set 4.089x speedup, val set 5.324x speedup, step: 1
Epoch 18/300 |loss: 0.001560| train set 5.268x speedup, test set 4.095x speedup, val set 5.364x speedup, step: 1
Epoch 19/300 |loss: 0.001816| train set 5.254x speedup, test set 4.089x speedup, val set 5.324x speedup, step: 2
Epoch 20/300 |loss: 0.001031| train set 4.914x speedup, test set 3.919x speedup, val set 4.774x speedup, step: 3
Epoch 21/300 |loss: 0.001011| train set 5.253x speedup, test set 4.093x speedup, val set 5.320x speedup, step: 4
Epoch 22/300 |loss: 0.001078| train set 5.234x speedup, test set 4.081x speedup, val set 5.280x speedup, step: 5
Epoch 23/300 |loss: 0.000857| train set 5.187x speedup, test set 4.053x speedup, val set 5.274x speedup, step: 6
Epoch 24/300 |loss: 0.000907| train set 5.319x speedup, test set 4.399x speedup, val set 5.391x speedup, step: 1
Epoch 25/300 |loss: 0.000713| train set 5.325x speedup, test set 4.132x speedup, val set 5.399x speedup, step: 1
Epoch 26/300 |loss: 0.000649| train set 5.320x speedup, test set 4.131x speedup, val set 5.393x speedup, step: 2
Epoch 27/300 |loss: 0.000593| train set 5.326x speedup, test set 4.127x speedup, val set 5.403x speedup, step: 1
Epoch 28/300 |loss: 0.000793| train set 5.325x speedup, test set 4.132x speedup, val set 5.400x speedup, step: 2
Epoch 29/300 |loss: 0.000719| train set 5.308x speedup, test set 4.115x speedup, val set 5.365x speedup, step: 3
Epoch 30/300 |loss: 0.000697| train set 5.320x speedup, test set 4.128x speedup, val set 5.391x speedup, step: 4
Epoch 31/300 |loss: 0.000679| train set 5.326x speedup, test set 4.127x speedup, val set 5.404x speedup, step: 1
Epoch 32/300 |loss: 0.000829| train set 5.325x speedup, test set 4.132x speedup, val set 5.399x speedup, step: 2
Epoch 33/300 |loss: 0.000639| train set 5.307x speedup, test set 4.117x speedup, val set 5.354x speedup, step: 3
Epoch 34/300 |loss: 0.000575| train set 5.267x speedup, test set 4.100x speedup, val set 5.342x speedup, step: 4
Epoch 35/300 |loss: 0.000610| train set 5.324x speedup, test set 4.129x speedup, val set 5.400x speedup, step: 5
Epoch 36/300 |loss: 0.000630| train set 5.250x speedup, test set 4.088x speedup, val set 5.303x speedup, step: 6
early stopping at epoch 36
Training per epoch cost 0.423 s
Optimal speedup on test set is 5.720x
01, opt runtime 34.775s, model runtime 37.830s, pg runtime 37.830s, speedup 1.000x
02, opt runtime 31.109s, model runtime 31.109s, pg runtime 31.109s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 30.267s, model runtime 30.267s, pg runtime 100.885s, speedup 3.333x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.377s, model runtime 8.474s, pg runtime 28.655s, speedup 3.382x
09, opt runtime 5.543s, model runtime 5.543s, pg runtime 5.543s, speedup 1.000x
10, opt runtime 5.237s, model runtime 5.237s, pg runtime 5.237s, speedup 1.000x
11, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.258s, model runtime 3.312s, pg runtime 18.141s, speedup 5.478x
15, opt runtime 53.298s, model runtime 180.921s, pg runtime 148.707s, speedup 0.822x
16, opt runtime 53.440s, model runtime 165.749s, pg runtime 140.742s, speedup 0.849x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.347s, model runtime 1.438s, pg runtime 1.438s, speedup 1.000x
20, opt runtime 1.428s, model runtime 1.428s, pg runtime 1.428s, speedup 1.000x
21, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 6.250s, model runtime 6.250s, pg runtime 32.969s, speedup 5.275x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.642s, model runtime 1.752s, pg runtime 1.752s, speedup 1.000x
26, opt runtime 1.423s, model runtime 1.423s, pg runtime 1.423s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.799s, pg runtime 7.799s, speedup 1.000x
28, opt runtime 7.199s, model runtime 7.619s, pg runtime 7.619s, speedup 1.000x
29, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
30, opt runtime 5.539s, model runtime 5.539s, pg runtime 5.539s, speedup 1.000x
31, opt runtime 24.840s, model runtime 24.840s, pg runtime 626.529s, speedup 25.222x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 18.690s, model runtime 18.690s, pg runtime 651.942s, speedup 34.881x
36, opt runtime 16.280s, model runtime 16.280s, pg runtime 634.990s, speedup 39.005x
37, opt runtime 19.707s, model runtime 19.707s, pg runtime 19.707s, speedup 1.000x
38, opt runtime 18.262s, model runtime 18.262s, pg runtime 18.262s, speedup 1.000x
39, opt runtime 1.088s, model runtime 1.206s, pg runtime 1.206s, speedup 1.000x
40, opt runtime 1.086s, model runtime 1.181s, pg runtime 1.181s, speedup 1.000x
====================
best train speedup epoch: 27, train speedup 5.326, test speedup 4.127, val speedup 5.403
best test speedup epoch: 24, train speedup 5.319, test speedup 4.399, val speedup 5.391
best validation speedup epoch: 31, train speedup 5.326, test speedup 4.127, val speedup 5.404
last model at epoch 36, train speedup 5.250, test speedup 4.088, val speedup 5.303
execution cost 0:00:35.741459
==================================================
all print will write to path record/postgresql/TPCH/TCNN/slow_split/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/slow_split/point
seed: 42
shuffle_num: 1
slow: 1
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

load TPCH...
[0, 1, 2, 4, 5, 9] [6, 8] [7 3]
[0, 1, 3, 4, 7, 9] [5, 2] [6 8]
[0, 2, 5, 6, 7, 8] [1, 3] [4 9]
[0, 2, 3, 4, 6, 7, 8] [1, 9] [5 5]
[0, 3, 4, 5, 6, 9] [7, 2] [8 1]
[0, 1, 3, 4, 6, 8] [5, 9] [2 7]
[0, 2, 4, 5, 7, 8, 9] [1, 6] [3 3]
[1, 3, 4, 5, 7, 8] [0, 2] [9 6]
[2, 3, 4, 6, 7, 8] [1, 0] [5 9]
[0, 1, 4, 5, 6, 7] [3, 9] [8 2]
[0, 1, 2, 3, 8, 9] [4, 6] [7 5]
[0, 2, 3, 4, 5, 6] [9, 8] [1 7]
[0, 3, 4, 6, 8, 9] [1, 2] [5 7]
[1, 3, 4, 5, 8, 9] [0, 7] [6 2]
[0, 1, 4, 6, 7, 8] [3, 2] [9 5]
[1, 3, 4, 6, 7, 9] [8, 2] [5 0]
[0, 2, 4, 6, 7, 9] [8, 5] [3 1]
[0, 1, 2, 4, 8, 9] [5, 3] [7 6]
[1, 2, 4, 5, 6, 8] [7, 9] [3 0]
[1, 4, 5, 7, 8, 9] [2, 6] [0 3]
load TPCH succ
train, test, validation (122, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.498986, and there are 5978 training samples
in channel 9
Epoch 0/300 |loss: 0.050603| train set 2.344x speedup, test set 2.756x speedup, val set 2.285x speedup, step: 1
Epoch 1/300 |loss: 0.017820| train set 2.851x speedup, test set 3.190x speedup, val set 2.877x speedup, step: 1
Epoch 2/300 |loss: 0.009638| train set 2.790x speedup, test set 3.332x speedup, val set 2.794x speedup, step: 2
Epoch 3/300 |loss: 0.006189| train set 3.475x speedup, test set 3.905x speedup, val set 3.557x speedup, step: 1
Epoch 4/300 |loss: 0.004777| train set 3.049x speedup, test set 3.622x speedup, val set 3.056x speedup, step: 2
Epoch 5/300 |loss: 0.005024| train set 3.611x speedup, test set 3.828x speedup, val set 3.716x speedup, step: 1
Epoch 6/300 |loss: 0.004194| train set 3.289x speedup, test set 3.991x speedup, val set 3.305x speedup, step: 2
Epoch 7/300 |loss: 0.003220| train set 3.827x speedup, test set 4.152x speedup, val set 3.787x speedup, step: 1
Epoch 8/300 |loss: 0.002827| train set 3.701x speedup, test set 4.157x speedup, val set 3.777x speedup, step: 2
Epoch 9/300 |loss: 0.002511| train set 3.549x speedup, test set 4.149x speedup, val set 3.495x speedup, step: 3
Epoch 10/300 |loss: 0.002231| train set 3.813x speedup, test set 4.162x speedup, val set 3.920x speedup, step: 1
Epoch 11/300 |loss: 0.002698| train set 4.904x speedup, test set 4.056x speedup, val set 4.744x speedup, step: 1
Epoch 12/300 |loss: 0.002680| train set 3.522x speedup, test set 4.115x speedup, val set 3.477x speedup, step: 2
Epoch 13/300 |loss: 0.003057| train set 4.914x speedup, test set 4.162x speedup, val set 4.774x speedup, step: 1
Epoch 14/300 |loss: 0.002216| train set 4.054x speedup, test set 4.362x speedup, val set 4.165x speedup, step: 2
Epoch 15/300 |loss: 0.001755| train set 4.913x speedup, test set 4.167x speedup, val set 4.771x speedup, step: 3
Epoch 16/300 |loss: 0.001517| train set 5.138x speedup, test set 4.038x speedup, val set 5.190x speedup, step: 1
Epoch 17/300 |loss: 0.001709| train set 5.190x speedup, test set 4.317x speedup, val set 5.277x speedup, step: 1
Epoch 18/300 |loss: 0.001692| train set 5.268x speedup, test set 4.094x speedup, val set 5.364x speedup, step: 1
Epoch 19/300 |loss: 0.002024| train set 5.249x speedup, test set 4.238x speedup, val set 5.313x speedup, step: 2
Epoch 20/300 |loss: 0.001066| train set 4.914x speedup, test set 3.919x speedup, val set 4.774x speedup, step: 3
Epoch 21/300 |loss: 0.001006| train set 5.326x speedup, test set 4.126x speedup, val set 5.403x speedup, step: 1
Epoch 22/300 |loss: 0.001037| train set 5.250x speedup, test set 4.234x speedup, val set 5.324x speedup, step: 2
Epoch 23/300 |loss: 0.000832| train set 5.198x speedup, test set 4.199x speedup, val set 5.286x speedup, step: 3
Epoch 24/300 |loss: 0.000904| train set 5.303x speedup, test set 4.264x speedup, val set 5.360x speedup, step: 4
Epoch 25/300 |loss: 0.000735| train set 5.306x speedup, test set 4.267x speedup, val set 5.361x speedup, step: 5
Epoch 26/300 |loss: 0.000651| train set 5.320x speedup, test set 4.131x speedup, val set 5.393x speedup, step: 6
Epoch 27/300 |loss: 0.000597| train set 5.325x speedup, test set 4.126x speedup, val set 5.403x speedup, step: 1
Epoch 28/300 |loss: 0.000680| train set 5.325x speedup, test set 4.132x speedup, val set 5.399x speedup, step: 2
Epoch 29/300 |loss: 0.000695| train set 5.207x speedup, test set 4.063x speedup, val set 5.250x speedup, step: 3
Epoch 30/300 |loss: 0.000692| train set 5.303x speedup, test set 4.117x speedup, val set 5.353x speedup, step: 4
Epoch 31/300 |loss: 0.000818| train set 5.326x speedup, test set 4.126x speedup, val set 5.403x speedup, step: 5
Epoch 32/300 |loss: 0.000766| train set 5.324x speedup, test set 4.132x speedup, val set 5.380x speedup, step: 6
Epoch 33/300 |loss: 0.000645| train set 5.308x speedup, test set 4.116x speedup, val set 5.365x speedup, step: 7
Epoch 34/300 |loss: 0.000601| train set 5.267x speedup, test set 4.245x speedup, val set 5.341x speedup, step: 8
Epoch 35/300 |loss: 0.000598| train set 5.325x speedup, test set 4.279x speedup, val set 5.399x speedup, step: 9
Epoch 36/300 |loss: 0.000614| train set 5.264x speedup, test set 4.098x speedup, val set 5.352x speedup, step: 10
early stopping at epoch 36
Training per epoch cost 0.416 s
Optimal speedup on test set is 5.720x
01, opt runtime 34.775s, model runtime 37.830s, pg runtime 37.830s, speedup 1.000x
02, opt runtime 31.109s, model runtime 31.109s, pg runtime 31.109s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 30.267s, model runtime 30.267s, pg runtime 100.885s, speedup 3.333x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.377s, model runtime 8.474s, pg runtime 28.655s, speedup 3.382x
09, opt runtime 5.543s, model runtime 5.543s, pg runtime 5.543s, speedup 1.000x
10, opt runtime 5.237s, model runtime 5.237s, pg runtime 5.237s, speedup 1.000x
11, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.258s, model runtime 3.312s, pg runtime 18.141s, speedup 5.478x
15, opt runtime 53.298s, model runtime 180.921s, pg runtime 148.707s, speedup 0.822x
16, opt runtime 53.440s, model runtime 165.749s, pg runtime 140.742s, speedup 0.849x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.347s, model runtime 1.398s, pg runtime 1.438s, speedup 1.028x
20, opt runtime 1.428s, model runtime 1.645s, pg runtime 1.428s, speedup 0.868x
21, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 6.250s, model runtime 6.250s, pg runtime 32.969s, speedup 5.275x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.642s, model runtime 1.752s, pg runtime 1.752s, speedup 1.000x
26, opt runtime 1.423s, model runtime 1.423s, pg runtime 1.423s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.799s, pg runtime 7.799s, speedup 1.000x
28, opt runtime 7.199s, model runtime 7.619s, pg runtime 7.619s, speedup 1.000x
29, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
30, opt runtime 5.539s, model runtime 5.539s, pg runtime 5.539s, speedup 1.000x
31, opt runtime 24.840s, model runtime 24.840s, pg runtime 626.529s, speedup 25.222x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 18.690s, model runtime 18.690s, pg runtime 651.942s, speedup 34.881x
36, opt runtime 16.280s, model runtime 16.280s, pg runtime 634.990s, speedup 39.005x
37, opt runtime 19.707s, model runtime 19.707s, pg runtime 19.707s, speedup 1.000x
38, opt runtime 18.262s, model runtime 18.262s, pg runtime 18.262s, speedup 1.000x
39, opt runtime 1.088s, model runtime 1.206s, pg runtime 1.206s, speedup 1.000x
40, opt runtime 1.086s, model runtime 1.181s, pg runtime 1.181s, speedup 1.000x
====================
best train speedup epoch: 21, train speedup 5.326, test speedup 4.126, val speedup 5.403
best test speedup epoch: 14, train speedup 4.054, test speedup 4.362, val speedup 4.165
best validation speedup epoch: 27, train speedup 5.325, test speedup 4.126, val speedup 5.403
last model at epoch 36, train speedup 5.264, test speedup 4.098, val speedup 5.352
execution cost 0:00:35.339652
==================================================
all print will write to path record/postgresql/TPCH/TCNN/slow_split/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/slow_split/point
seed: 42
shuffle_num: 1
slow: 1
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

load TPCH...
[0, 1, 2, 4, 5, 9] [6, 8] [7 3]
[0, 1, 3, 4, 7, 9] [5, 2] [6 8]
[0, 2, 5, 6, 7, 8] [1, 3] [4 9]
[0, 2, 3, 4, 6, 7, 8] [1, 9] [5 5]
[0, 3, 4, 5, 6, 9] [7, 2] [8 1]
[0, 1, 3, 4, 6, 8] [5, 9] [2 7]
[0, 2, 4, 5, 7, 8, 9] [1, 6] [3 3]
[1, 3, 4, 5, 7, 8] [0, 2] [9 6]
[2, 3, 4, 6, 7, 8] [1, 0] [5 9]
[0, 1, 4, 5, 6, 7] [3, 9] [8 2]
[0, 1, 2, 3, 8, 9] [4, 6] [7 5]
[0, 2, 3, 4, 5, 6] [9, 8] [1 7]
[0, 3, 4, 6, 8, 9] [1, 2] [5 7]
[1, 3, 4, 5, 8, 9] [0, 7] [6 2]
[0, 1, 4, 6, 7, 8] [3, 2] [9 5]
[1, 3, 4, 6, 7, 9] [8, 2] [5 0]
[0, 2, 4, 6, 7, 9] [8, 5] [3 1]
[0, 1, 2, 4, 8, 9] [5, 3] [7 6]
[1, 2, 4, 5, 6, 8] [7, 9] [3 0]
[1, 4, 5, 7, 8, 9] [2, 6] [0 3]
load TPCH succ
train, test, validation (122, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.499429, and there are 5978 training samples
in channel 9
Epoch 0/300 |loss: 0.050603| train set 2.344x speedup, test set 2.756x speedup, val set 2.285x speedup, step: 1
Epoch 1/300 |loss: 0.017820| train set 2.851x speedup, test set 3.190x speedup, val set 2.877x speedup, step: 1
Epoch 2/300 |loss: 0.009638| train set 2.790x speedup, test set 3.332x speedup, val set 2.794x speedup, step: 2
Epoch 3/300 |loss: 0.006189| train set 3.475x speedup, test set 3.905x speedup, val set 3.557x speedup, step: 1
Epoch 4/300 |loss: 0.004777| train set 3.049x speedup, test set 3.622x speedup, val set 3.056x speedup, step: 2
Epoch 5/300 |loss: 0.005024| train set 3.611x speedup, test set 3.828x speedup, val set 3.716x speedup, step: 1
Epoch 6/300 |loss: 0.004199| train set 3.289x speedup, test set 3.991x speedup, val set 3.305x speedup, step: 2
Epoch 7/300 |loss: 0.003262| train set 3.748x speedup, test set 4.077x speedup, val set 3.788x speedup, step: 1
Epoch 8/300 |loss: 0.002908| train set 3.688x speedup, test set 4.160x speedup, val set 3.768x speedup, step: 2
Epoch 9/300 |loss: 0.002542| train set 3.548x speedup, test set 4.147x speedup, val set 3.494x speedup, step: 3
Epoch 10/300 |loss: 0.002292| train set 3.766x speedup, test set 4.119x speedup, val set 3.875x speedup, step: 1
Epoch 11/300 |loss: 0.002765| train set 4.824x speedup, test set 3.877x speedup, val set 4.674x speedup, step: 1
Epoch 12/300 |loss: 0.002648| train set 3.792x speedup, test set 4.005x speedup, val set 3.752x speedup, step: 2
Epoch 13/300 |loss: 0.002864| train set 4.930x speedup, test set 3.925x speedup, val set 4.919x speedup, step: 1
Epoch 14/300 |loss: 0.002134| train set 4.091x speedup, test set 4.394x speedup, val set 4.194x speedup, step: 2
Epoch 15/300 |loss: 0.001663| train set 4.919x speedup, test set 4.168x speedup, val set 4.774x speedup, step: 3
Epoch 16/300 |loss: 0.001524| train set 5.157x speedup, test set 4.052x speedup, val set 5.230x speedup, step: 1
Epoch 17/300 |loss: 0.001873| train set 5.326x speedup, test set 4.274x speedup, val set 5.403x speedup, step: 1
Epoch 18/300 |loss: 0.001588| train set 5.268x speedup, test set 4.095x speedup, val set 5.364x speedup, step: 2
Epoch 19/300 |loss: 0.001712| train set 5.307x speedup, test set 4.112x speedup, val set 5.352x speedup, step: 3
Epoch 20/300 |loss: 0.000961| train set 4.914x speedup, test set 3.919x speedup, val set 4.774x speedup, step: 4
Epoch 21/300 |loss: 0.000936| train set 5.316x speedup, test set 4.128x speedup, val set 5.393x speedup, step: 5
Epoch 22/300 |loss: 0.001081| train set 5.301x speedup, test set 4.113x speedup, val set 5.360x speedup, step: 6
Epoch 23/300 |loss: 0.000880| train set 5.268x speedup, test set 4.360x speedup, val set 5.364x speedup, step: 7
Epoch 24/300 |loss: 0.000900| train set 5.307x speedup, test set 4.389x speedup, val set 5.361x speedup, step: 8
Epoch 25/300 |loss: 0.000699| train set 5.325x speedup, test set 4.280x speedup, val set 5.399x speedup, step: 9
Epoch 26/300 |loss: 0.000631| train set 5.317x speedup, test set 4.128x speedup, val set 5.392x speedup, step: 10
Epoch 27/300 |loss: 0.000600| train set 5.326x speedup, test set 4.275x speedup, val set 5.403x speedup, step: 1
Epoch 28/300 |loss: 0.000793| train set 5.325x speedup, test set 5.568x speedup, val set 5.400x speedup, step: 2
Epoch 29/300 |loss: 0.000791| train set 5.229x speedup, test set 4.078x speedup, val set 5.295x speedup, step: 3
Epoch 30/300 |loss: 0.000743| train set 5.303x speedup, test set 4.117x speedup, val set 5.353x speedup, step: 4
Epoch 31/300 |loss: 0.000699| train set 5.326x speedup, test set 4.126x speedup, val set 5.403x speedup, step: 5
Epoch 32/300 |loss: 0.000771| train set 5.267x speedup, test set 4.245x speedup, val set 5.361x speedup, step: 6
Epoch 33/300 |loss: 0.000612| train set 5.307x speedup, test set 4.390x speedup, val set 5.361x speedup, step: 7
Epoch 34/300 |loss: 0.000572| train set 5.267x speedup, test set 4.099x speedup, val set 5.360x speedup, step: 8
Epoch 35/300 |loss: 0.000600| train set 5.325x speedup, test set 4.280x speedup, val set 5.399x speedup, step: 9
Epoch 36/300 |loss: 0.000642| train set 5.321x speedup, test set 4.129x speedup, val set 5.400x speedup, step: 10
Epoch 37/300 |loss: 0.000630| train set 5.250x speedup, test set 4.085x speedup, val set 5.323x speedup, step: 11
Epoch 38/300 |loss: 0.000605| train set 5.325x speedup, test set 4.132x speedup, val set 5.400x speedup, step: 12
Epoch 39/300 |loss: 0.000592| train set 5.304x speedup, test set 4.115x speedup, val set 5.346x speedup, step: 13
Epoch 40/300 |loss: 0.000630| train set 5.300x speedup, test set 4.117x speedup, val set 5.356x speedup, step: 14
Epoch 41/300 |loss: 0.000655| train set 5.325x speedup, test set 4.132x speedup, val set 5.399x speedup, step: 15
Epoch 42/300 |loss: 0.000657| train set 5.317x speedup, test set 4.129x speedup, val set 5.394x speedup, step: 16
early stopping at epoch 42
Training per epoch cost 0.417 s
Optimal speedup on test set is 5.720x
01, opt runtime 34.775s, model runtime 37.830s, pg runtime 37.830s, speedup 1.000x
02, opt runtime 31.109s, model runtime 31.109s, pg runtime 31.109s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 30.267s, model runtime 30.267s, pg runtime 100.885s, speedup 3.333x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.377s, model runtime 8.474s, pg runtime 28.655s, speedup 3.382x
09, opt runtime 5.543s, model runtime 5.543s, pg runtime 5.543s, speedup 1.000x
10, opt runtime 5.237s, model runtime 5.237s, pg runtime 5.237s, speedup 1.000x
11, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.258s, model runtime 3.312s, pg runtime 18.141s, speedup 5.478x
15, opt runtime 53.298s, model runtime 148.707s, pg runtime 148.707s, speedup 1.000x
16, opt runtime 53.440s, model runtime 165.749s, pg runtime 140.742s, speedup 0.849x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.347s, model runtime 1.347s, pg runtime 1.438s, speedup 1.067x
20, opt runtime 1.428s, model runtime 1.595s, pg runtime 1.428s, speedup 0.896x
21, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 6.250s, model runtime 6.250s, pg runtime 32.969s, speedup 5.275x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.642s, model runtime 1.752s, pg runtime 1.752s, speedup 1.000x
26, opt runtime 1.423s, model runtime 1.423s, pg runtime 1.423s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.799s, pg runtime 7.799s, speedup 1.000x
28, opt runtime 7.199s, model runtime 7.619s, pg runtime 7.619s, speedup 1.000x
29, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
30, opt runtime 5.539s, model runtime 5.539s, pg runtime 5.539s, speedup 1.000x
31, opt runtime 24.840s, model runtime 24.840s, pg runtime 626.529s, speedup 25.222x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 18.690s, model runtime 18.690s, pg runtime 651.942s, speedup 34.881x
36, opt runtime 16.280s, model runtime 16.280s, pg runtime 634.990s, speedup 39.005x
37, opt runtime 19.707s, model runtime 19.707s, pg runtime 19.707s, speedup 1.000x
38, opt runtime 18.262s, model runtime 18.262s, pg runtime 18.262s, speedup 1.000x
39, opt runtime 1.088s, model runtime 1.088s, pg runtime 1.206s, speedup 1.109x
40, opt runtime 1.086s, model runtime 1.086s, pg runtime 1.181s, speedup 1.088x
====================
best train speedup epoch: 27, train speedup 5.326, test speedup 4.275, val speedup 5.403
best test speedup epoch: 28, train speedup 5.325, test speedup 5.568, val speedup 5.400
best validation speedup epoch: 27, train speedup 5.326, test speedup 4.275, val speedup 5.403
last model at epoch 42, train speedup 5.317, test speedup 4.129, val speedup 5.394
execution cost 0:00:40.269742
==================================================
all print will write to path record/postgresql/TPCH/TCNN/slow_split/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/slow_split/point
seed: 42
shuffle_num: 1
slow: 1
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1d.sql' '10c.sql' '11c.sql' '12c.sql' '13d.sql' '14c.sql' '15d.sql'
 '16b.sql' '17a.sql' '18c.sql' '19d.sql' '2d.sql' '20c.sql' '21a.sql'
 '22c.sql' '23c.sql' '24a.sql' '25c.sql' '26c.sql' '27c.sql' '28c.sql'
 '29b.sql' '3c.sql' '30c.sql' '31c.sql' '32b.sql' '33c.sql' '4a.sql'
 '5c.sql' '6d.sql' '7c.sql' '8c.sql' '9d.sql']
load JOB succ
load TPCH...
[2, 3, 4, 5, 7, 9] [6, 8] [1, 0]
[0, 3, 4, 7, 8, 9] [5, 2] [6, 1]
[0, 4, 6, 7, 8, 9] [1, 3] [5, 2]
[0, 3, 4, 5, 7, 8] [1, 9] [2, 6]
[0, 3, 4, 6, 8, 9] [7, 2] [1, 5]
[1, 2, 3, 4, 6, 8] [5, 9] [7, 0]
[2, 3, 4, 5, 7, 8] [1, 6] [0, 9]
[1, 4, 6, 7, 8, 9] [0, 2] [5, 3]
[3, 4, 5, 7, 8, 9] [1, 0] [2, 6]
[0, 1, 2, 5, 7, 8] [3, 9] [4, 6]
[0, 2, 3, 5, 7, 9] [4, 6] [8, 1]
[0, 1, 2, 3, 5, 6] [9, 8] [7, 4]
[0, 3, 4, 5, 7, 9] [1, 2] [6, 8]
[2, 3, 4, 5, 6, 9] [0, 7] [1, 8]
[0, 1, 5, 6, 8, 9] [3, 2] [4, 7]
[0, 1, 4, 5, 6, 9] [8, 2] [7, 3]
[0, 2, 3, 6, 7, 9] [8, 5] [4, 1]
[0, 1, 2, 6, 7, 9] [5, 3] [4, 8]
[1, 2, 3, 4, 6, 8] [7, 9] [5, 0]
[0, 3, 5, 7, 8, 9] [2, 6] [1, 4]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.728945, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.048859| train set 2.499x speedup, test set 2.867x speedup, val set 2.708x speedup, step: 1
Epoch 1/300 |loss: 0.019868| train set 2.561x speedup, test set 2.910x speedup, val set 2.683x speedup, step: 2
Epoch 2/300 |loss: 0.010596| train set 3.168x speedup, test set 3.399x speedup, val set 3.408x speedup, step: 1
Epoch 3/300 |loss: 0.007215| train set 3.269x speedup, test set 3.785x speedup, val set 3.570x speedup, step: 1
Epoch 4/300 |loss: 0.005759| train set 3.647x speedup, test set 4.039x speedup, val set 3.921x speedup, step: 1
Epoch 5/300 |loss: 0.003858| train set 3.117x speedup, test set 3.660x speedup, val set 3.395x speedup, step: 2
Epoch 6/300 |loss: 0.003641| train set 3.375x speedup, test set 3.809x speedup, val set 3.639x speedup, step: 3
Epoch 7/300 |loss: 0.003097| train set 3.320x speedup, test set 3.572x speedup, val set 3.308x speedup, step: 4
Epoch 8/300 |loss: 0.002600| train set 3.672x speedup, test set 4.087x speedup, val set 3.979x speedup, step: 1
Epoch 9/300 |loss: 0.002337| train set 5.163x speedup, test set 4.045x speedup, val set 5.443x speedup, step: 1
Epoch 10/300 |loss: 0.002109| train set 3.672x speedup, test set 4.086x speedup, val set 3.978x speedup, step: 2
Epoch 11/300 |loss: 0.002045| train set 5.162x speedup, test set 4.041x speedup, val set 5.435x speedup, step: 3
Epoch 12/300 |loss: 0.002465| train set 5.150x speedup, test set 4.125x speedup, val set 5.313x speedup, step: 4
Epoch 13/300 |loss: 0.001913| train set 5.251x speedup, test set 4.127x speedup, val set 5.625x speedup, step: 1
Epoch 14/300 |loss: 0.002511| train set 3.313x speedup, test set 3.899x speedup, val set 3.652x speedup, step: 2
Epoch 15/300 |loss: 0.002684| train set 5.164x speedup, test set 4.082x speedup, val set 5.540x speedup, step: 3
Epoch 16/300 |loss: 0.001550| train set 5.171x speedup, test set 4.078x speedup, val set 5.540x speedup, step: 4
Epoch 17/300 |loss: 0.001555| train set 3.969x speedup, test set 4.080x speedup, val set 4.363x speedup, step: 5
Epoch 18/300 |loss: 0.001766| train set 5.156x speedup, test set 4.233x speedup, val set 5.526x speedup, step: 6
Epoch 19/300 |loss: 0.001552| train set 5.260x speedup, test set 4.097x speedup, val set 5.541x speedup, step: 7
Epoch 20/300 |loss: 0.001341| train set 3.949x speedup, test set 4.061x speedup, val set 4.347x speedup, step: 8
Epoch 21/300 |loss: 0.001088| train set 5.254x speedup, test set 5.502x speedup, val set 5.530x speedup, step: 9
Epoch 22/300 |loss: 0.001824| train set 5.256x speedup, test set 4.247x speedup, val set 5.638x speedup, step: 1
Epoch 23/300 |loss: 0.001314| train set 5.252x speedup, test set 5.561x speedup, val set 5.629x speedup, step: 2
Epoch 24/300 |loss: 0.000903| train set 4.482x speedup, test set 4.424x speedup, val set 4.937x speedup, step: 3
Epoch 25/300 |loss: 0.000804| train set 5.247x speedup, test set 5.563x speedup, val set 5.616x speedup, step: 4
Epoch 26/300 |loss: 0.000749| train set 5.262x speedup, test set 5.559x speedup, val set 5.638x speedup, step: 1
Epoch 27/300 |loss: 0.000733| train set 5.260x speedup, test set 5.556x speedup, val set 5.635x speedup, step: 2
Epoch 28/300 |loss: 0.000772| train set 5.263x speedup, test set 5.498x speedup, val set 5.539x speedup, step: 3
Epoch 29/300 |loss: 0.000811| train set 5.256x speedup, test set 5.563x speedup, val set 5.626x speedup, step: 4
Epoch 30/300 |loss: 0.000810| train set 5.254x speedup, test set 5.551x speedup, val set 5.624x speedup, step: 5
Epoch 31/300 |loss: 0.000795| train set 5.253x speedup, test set 5.568x speedup, val set 5.637x speedup, step: 6
Epoch 32/300 |loss: 0.000789| train set 5.262x speedup, test set 5.560x speedup, val set 5.637x speedup, step: 7
Epoch 33/300 |loss: 0.000691| train set 5.262x speedup, test set 5.560x speedup, val set 5.637x speedup, step: 8
Epoch 34/300 |loss: 0.000696| train set 5.267x speedup, test set 5.497x speedup, val set 5.637x speedup, step: 9
Epoch 35/300 |loss: 0.000699| train set 5.230x speedup, test set 5.478x speedup, val set 5.495x speedup, step: 10
Epoch 36/300 |loss: 0.000697| train set 5.263x speedup, test set 5.498x speedup, val set 5.539x speedup, step: 11
Epoch 37/300 |loss: 0.000800| train set 5.252x speedup, test set 5.561x speedup, val set 5.627x speedup, step: 12
Epoch 38/300 |loss: 0.000655| train set 5.256x speedup, test set 5.564x speedup, val set 5.626x speedup, step: 13
Epoch 39/300 |loss: 0.000690| train set 5.253x speedup, test set 5.567x speedup, val set 5.637x speedup, step: 14
Epoch 40/300 |loss: 0.000617| train set 5.173x speedup, test set 5.507x speedup, val set 5.663x speedup, step: 1
Epoch 41/300 |loss: 0.000715| train set 5.153x speedup, test set 5.462x speedup, val set 5.516x speedup, step: 2
Epoch 42/300 |loss: 0.000721| train set 5.238x speedup, test set 5.485x speedup, val set 5.516x speedup, step: 3
early stopping at epoch 42
Training per epoch cost 0.406 s
Optimal speedup on test set is 5.720x
01, opt runtime 34.775s, model runtime 37.830s, pg runtime 37.830s, speedup 1.000x
02, opt runtime 31.109s, model runtime 31.109s, pg runtime 31.109s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 30.267s, model runtime 30.267s, pg runtime 100.885s, speedup 3.333x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.377s, model runtime 8.474s, pg runtime 28.655s, speedup 3.382x
09, opt runtime 5.543s, model runtime 5.543s, pg runtime 5.543s, speedup 1.000x
10, opt runtime 5.237s, model runtime 5.237s, pg runtime 5.237s, speedup 1.000x
11, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 3.332s, pg runtime 21.298s, speedup 6.391x
14, opt runtime 3.258s, model runtime 3.258s, pg runtime 18.141s, speedup 5.568x
15, opt runtime 53.298s, model runtime 53.298s, pg runtime 148.707s, speedup 2.790x
16, opt runtime 53.440s, model runtime 53.440s, pg runtime 140.742s, speedup 2.634x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.347s, model runtime 1.347s, pg runtime 1.438s, speedup 1.067x
20, opt runtime 1.428s, model runtime 1.595s, pg runtime 1.428s, speedup 0.896x
21, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 6.250s, model runtime 6.250s, pg runtime 32.969s, speedup 5.275x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.642s, model runtime 1.752s, pg runtime 1.752s, speedup 1.000x
26, opt runtime 1.423s, model runtime 1.423s, pg runtime 1.423s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.799s, pg runtime 7.799s, speedup 1.000x
28, opt runtime 7.199s, model runtime 7.619s, pg runtime 7.619s, speedup 1.000x
29, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
30, opt runtime 5.539s, model runtime 5.539s, pg runtime 5.539s, speedup 1.000x
31, opt runtime 24.840s, model runtime 24.840s, pg runtime 626.529s, speedup 25.222x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
34, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
35, opt runtime 18.690s, model runtime 18.690s, pg runtime 651.942s, speedup 34.881x
36, opt runtime 16.280s, model runtime 16.280s, pg runtime 634.990s, speedup 39.005x
37, opt runtime 19.707s, model runtime 19.707s, pg runtime 19.707s, speedup 1.000x
38, opt runtime 18.262s, model runtime 18.262s, pg runtime 18.262s, speedup 1.000x
39, opt runtime 1.088s, model runtime 1.088s, pg runtime 1.206s, speedup 1.109x
40, opt runtime 1.086s, model runtime 1.086s, pg runtime 1.181s, speedup 1.088x
====================
best train speedup epoch: 34, train speedup 5.267, test speedup 5.497, val speedup 5.637
best test speedup epoch: 31, train speedup 5.253, test speedup 5.568, val speedup 5.637
best validation speedup epoch: 40, train speedup 5.173, test speedup 5.507, val speedup 5.663
last model at epoch 42, train speedup 5.238, test speedup 5.485, val speedup 5.516
execution cost 0:00:41.648747
==================================================
all print will write to path record/postgresql/TPCH/TCNN/slow_split/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/slow_split/point
seed: 42
shuffle_num: 1
slow: 1
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1d.sql' '10c.sql' '11c.sql' '12c.sql' '13d.sql' '14c.sql' '15d.sql'
 '16b.sql' '17a.sql' '18c.sql' '19d.sql' '2d.sql' '20c.sql' '21a.sql'
 '22c.sql' '23c.sql' '24a.sql' '25c.sql' '26c.sql' '27c.sql' '28c.sql'
 '29b.sql' '3c.sql' '30c.sql' '31c.sql' '32b.sql' '33c.sql' '4a.sql'
 '5c.sql' '6d.sql' '7c.sql' '8c.sql' '9d.sql']
load JOB succ
load TPCH...
[2, 3, 4, 5, 7, 9] [6, 8] [1, 0]
[0, 3, 4, 7, 8, 9] [5, 2] [6, 1]
[0, 4, 6, 7, 8, 9] [1, 3] [5, 2]
[0, 3, 4, 5, 7, 8] [1, 9] [2, 6]
[0, 3, 4, 6, 8, 9] [7, 2] [1, 5]
[1, 2, 3, 4, 6, 8] [5, 9] [7, 0]
[2, 3, 4, 5, 7, 8] [1, 6] [0, 9]
[1, 4, 6, 7, 8, 9] [0, 2] [5, 3]
[3, 4, 5, 7, 8, 9] [1, 0] [2, 6]
[0, 1, 2, 5, 7, 8] [3, 9] [4, 6]
[0, 2, 3, 5, 7, 9] [4, 6] [8, 1]
[0, 1, 2, 3, 5, 6] [9, 8] [7, 4]
[0, 3, 4, 5, 7, 9] [1, 2] [6, 8]
[2, 3, 4, 5, 6, 9] [0, 7] [1, 8]
[0, 1, 5, 6, 8, 9] [3, 2] [4, 7]
[0, 1, 4, 5, 6, 9] [8, 2] [7, 3]
[0, 2, 3, 6, 7, 9] [8, 5] [4, 1]
[0, 1, 2, 6, 7, 9] [5, 3] [4, 8]
[1, 2, 3, 4, 6, 8] [7, 9] [5, 0]
[0, 3, 5, 7, 8, 9] [2, 6] [1, 4]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.764886, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.048859| train set 2.499x speedup, test set 2.867x speedup, val set 2.708x speedup, step: 1
Epoch 1/300 |loss: 0.019868| train set 2.561x speedup, test set 2.910x speedup, val set 2.683x speedup, step: 2
Epoch 2/300 |loss: 0.010594| train set 3.168x speedup, test set 3.399x speedup, val set 3.408x speedup, step: 1
Epoch 3/300 |loss: 0.007224| train set 3.347x speedup, test set 3.768x speedup, val set 3.596x speedup, step: 1
Epoch 4/300 |loss: 0.005668| train set 4.218x speedup, test set 4.034x speedup, val set 4.351x speedup, step: 1
Epoch 5/300 |loss: 0.003800| train set 3.117x speedup, test set 3.660x speedup, val set 3.395x speedup, step: 2
Epoch 6/300 |loss: 0.003716| train set 3.696x speedup, test set 3.851x speedup, val set 3.969x speedup, step: 3
Epoch 7/300 |loss: 0.003146| train set 3.967x speedup, test set 3.522x speedup, val set 4.248x speedup, step: 4
Epoch 8/300 |loss: 0.002669| train set 3.994x speedup, test set 4.052x speedup, val set 4.256x speedup, step: 5
Epoch 9/300 |loss: 0.002400| train set 5.160x speedup, test set 4.043x speedup, val set 5.441x speedup, step: 1
Epoch 10/300 |loss: 0.002132| train set 3.672x speedup, test set 4.087x speedup, val set 3.979x speedup, step: 2
Epoch 11/300 |loss: 0.001962| train set 5.159x speedup, test set 4.045x speedup, val set 5.436x speedup, step: 3
Epoch 12/300 |loss: 0.002285| train set 5.148x speedup, test set 4.130x speedup, val set 5.315x speedup, step: 4
Epoch 13/300 |loss: 0.002612| train set 5.254x speedup, test set 4.095x speedup, val set 5.560x speedup, step: 1
Epoch 14/300 |loss: 0.001916| train set 3.413x speedup, test set 3.880x speedup, val set 3.826x speedup, step: 2
Epoch 15/300 |loss: 0.001987| train set 5.188x speedup, test set 4.089x speedup, val set 5.563x speedup, step: 1
Epoch 16/300 |loss: 0.001659| train set 5.188x speedup, test set 4.089x speedup, val set 5.563x speedup, step: 1
Epoch 17/300 |loss: 0.001476| train set 3.993x speedup, test set 4.424x speedup, val set 4.392x speedup, step: 2
Epoch 18/300 |loss: 0.001692| train set 5.156x speedup, test set 4.080x speedup, val set 5.528x speedup, step: 3
Epoch 19/300 |loss: 0.001605| train set 5.209x speedup, test set 4.150x speedup, val set 5.507x speedup, step: 4
Epoch 20/300 |loss: 0.001351| train set 4.605x speedup, test set 4.197x speedup, val set 4.853x speedup, step: 5
Epoch 21/300 |loss: 0.001055| train set 5.254x speedup, test set 5.501x speedup, val set 5.530x speedup, step: 6
Epoch 22/300 |loss: 0.001808| train set 5.186x speedup, test set 4.240x speedup, val set 5.551x speedup, step: 7
Epoch 23/300 |loss: 0.001241| train set 5.252x speedup, test set 4.942x speedup, val set 5.627x speedup, step: 1
Epoch 24/300 |loss: 0.000824| train set 5.179x speedup, test set 4.424x speedup, val set 5.678x speedup, step: 1
Epoch 25/300 |loss: 0.000790| train set 5.247x speedup, test set 5.562x speedup, val set 5.626x speedup, step: 2
Epoch 26/300 |loss: 0.000741| train set 5.177x speedup, test set 5.509x speedup, val set 5.680x speedup, step: 1
Epoch 27/300 |loss: 0.000773| train set 5.178x speedup, test set 5.500x speedup, val set 5.677x speedup, step: 2
Epoch 28/300 |loss: 0.000800| train set 5.245x speedup, test set 5.476x speedup, val set 5.517x speedup, step: 3
Epoch 29/300 |loss: 0.000835| train set 5.156x speedup, test set 5.474x speedup, val set 5.526x speedup, step: 4
Epoch 30/300 |loss: 0.000725| train set 5.256x speedup, test set 5.562x speedup, val set 5.625x speedup, step: 5
Epoch 31/300 |loss: 0.000762| train set 5.253x speedup, test set 5.568x speedup, val set 5.637x speedup, step: 6
Epoch 32/300 |loss: 0.000723| train set 5.262x speedup, test set 5.558x speedup, val set 5.638x speedup, step: 7
Epoch 33/300 |loss: 0.000665| train set 5.259x speedup, test set 5.567x speedup, val set 5.638x speedup, step: 8
Epoch 34/300 |loss: 0.000704| train set 5.263x speedup, test set 5.498x speedup, val set 5.539x speedup, step: 9
Epoch 35/300 |loss: 0.000703| train set 5.254x speedup, test set 5.564x speedup, val set 5.628x speedup, step: 10
Epoch 36/300 |loss: 0.000683| train set 5.262x speedup, test set 5.559x speedup, val set 5.638x speedup, step: 11
Epoch 37/300 |loss: 0.000771| train set 5.256x speedup, test set 5.554x speedup, val set 5.628x speedup, step: 12
Epoch 38/300 |loss: 0.000714| train set 5.256x speedup, test set 5.562x speedup, val set 5.625x speedup, step: 13
Epoch 39/300 |loss: 0.000700| train set 5.253x speedup, test set 5.568x speedup, val set 5.637x speedup, step: 14
Epoch 40/300 |loss: 0.000674| train set 5.255x speedup, test set 5.573x speedup, val set 5.621x speedup, step: 15
Epoch 41/300 |loss: 0.000728| train set 5.262x speedup, test set 5.559x speedup, val set 5.638x speedup, step: 16
Epoch 42/300 |loss: 0.000752| train set 5.239x speedup, test set 5.537x speedup, val set 5.613x speedup, step: 17
early stopping at epoch 42
Training per epoch cost 0.403 s
Optimal speedup on test set is 5.720x
01, opt runtime 34.775s, model runtime 37.830s, pg runtime 37.830s, speedup 1.000x
02, opt runtime 31.109s, model runtime 31.109s, pg runtime 31.109s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 30.267s, model runtime 30.267s, pg runtime 100.885s, speedup 3.333x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.377s, model runtime 8.474s, pg runtime 28.655s, speedup 3.382x
09, opt runtime 5.543s, model runtime 5.543s, pg runtime 5.543s, speedup 1.000x
10, opt runtime 5.237s, model runtime 5.237s, pg runtime 5.237s, speedup 1.000x
11, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.258s, model runtime 3.312s, pg runtime 18.141s, speedup 5.478x
15, opt runtime 53.298s, model runtime 53.298s, pg runtime 148.707s, speedup 2.790x
16, opt runtime 53.440s, model runtime 53.440s, pg runtime 140.742s, speedup 2.634x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.347s, model runtime 1.347s, pg runtime 1.438s, speedup 1.067x
20, opt runtime 1.428s, model runtime 1.595s, pg runtime 1.428s, speedup 0.896x
21, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 6.250s, model runtime 6.250s, pg runtime 32.969s, speedup 5.275x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.642s, model runtime 1.752s, pg runtime 1.752s, speedup 1.000x
26, opt runtime 1.423s, model runtime 1.423s, pg runtime 1.423s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.197s, pg runtime 7.799s, speedup 1.084x
28, opt runtime 7.199s, model runtime 7.199s, pg runtime 7.619s, speedup 1.058x
29, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
30, opt runtime 5.539s, model runtime 5.539s, pg runtime 5.539s, speedup 1.000x
31, opt runtime 24.840s, model runtime 24.840s, pg runtime 626.529s, speedup 25.222x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
34, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
35, opt runtime 18.690s, model runtime 18.690s, pg runtime 651.942s, speedup 34.881x
36, opt runtime 16.280s, model runtime 16.280s, pg runtime 634.990s, speedup 39.005x
37, opt runtime 19.707s, model runtime 19.707s, pg runtime 19.707s, speedup 1.000x
38, opt runtime 18.262s, model runtime 18.262s, pg runtime 18.262s, speedup 1.000x
39, opt runtime 1.088s, model runtime 1.088s, pg runtime 1.206s, speedup 1.109x
40, opt runtime 1.086s, model runtime 1.086s, pg runtime 1.181s, speedup 1.088x
====================
best train speedup epoch: 34, train speedup 5.263, test speedup 5.498, val speedup 5.539
best test speedup epoch: 40, train speedup 5.255, test speedup 5.573, val speedup 5.621
best validation speedup epoch: 26, train speedup 5.177, test speedup 5.509, val speedup 5.680
last model at epoch 42, train speedup 5.239, test speedup 5.537, val speedup 5.613
execution cost 0:00:41.658156
==================================================
all print will write to path record/postgresql/TPCH/TCNN/slow_split/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/slow_split/point
seed: 42
shuffle_num: 1
slow: 1
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1d.sql' '10c.sql' '11c.sql' '12c.sql' '13d.sql' '14c.sql' '15d.sql'
 '16b.sql' '17a.sql' '18c.sql' '19d.sql' '2d.sql' '20c.sql' '21a.sql'
 '22c.sql' '23c.sql' '24a.sql' '25c.sql' '26c.sql' '27c.sql' '28c.sql'
 '29b.sql' '3c.sql' '30c.sql' '31c.sql' '32b.sql' '33c.sql' '4a.sql'
 '5c.sql' '6d.sql' '7c.sql' '8c.sql' '9d.sql']
load JOB succ
load TPCH...
[2, 3, 4, 5, 7, 9] [6, 8] [1, 0]
[0, 3, 4, 7, 8, 9] [5, 2] [6, 1]
[0, 4, 6, 7, 8, 9] [1, 3] [5, 2]
[0, 3, 4, 5, 7, 8] [1, 9] [2, 6]
[0, 3, 4, 6, 8, 9] [7, 2] [1, 5]
[1, 2, 3, 4, 6, 8] [5, 9] [7, 0]
[2, 3, 4, 5, 7, 8] [1, 6] [0, 9]
[1, 4, 6, 7, 8, 9] [0, 2] [5, 3]
[3, 4, 5, 7, 8, 9] [1, 0] [2, 6]
[0, 1, 2, 5, 7, 8] [3, 9] [4, 6]
[0, 2, 3, 5, 7, 9] [4, 6] [8, 1]
[0, 1, 2, 3, 5, 6] [9, 8] [7, 4]
[0, 3, 4, 5, 7, 9] [1, 2] [6, 8]
[2, 3, 4, 5, 6, 9] [0, 7] [1, 8]
[0, 1, 5, 6, 8, 9] [3, 2] [4, 7]
[0, 1, 4, 5, 6, 9] [8, 2] [7, 3]
[0, 2, 3, 6, 7, 9] [8, 5] [4, 1]
[0, 1, 2, 6, 7, 9] [5, 3] [4, 8]
[1, 2, 3, 4, 6, 8] [7, 9] [5, 0]
[0, 3, 5, 7, 8, 9] [2, 6] [1, 4]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.956023, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.048859| train set 2.499x speedup, test set 2.867x speedup, val set 2.708x speedup, step: 1
Epoch 1/300 |loss: 0.019868| train set 2.561x speedup, test set 2.910x speedup, val set 2.683x speedup, step: 2
Epoch 2/300 |loss: 0.010596| train set 3.168x speedup, test set 3.399x speedup, val set 3.408x speedup, step: 1
Epoch 3/300 |loss: 0.007215| train set 3.269x speedup, test set 3.785x speedup, val set 3.570x speedup, step: 1
Epoch 4/300 |loss: 0.005759| train set 3.647x speedup, test set 4.039x speedup, val set 3.921x speedup, step: 1
Epoch 5/300 |loss: 0.003860| train set 3.117x speedup, test set 3.660x speedup, val set 3.395x speedup, step: 2
Epoch 6/300 |loss: 0.003628| train set 3.504x speedup, test set 3.851x speedup, val set 3.815x speedup, step: 3
Epoch 7/300 |loss: 0.003128| train set 3.468x speedup, test set 3.572x speedup, val set 3.746x speedup, step: 4
Epoch 8/300 |loss: 0.002668| train set 3.995x speedup, test set 4.087x speedup, val set 4.315x speedup, step: 1
Epoch 9/300 |loss: 0.002310| train set 5.163x speedup, test set 4.045x speedup, val set 5.443x speedup, step: 1
Epoch 10/300 |loss: 0.002096| train set 3.672x speedup, test set 4.086x speedup, val set 3.978x speedup, step: 2
Epoch 11/300 |loss: 0.002093| train set 5.162x speedup, test set 4.041x speedup, val set 5.435x speedup, step: 3
Epoch 12/300 |loss: 0.002359| train set 5.150x speedup, test set 4.125x speedup, val set 5.313x speedup, step: 4
Epoch 13/300 |loss: 0.001941| train set 5.254x speedup, test set 4.129x speedup, val set 5.628x speedup, step: 1
Epoch 14/300 |loss: 0.002381| train set 3.263x speedup, test set 3.841x speedup, val set 3.598x speedup, step: 2
Epoch 15/300 |loss: 0.002345| train set 5.068x speedup, test set 4.281x speedup, val set 5.334x speedup, step: 3
Epoch 16/300 |loss: 0.001686| train set 5.164x speedup, test set 4.082x speedup, val set 5.540x speedup, step: 4
Epoch 17/300 |loss: 0.001510| train set 3.975x speedup, test set 4.328x speedup, val set 4.369x speedup, step: 5
Epoch 18/300 |loss: 0.001771| train set 5.144x speedup, test set 4.230x speedup, val set 5.517x speedup, step: 6
Epoch 19/300 |loss: 0.001596| train set 5.253x speedup, test set 4.285x speedup, val set 5.629x speedup, step: 1
Epoch 20/300 |loss: 0.001371| train set 3.932x speedup, test set 4.197x speedup, val set 4.324x speedup, step: 2
Epoch 21/300 |loss: 0.001044| train set 5.262x speedup, test set 4.284x speedup, val set 5.638x speedup, step: 1
Epoch 22/300 |loss: 0.001556| train set 5.151x speedup, test set 4.224x speedup, val set 5.514x speedup, step: 2
Epoch 23/300 |loss: 0.001177| train set 5.262x speedup, test set 4.812x speedup, val set 5.638x speedup, step: 1
Epoch 24/300 |loss: 0.000845| train set 5.179x speedup, test set 4.424x speedup, val set 5.678x speedup, step: 1
Epoch 25/300 |loss: 0.000862| train set 5.254x speedup, test set 5.564x speedup, val set 5.617x speedup, step: 2
Epoch 26/300 |loss: 0.000797| train set 5.256x speedup, test set 5.563x speedup, val set 5.626x speedup, step: 3
Epoch 27/300 |loss: 0.000851| train set 5.178x speedup, test set 5.500x speedup, val set 5.677x speedup, step: 4
Epoch 28/300 |loss: 0.000883| train set 5.263x speedup, test set 5.497x speedup, val set 5.538x speedup, step: 5
Epoch 29/300 |loss: 0.000834| train set 5.257x speedup, test set 5.564x speedup, val set 5.636x speedup, step: 6
Epoch 30/300 |loss: 0.000911| train set 5.254x speedup, test set 5.551x speedup, val set 5.624x speedup, step: 7
Epoch 31/300 |loss: 0.000941| train set 5.259x speedup, test set 5.567x speedup, val set 5.638x speedup, step: 8
Epoch 32/300 |loss: 0.000791| train set 5.262x speedup, test set 5.558x speedup, val set 5.638x speedup, step: 9
Epoch 33/300 |loss: 0.000744| train set 5.259x speedup, test set 5.564x speedup, val set 5.638x speedup, step: 10
Epoch 34/300 |loss: 0.000718| train set 5.262x speedup, test set 5.560x speedup, val set 5.637x speedup, step: 11
Epoch 35/300 |loss: 0.000707| train set 5.252x speedup, test set 5.497x speedup, val set 5.519x speedup, step: 12
Epoch 36/300 |loss: 0.000735| train set 5.170x speedup, test set 5.503x speedup, val set 5.668x speedup, step: 13
Epoch 37/300 |loss: 0.000764| train set 5.256x speedup, test set 5.554x speedup, val set 5.626x speedup, step: 14
Epoch 38/300 |loss: 0.000691| train set 5.248x speedup, test set 5.558x speedup, val set 5.606x speedup, step: 15
Epoch 39/300 |loss: 0.000731| train set 5.253x speedup, test set 5.567x speedup, val set 5.637x speedup, step: 16
Epoch 40/300 |loss: 0.000634| train set 5.260x speedup, test set 5.565x speedup, val set 5.621x speedup, step: 17
Epoch 41/300 |loss: 0.000699| train set 5.258x speedup, test set 5.567x speedup, val set 5.625x speedup, step: 18
Epoch 42/300 |loss: 0.000644| train set 5.262x speedup, test set 5.558x speedup, val set 5.637x speedup, step: 19
Epoch 43/300 |loss: 0.000700| train set 5.259x speedup, test set 5.554x speedup, val set 5.626x speedup, step: 20
Epoch 44/300 |loss: 0.002234| train set 5.264x speedup, test set 5.499x speedup, val set 5.539x speedup, step: 21
Epoch 45/300 |loss: 0.001159| train set 5.254x speedup, test set 5.551x speedup, val set 5.615x speedup, step: 22
early stopping at epoch 45
Training per epoch cost 0.427 s
Optimal speedup on test set is 5.720x
01, opt runtime 34.775s, model runtime 37.830s, pg runtime 37.830s, speedup 1.000x
02, opt runtime 31.109s, model runtime 31.109s, pg runtime 31.109s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 30.267s, model runtime 30.267s, pg runtime 100.885s, speedup 3.333x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.377s, model runtime 8.474s, pg runtime 28.655s, speedup 3.382x
09, opt runtime 5.543s, model runtime 5.543s, pg runtime 5.543s, speedup 1.000x
10, opt runtime 5.237s, model runtime 5.237s, pg runtime 5.237s, speedup 1.000x
11, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.258s, model runtime 3.312s, pg runtime 18.141s, speedup 5.478x
15, opt runtime 53.298s, model runtime 139.919s, pg runtime 148.707s, speedup 1.063x
16, opt runtime 53.440s, model runtime 136.731s, pg runtime 140.742s, speedup 1.029x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.347s, model runtime 1.398s, pg runtime 1.438s, speedup 1.028x
20, opt runtime 1.428s, model runtime 1.645s, pg runtime 1.428s, speedup 0.868x
21, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 6.250s, model runtime 6.250s, pg runtime 32.969s, speedup 5.275x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.642s, model runtime 1.752s, pg runtime 1.752s, speedup 1.000x
26, opt runtime 1.423s, model runtime 1.423s, pg runtime 1.423s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.799s, pg runtime 7.799s, speedup 1.000x
28, opt runtime 7.199s, model runtime 7.619s, pg runtime 7.619s, speedup 1.000x
29, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
30, opt runtime 5.539s, model runtime 5.539s, pg runtime 5.539s, speedup 1.000x
31, opt runtime 24.840s, model runtime 24.840s, pg runtime 626.529s, speedup 25.222x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
34, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
35, opt runtime 18.690s, model runtime 18.690s, pg runtime 651.942s, speedup 34.881x
36, opt runtime 16.280s, model runtime 16.280s, pg runtime 634.990s, speedup 39.005x
37, opt runtime 19.707s, model runtime 19.707s, pg runtime 19.707s, speedup 1.000x
38, opt runtime 18.262s, model runtime 18.262s, pg runtime 18.262s, speedup 1.000x
39, opt runtime 1.088s, model runtime 1.088s, pg runtime 1.206s, speedup 1.109x
40, opt runtime 1.086s, model runtime 1.086s, pg runtime 1.181s, speedup 1.088x
====================
best train speedup epoch: 44, train speedup 5.264, test speedup 5.499, val speedup 5.539
best test speedup epoch: 31, train speedup 5.259, test speedup 5.567, val speedup 5.638
best validation speedup epoch: 24, train speedup 5.179, test speedup 4.424, val speedup 5.678
last model at epoch 45, train speedup 5.254, test speedup 5.551, val speedup 5.615
execution cost 0:00:45.918749
==================================================
all print will write to path record/postgresql/TPCH/TCNN/slow_split/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/slow_split/point
seed: 42
shuffle_num: 1
slow: 1
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1d.sql' '10c.sql' '11c.sql' '12c.sql' '13d.sql' '14c.sql' '15d.sql'
 '16b.sql' '17a.sql' '18c.sql' '19d.sql' '2d.sql' '20c.sql' '21a.sql'
 '22c.sql' '23c.sql' '24a.sql' '25c.sql' '26c.sql' '27c.sql' '28c.sql'
 '29b.sql' '3c.sql' '30c.sql' '31c.sql' '32b.sql' '33c.sql' '4a.sql'
 '5c.sql' '6d.sql' '7c.sql' '8c.sql' '9d.sql']
load JOB succ
load TPCH...
[2, 3, 4, 5, 7, 9] [6, 8] [1, 0]
[0, 3, 4, 7, 8, 9] [5, 2] [6, 1]
[0, 4, 6, 7, 8, 9] [1, 3] [5, 2]
[0, 3, 4, 5, 7, 8] [1, 9] [2, 6]
[0, 3, 4, 6, 8, 9] [7, 2] [1, 5]
[1, 2, 3, 4, 6, 8] [5, 9] [7, 0]
[2, 3, 4, 5, 7, 8] [1, 6] [0, 9]
[1, 4, 6, 7, 8, 9] [0, 2] [5, 3]
[3, 4, 5, 7, 8, 9] [1, 0] [2, 6]
[0, 1, 2, 5, 7, 8] [3, 9] [4, 6]
[0, 2, 3, 5, 7, 9] [4, 6] [8, 1]
[0, 1, 2, 3, 5, 6] [9, 8] [7, 4]
[0, 3, 4, 5, 7, 9] [1, 2] [6, 8]
[2, 3, 4, 5, 6, 9] [0, 7] [1, 8]
[0, 1, 5, 6, 8, 9] [3, 2] [4, 7]
[0, 1, 4, 5, 6, 9] [8, 2] [7, 3]
[0, 2, 3, 6, 7, 9] [8, 5] [4, 1]
[0, 1, 2, 6, 7, 9] [5, 3] [4, 8]
[1, 2, 3, 4, 6, 8] [7, 9] [5, 0]
[0, 3, 5, 7, 8, 9] [2, 6] [1, 4]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.755591, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.048859| train set 2.499x speedup, test set 2.867x speedup, val set 2.708x speedup, step: 1
Epoch 1/300 |loss: 0.019868| train set 2.561x speedup, test set 2.910x speedup, val set 2.683x speedup, step: 2
Epoch 2/300 |loss: 0.010596| train set 3.168x speedup, test set 3.399x speedup, val set 3.408x speedup, step: 1
Epoch 3/300 |loss: 0.007215| train set 3.269x speedup, test set 3.785x speedup, val set 3.570x speedup, step: 1
Epoch 4/300 |loss: 0.005759| train set 3.647x speedup, test set 4.039x speedup, val set 3.921x speedup, step: 1
Epoch 5/300 |loss: 0.003862| train set 3.117x speedup, test set 3.660x speedup, val set 3.395x speedup, step: 2
Epoch 6/300 |loss: 0.003653| train set 3.376x speedup, test set 3.810x speedup, val set 3.641x speedup, step: 3
Epoch 7/300 |loss: 0.003173| train set 3.316x speedup, test set 3.568x speedup, val set 3.299x speedup, step: 4
Epoch 8/300 |loss: 0.002629| train set 3.672x speedup, test set 4.087x speedup, val set 3.979x speedup, step: 1
Epoch 9/300 |loss: 0.002311| train set 5.205x speedup, test set 4.134x speedup, val set 5.334x speedup, step: 1
Epoch 10/300 |loss: 0.002130| train set 3.631x speedup, test set 4.054x speedup, val set 3.999x speedup, step: 2
Epoch 11/300 |loss: 0.002012| train set 5.065x speedup, test set 4.002x speedup, val set 5.368x speedup, step: 1
Epoch 12/300 |loss: 0.002207| train set 5.167x speedup, test set 4.139x speedup, val set 5.334x speedup, step: 2
Epoch 13/300 |loss: 0.002328| train set 5.258x speedup, test set 4.096x speedup, val set 5.537x speedup, step: 1
Epoch 14/300 |loss: 0.002202| train set 3.372x speedup, test set 3.966x speedup, val set 3.765x speedup, step: 2
Epoch 15/300 |loss: 0.002236| train set 5.177x speedup, test set 4.125x speedup, val set 5.564x speedup, step: 1
Epoch 16/300 |loss: 0.001619| train set 5.189x speedup, test set 4.055x speedup, val set 5.468x speedup, step: 2
Epoch 17/300 |loss: 0.001550| train set 3.974x speedup, test set 4.412x speedup, val set 4.371x speedup, step: 3
Epoch 18/300 |loss: 0.001859| train set 5.070x speedup, test set 4.048x speedup, val set 5.567x speedup, step: 1
Epoch 19/300 |loss: 0.001719| train set 5.157x speedup, test set 4.047x speedup, val set 5.434x speedup, step: 2
Epoch 20/300 |loss: 0.001404| train set 5.105x speedup, test set 4.055x speedup, val set 5.591x speedup, step: 1
Epoch 21/300 |loss: 0.001103| train set 5.252x speedup, test set 4.892x speedup, val set 5.527x speedup, step: 2
Epoch 22/300 |loss: 0.001761| train set 5.154x speedup, test set 4.227x speedup, val set 5.517x speedup, step: 3
Epoch 23/300 |loss: 0.001388| train set 5.262x speedup, test set 5.558x speedup, val set 5.638x speedup, step: 1
Epoch 24/300 |loss: 0.000929| train set 5.179x speedup, test set 4.424x speedup, val set 5.678x speedup, step: 1
Epoch 25/300 |loss: 0.000874| train set 5.255x speedup, test set 5.502x speedup, val set 5.530x speedup, step: 2
Epoch 26/300 |loss: 0.000799| train set 5.254x speedup, test set 5.564x speedup, val set 5.628x speedup, step: 3
Epoch 27/300 |loss: 0.000817| train set 5.178x speedup, test set 5.500x speedup, val set 5.677x speedup, step: 4
Epoch 28/300 |loss: 0.000850| train set 5.241x speedup, test set 5.476x speedup, val set 5.517x speedup, step: 5
Epoch 29/300 |loss: 0.000833| train set 5.157x speedup, test set 5.415x speedup, val set 5.432x speedup, step: 6
Epoch 30/300 |loss: 0.000867| train set 5.262x speedup, test set 5.560x speedup, val set 5.637x speedup, step: 7
Epoch 31/300 |loss: 0.000920| train set 5.252x speedup, test set 5.571x speedup, val set 5.626x speedup, step: 8
Epoch 32/300 |loss: 0.000684| train set 5.263x speedup, test set 5.497x speedup, val set 5.540x speedup, step: 9
Epoch 33/300 |loss: 0.000749| train set 5.259x speedup, test set 5.567x speedup, val set 5.638x speedup, step: 10
Epoch 34/300 |loss: 0.000698| train set 5.267x speedup, test set 5.497x speedup, val set 5.637x speedup, step: 11
Epoch 35/300 |loss: 0.000695| train set 5.256x speedup, test set 5.563x speedup, val set 5.626x speedup, step: 12
Epoch 36/300 |loss: 0.000716| train set 5.253x speedup, test set 5.562x speedup, val set 5.627x speedup, step: 13
Epoch 37/300 |loss: 0.000829| train set 5.253x speedup, test set 5.559x speedup, val set 5.627x speedup, step: 14
Epoch 38/300 |loss: 0.000736| train set 5.251x speedup, test set 5.559x speedup, val set 5.616x speedup, step: 15
Epoch 39/300 |loss: 0.000781| train set 5.253x speedup, test set 5.567x speedup, val set 5.637x speedup, step: 16
Epoch 40/300 |loss: 0.000636| train set 5.259x speedup, test set 5.568x speedup, val set 5.638x speedup, step: 17
Epoch 41/300 |loss: 0.000713| train set 5.256x speedup, test set 5.554x speedup, val set 5.626x speedup, step: 18
Epoch 42/300 |loss: 0.000673| train set 5.259x speedup, test set 5.567x speedup, val set 5.638x speedup, step: 19
Epoch 43/300 |loss: 0.000691| train set 5.259x speedup, test set 5.554x speedup, val set 5.626x speedup, step: 20
Epoch 44/300 |loss: 0.002015| train set 5.253x speedup, test set 5.562x speedup, val set 5.628x speedup, step: 21
Epoch 45/300 |loss: 0.000841| train set 5.248x speedup, test set 5.556x speedup, val set 5.642x speedup, step: 22
early stopping at epoch 45
Training per epoch cost 0.412 s
Optimal speedup on test set is 5.720x
01, opt runtime 34.775s, model runtime 37.830s, pg runtime 37.830s, speedup 1.000x
02, opt runtime 31.109s, model runtime 31.109s, pg runtime 31.109s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 30.267s, model runtime 30.267s, pg runtime 100.885s, speedup 3.333x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.377s, model runtime 8.474s, pg runtime 28.655s, speedup 3.382x
09, opt runtime 5.543s, model runtime 5.543s, pg runtime 5.543s, speedup 1.000x
10, opt runtime 5.237s, model runtime 5.237s, pg runtime 5.237s, speedup 1.000x
11, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.258s, model runtime 3.312s, pg runtime 18.141s, speedup 5.478x
15, opt runtime 53.298s, model runtime 139.919s, pg runtime 148.707s, speedup 1.063x
16, opt runtime 53.440s, model runtime 136.731s, pg runtime 140.742s, speedup 1.029x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.347s, model runtime 1.398s, pg runtime 1.438s, speedup 1.028x
20, opt runtime 1.428s, model runtime 1.645s, pg runtime 1.428s, speedup 0.868x
21, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 6.250s, model runtime 6.250s, pg runtime 32.969s, speedup 5.275x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.642s, model runtime 1.752s, pg runtime 1.752s, speedup 1.000x
26, opt runtime 1.423s, model runtime 1.423s, pg runtime 1.423s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.799s, pg runtime 7.799s, speedup 1.000x
28, opt runtime 7.199s, model runtime 7.619s, pg runtime 7.619s, speedup 1.000x
29, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
30, opt runtime 5.539s, model runtime 5.539s, pg runtime 5.539s, speedup 1.000x
31, opt runtime 24.840s, model runtime 24.840s, pg runtime 626.529s, speedup 25.222x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
34, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
35, opt runtime 18.690s, model runtime 18.690s, pg runtime 651.942s, speedup 34.881x
36, opt runtime 16.280s, model runtime 16.280s, pg runtime 634.990s, speedup 39.005x
37, opt runtime 19.707s, model runtime 19.707s, pg runtime 19.707s, speedup 1.000x
38, opt runtime 18.262s, model runtime 18.262s, pg runtime 18.262s, speedup 1.000x
39, opt runtime 1.088s, model runtime 1.088s, pg runtime 1.206s, speedup 1.109x
40, opt runtime 1.086s, model runtime 1.086s, pg runtime 1.181s, speedup 1.088x
====================
best train speedup epoch: 34, train speedup 5.267, test speedup 5.497, val speedup 5.637
best test speedup epoch: 31, train speedup 5.252, test speedup 5.571, val speedup 5.626
best validation speedup epoch: 24, train speedup 5.179, test speedup 4.424, val speedup 5.678
last model at epoch 45, train speedup 5.248, test speedup 5.556, val speedup 5.642
execution cost 0:00:44.711796
==================================================
all print will write to path record/postgresql/TPCH/TCNN/slow_split/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/slow_split/point
seed: 42
shuffle_num: 1
slow: 1
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1d.sql' '10c.sql' '11c.sql' '12c.sql' '13d.sql' '14c.sql' '15d.sql'
 '16b.sql' '17a.sql' '18c.sql' '19d.sql' '2d.sql' '20c.sql' '21a.sql'
 '22c.sql' '23c.sql' '24a.sql' '25c.sql' '26c.sql' '27c.sql' '28c.sql'
 '29b.sql' '3c.sql' '30c.sql' '31c.sql' '32b.sql' '33c.sql' '4a.sql'
 '5c.sql' '6d.sql' '7c.sql' '8c.sql' '9d.sql']
load JOB succ
load TPCH...
[2, 3, 4, 5, 7, 9] [6, 8] [1, 0]
[0, 3, 4, 7, 8, 9] [5, 2] [6, 1]
[0, 4, 6, 7, 8, 9] [1, 3] [5, 2]
[0, 3, 4, 5, 7, 8] [1, 9] [2, 6]
[0, 3, 4, 6, 8, 9] [7, 2] [1, 5]
[1, 2, 3, 4, 6, 8] [5, 9] [7, 0]
[2, 3, 4, 5, 7, 8] [1, 6] [0, 9]
[1, 4, 6, 7, 8, 9] [0, 2] [5, 3]
[3, 4, 5, 7, 8, 9] [1, 0] [2, 6]
[0, 1, 2, 5, 7, 8] [3, 9] [4, 6]
[0, 2, 3, 5, 7, 9] [4, 6] [8, 1]
[0, 1, 2, 3, 5, 6] [9, 8] [7, 4]
[0, 3, 4, 5, 7, 9] [1, 2] [6, 8]
[2, 3, 4, 5, 6, 9] [0, 7] [1, 8]
[0, 1, 5, 6, 8, 9] [3, 2] [4, 7]
[0, 1, 4, 5, 6, 9] [8, 2] [7, 3]
[0, 2, 3, 6, 7, 9] [8, 5] [4, 1]
[0, 1, 2, 6, 7, 9] [5, 3] [4, 8]
[1, 2, 3, 4, 6, 8] [7, 9] [5, 0]
[0, 3, 5, 7, 8, 9] [2, 6] [1, 4]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.723118, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.048859| train set 2.499x speedup, test set 2.867x speedup, val set 2.708x speedup, step: 1
Epoch 1/300 |loss: 0.019868| train set 2.561x speedup, test set 2.910x speedup, val set 2.683x speedup, step: 2
Epoch 2/300 |loss: 0.010594| train set 3.168x speedup, test set 3.399x speedup, val set 3.408x speedup, step: 1
Epoch 3/300 |loss: 0.007222| train set 3.269x speedup, test set 3.785x speedup, val set 3.570x speedup, step: 1
Epoch 4/300 |loss: 0.005618| train set 4.612x speedup, test set 3.810x speedup, val set 4.917x speedup, step: 1
Epoch 5/300 |loss: 0.003818| train set 3.116x speedup, test set 3.659x speedup, val set 3.394x speedup, step: 2
Epoch 6/300 |loss: 0.003728| train set 3.460x speedup, test set 3.805x speedup, val set 3.769x speedup, step: 3
Epoch 7/300 |loss: 0.003114| train set 3.705x speedup, test set 3.814x speedup, val set 3.645x speedup, step: 4
Epoch 8/300 |loss: 0.002609| train set 3.995x speedup, test set 4.087x speedup, val set 4.315x speedup, step: 5
Epoch 9/300 |loss: 0.002365| train set 5.163x speedup, test set 4.045x speedup, val set 5.443x speedup, step: 1
Epoch 10/300 |loss: 0.002136| train set 3.657x speedup, test set 4.074x speedup, val set 3.965x speedup, step: 2
Epoch 11/300 |loss: 0.002074| train set 5.163x speedup, test set 4.042x speedup, val set 5.435x speedup, step: 3
Epoch 12/300 |loss: 0.002416| train set 5.172x speedup, test set 4.136x speedup, val set 5.335x speedup, step: 4
Epoch 13/300 |loss: 0.002058| train set 5.253x speedup, test set 4.129x speedup, val set 5.628x speedup, step: 1
Epoch 14/300 |loss: 0.002119| train set 3.372x speedup, test set 3.966x speedup, val set 3.765x speedup, step: 2
Epoch 15/300 |loss: 0.002034| train set 5.188x speedup, test set 4.243x speedup, val set 5.563x speedup, step: 3
Epoch 16/300 |loss: 0.001577| train set 5.188x speedup, test set 4.088x speedup, val set 5.563x speedup, step: 4
Epoch 17/300 |loss: 0.001492| train set 3.938x speedup, test set 4.367x speedup, val set 4.332x speedup, step: 5
Epoch 18/300 |loss: 0.001685| train set 5.250x speedup, test set 4.286x speedup, val set 5.626x speedup, step: 6
Epoch 19/300 |loss: 0.001442| train set 5.188x speedup, test set 4.089x speedup, val set 5.562x speedup, step: 7
Epoch 20/300 |loss: 0.001201| train set 5.176x speedup, test set 4.098x speedup, val set 5.681x speedup, step: 1
Epoch 21/300 |loss: 0.000985| train set 5.250x speedup, test set 5.559x speedup, val set 5.625x speedup, step: 2
Epoch 22/300 |loss: 0.002042| train set 5.137x speedup, test set 4.217x speedup, val set 5.503x speedup, step: 3
Epoch 23/300 |loss: 0.001395| train set 5.262x speedup, test set 5.560x speedup, val set 5.637x speedup, step: 4
Epoch 24/300 |loss: 0.000784| train set 4.302x speedup, test set 4.424x speedup, val set 4.391x speedup, step: 5
Epoch 25/300 |loss: 0.000802| train set 5.254x speedup, test set 5.554x speedup, val set 5.626x speedup, step: 6
Epoch 26/300 |loss: 0.000745| train set 5.177x speedup, test set 5.496x speedup, val set 5.667x speedup, step: 7
Epoch 27/300 |loss: 0.000694| train set 5.262x speedup, test set 5.560x speedup, val set 5.637x speedup, step: 8
Epoch 28/300 |loss: 0.000798| train set 5.263x speedup, test set 5.496x speedup, val set 5.540x speedup, step: 9
Epoch 29/300 |loss: 0.000841| train set 5.256x speedup, test set 5.564x speedup, val set 5.626x speedup, step: 10
Epoch 30/300 |loss: 0.000760| train set 5.262x speedup, test set 5.558x speedup, val set 5.637x speedup, step: 11
Epoch 31/300 |loss: 0.000844| train set 5.253x speedup, test set 5.568x speedup, val set 5.637x speedup, step: 12
Epoch 32/300 |loss: 0.000741| train set 5.262x speedup, test set 5.558x speedup, val set 5.638x speedup, step: 13
Epoch 33/300 |loss: 0.000698| train set 5.264x speedup, test set 5.499x speedup, val set 5.539x speedup, step: 14
Epoch 34/300 |loss: 0.000676| train set 5.256x speedup, test set 5.554x speedup, val set 5.626x speedup, step: 15
Epoch 35/300 |loss: 0.000696| train set 5.254x speedup, test set 5.563x speedup, val set 5.617x speedup, step: 16
Epoch 36/300 |loss: 0.000732| train set 5.262x speedup, test set 5.558x speedup, val set 5.637x speedup, step: 17
early stopping at epoch 36
Training per epoch cost 0.409 s
Optimal speedup on test set is 5.720x
01, opt runtime 34.775s, model runtime 37.830s, pg runtime 37.830s, speedup 1.000x
02, opt runtime 31.109s, model runtime 31.109s, pg runtime 31.109s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 30.267s, model runtime 30.267s, pg runtime 100.885s, speedup 3.333x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.377s, model runtime 8.474s, pg runtime 28.655s, speedup 3.382x
09, opt runtime 5.543s, model runtime 5.543s, pg runtime 5.543s, speedup 1.000x
10, opt runtime 5.237s, model runtime 5.237s, pg runtime 5.237s, speedup 1.000x
11, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.258s, model runtime 3.312s, pg runtime 18.141s, speedup 5.478x
15, opt runtime 53.298s, model runtime 180.921s, pg runtime 148.707s, speedup 0.822x
16, opt runtime 53.440s, model runtime 165.749s, pg runtime 140.742s, speedup 0.849x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.347s, model runtime 1.347s, pg runtime 1.438s, speedup 1.067x
20, opt runtime 1.428s, model runtime 1.595s, pg runtime 1.428s, speedup 0.896x
21, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 6.250s, model runtime 6.250s, pg runtime 32.969s, speedup 5.275x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.642s, model runtime 1.752s, pg runtime 1.752s, speedup 1.000x
26, opt runtime 1.423s, model runtime 1.423s, pg runtime 1.423s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.197s, pg runtime 7.799s, speedup 1.084x
28, opt runtime 7.199s, model runtime 7.199s, pg runtime 7.619s, speedup 1.058x
29, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
30, opt runtime 5.539s, model runtime 5.539s, pg runtime 5.539s, speedup 1.000x
31, opt runtime 24.840s, model runtime 24.840s, pg runtime 626.529s, speedup 25.222x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
34, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
35, opt runtime 18.690s, model runtime 18.690s, pg runtime 651.942s, speedup 34.881x
36, opt runtime 16.280s, model runtime 16.280s, pg runtime 634.990s, speedup 39.005x
37, opt runtime 19.707s, model runtime 19.707s, pg runtime 19.707s, speedup 1.000x
38, opt runtime 18.262s, model runtime 18.262s, pg runtime 18.262s, speedup 1.000x
39, opt runtime 1.088s, model runtime 1.206s, pg runtime 1.206s, speedup 1.000x
40, opt runtime 1.086s, model runtime 1.181s, pg runtime 1.181s, speedup 1.000x
====================
best train speedup epoch: 33, train speedup 5.264, test speedup 5.499, val speedup 5.539
best test speedup epoch: 31, train speedup 5.253, test speedup 5.568, val speedup 5.637
best validation speedup epoch: 20, train speedup 5.176, test speedup 4.098, val speedup 5.681
last model at epoch 36, train speedup 5.262, test speedup 5.558, val speedup 5.637
execution cost 0:00:36.790828
==================================================
all print will write to path record/postgresql/TPCH/TCNN/slow_split/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/slow_split/point
seed: 42
shuffle_num: 1
slow: 1
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1d.sql' '10c.sql' '11c.sql' '12c.sql' '13d.sql' '14c.sql' '15d.sql'
 '16b.sql' '17a.sql' '18c.sql' '19d.sql' '2d.sql' '20c.sql' '21a.sql'
 '22c.sql' '23c.sql' '24a.sql' '25c.sql' '26c.sql' '27c.sql' '28c.sql'
 '29b.sql' '3c.sql' '30c.sql' '31c.sql' '32b.sql' '33c.sql' '4a.sql'
 '5c.sql' '6d.sql' '7c.sql' '8c.sql' '9d.sql']
load JOB succ
load TPCH...
[2, 3, 4, 5, 7, 9] [6, 8] [1, 0]
[0, 3, 4, 7, 8, 9] [5, 2] [6, 1]
[0, 4, 6, 7, 8, 9] [1, 3] [5, 2]
[0, 3, 4, 5, 7, 8] [1, 9] [2, 6]
[0, 3, 4, 6, 8, 9] [7, 2] [1, 5]
[1, 2, 3, 4, 6, 8] [5, 9] [7, 0]
[2, 3, 4, 5, 7, 8] [1, 6] [0, 9]
[1, 4, 6, 7, 8, 9] [0, 2] [5, 3]
[3, 4, 5, 7, 8, 9] [1, 0] [2, 6]
[0, 1, 2, 5, 7, 8] [3, 9] [4, 6]
[0, 2, 3, 5, 7, 9] [4, 6] [8, 1]
[0, 1, 2, 3, 5, 6] [9, 8] [7, 4]
[0, 3, 4, 5, 7, 9] [1, 2] [6, 8]
[2, 3, 4, 5, 6, 9] [0, 7] [1, 8]
[0, 1, 5, 6, 8, 9] [3, 2] [4, 7]
[0, 1, 4, 5, 6, 9] [8, 2] [7, 3]
[0, 2, 3, 6, 7, 9] [8, 5] [4, 1]
[0, 1, 2, 6, 7, 9] [5, 3] [4, 8]
[1, 2, 3, 4, 6, 8] [7, 9] [5, 0]
[0, 3, 5, 7, 8, 9] [2, 6] [1, 4]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.781271, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.048859| train set 2.499x speedup, test set 2.867x speedup, val set 2.708x speedup, step: 1
Epoch 1/300 |loss: 0.019868| train set 2.561x speedup, test set 2.910x speedup, val set 2.683x speedup, step: 2
Epoch 2/300 |loss: 0.010596| train set 3.168x speedup, test set 3.399x speedup, val set 3.408x speedup, step: 1
Epoch 3/300 |loss: 0.007216| train set 3.269x speedup, test set 3.785x speedup, val set 3.570x speedup, step: 1
Epoch 4/300 |loss: 0.005659| train set 3.647x speedup, test set 4.039x speedup, val set 3.921x speedup, step: 1
Epoch 5/300 |loss: 0.003828| train set 3.117x speedup, test set 3.660x speedup, val set 3.395x speedup, step: 2
Epoch 6/300 |loss: 0.003695| train set 3.648x speedup, test set 3.810x speedup, val set 3.921x speedup, step: 3
Epoch 7/300 |loss: 0.003124| train set 4.045x speedup, test set 3.572x speedup, val set 4.328x speedup, step: 1
Epoch 8/300 |loss: 0.002636| train set 3.672x speedup, test set 4.087x speedup, val set 3.979x speedup, step: 2
Epoch 9/300 |loss: 0.002354| train set 5.106x speedup, test set 4.112x speedup, val set 5.291x speedup, step: 1
Epoch 10/300 |loss: 0.002148| train set 3.672x speedup, test set 4.086x speedup, val set 3.978x speedup, step: 2
Epoch 11/300 |loss: 0.001960| train set 5.162x speedup, test set 4.042x speedup, val set 5.434x speedup, step: 1
Epoch 12/300 |loss: 0.002469| train set 5.167x speedup, test set 4.135x speedup, val set 5.326x speedup, step: 2
Epoch 13/300 |loss: 0.002052| train set 5.244x speedup, test set 4.127x speedup, val set 5.624x speedup, step: 1
Epoch 14/300 |loss: 0.002292| train set 3.412x speedup, test set 4.016x speedup, val set 3.824x speedup, step: 2
Epoch 15/300 |loss: 0.002291| train set 5.164x speedup, test set 4.082x speedup, val set 5.540x speedup, step: 3
Epoch 16/300 |loss: 0.001712| train set 5.165x speedup, test set 4.049x speedup, val set 5.445x speedup, step: 4
Epoch 17/300 |loss: 0.001517| train set 3.987x speedup, test set 4.095x speedup, val set 4.386x speedup, step: 5
Epoch 18/300 |loss: 0.001722| train set 5.150x speedup, test set 4.172x speedup, val set 5.526x speedup, step: 6
Epoch 19/300 |loss: 0.001614| train set 5.187x speedup, test set 4.060x speedup, val set 5.468x speedup, step: 7
Epoch 20/300 |loss: 0.001385| train set 4.253x speedup, test set 4.147x speedup, val set 4.346x speedup, step: 8
Epoch 21/300 |loss: 0.001060| train set 5.250x speedup, test set 4.462x speedup, val set 5.625x speedup, step: 1
Epoch 22/300 |loss: 0.001291| train set 5.100x speedup, test set 4.053x speedup, val set 5.581x speedup, step: 2
Epoch 23/300 |loss: 0.001025| train set 5.262x speedup, test set 4.939x speedup, val set 5.638x speedup, step: 1
Epoch 24/300 |loss: 0.000811| train set 3.992x speedup, test set 4.423x speedup, val set 4.391x speedup, step: 2
Epoch 25/300 |loss: 0.000941| train set 5.179x speedup, test set 5.501x speedup, val set 5.679x speedup, step: 1
Epoch 26/300 |loss: 0.000830| train set 5.172x speedup, test set 5.496x speedup, val set 5.655x speedup, step: 2
Epoch 27/300 |loss: 0.000882| train set 5.179x speedup, test set 5.500x speedup, val set 5.678x speedup, step: 3
Epoch 28/300 |loss: 0.000846| train set 5.179x speedup, test set 5.439x speedup, val set 5.578x speedup, step: 4
Epoch 29/300 |loss: 0.000810| train set 5.158x speedup, test set 5.478x speedup, val set 5.529x speedup, step: 5
Epoch 30/300 |loss: 0.000949| train set 5.257x speedup, test set 5.552x speedup, val set 5.622x speedup, step: 6
Epoch 31/300 |loss: 0.001144| train set 5.253x speedup, test set 5.567x speedup, val set 5.637x speedup, step: 7
Epoch 32/300 |loss: 0.000793| train set 5.263x speedup, test set 5.497x speedup, val set 5.540x speedup, step: 8
Epoch 33/300 |loss: 0.000717| train set 5.258x speedup, test set 5.502x speedup, val set 5.537x speedup, step: 9
Epoch 34/300 |loss: 0.000683| train set 5.256x speedup, test set 5.554x speedup, val set 5.626x speedup, step: 10
Epoch 35/300 |loss: 0.000715| train set 5.255x speedup, test set 5.502x speedup, val set 5.530x speedup, step: 11
Epoch 36/300 |loss: 0.000732| train set 5.263x speedup, test set 5.498x speedup, val set 5.539x speedup, step: 12
Epoch 37/300 |loss: 0.000833| train set 5.256x speedup, test set 5.554x speedup, val set 5.626x speedup, step: 13
Epoch 38/300 |loss: 0.000831| train set 5.151x speedup, test set 5.469x speedup, val set 5.516x speedup, step: 14
early stopping at epoch 38
Training per epoch cost 0.424 s
Optimal speedup on test set is 5.720x
01, opt runtime 34.775s, model runtime 37.830s, pg runtime 37.830s, speedup 1.000x
02, opt runtime 31.109s, model runtime 31.109s, pg runtime 31.109s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 30.267s, model runtime 30.267s, pg runtime 100.885s, speedup 3.333x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.377s, model runtime 8.474s, pg runtime 28.655s, speedup 3.382x
09, opt runtime 5.543s, model runtime 5.543s, pg runtime 5.543s, speedup 1.000x
10, opt runtime 5.237s, model runtime 5.237s, pg runtime 5.237s, speedup 1.000x
11, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.258s, model runtime 3.312s, pg runtime 18.141s, speedup 5.478x
15, opt runtime 53.298s, model runtime 53.298s, pg runtime 148.707s, speedup 2.790x
16, opt runtime 53.440s, model runtime 53.440s, pg runtime 140.742s, speedup 2.634x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.347s, model runtime 1.438s, pg runtime 1.438s, speedup 1.000x
20, opt runtime 1.428s, model runtime 1.428s, pg runtime 1.428s, speedup 1.000x
21, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 6.250s, model runtime 6.250s, pg runtime 32.969s, speedup 5.275x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.642s, model runtime 1.752s, pg runtime 1.752s, speedup 1.000x
26, opt runtime 1.423s, model runtime 1.423s, pg runtime 1.423s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.799s, pg runtime 7.799s, speedup 1.000x
28, opt runtime 7.199s, model runtime 7.619s, pg runtime 7.619s, speedup 1.000x
29, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
30, opt runtime 5.539s, model runtime 5.539s, pg runtime 5.539s, speedup 1.000x
31, opt runtime 24.840s, model runtime 24.840s, pg runtime 626.529s, speedup 25.222x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
34, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
35, opt runtime 18.690s, model runtime 18.690s, pg runtime 651.942s, speedup 34.881x
36, opt runtime 16.280s, model runtime 16.280s, pg runtime 634.990s, speedup 39.005x
37, opt runtime 19.707s, model runtime 19.707s, pg runtime 19.707s, speedup 1.000x
38, opt runtime 18.262s, model runtime 18.262s, pg runtime 18.262s, speedup 1.000x
39, opt runtime 1.088s, model runtime 1.088s, pg runtime 1.206s, speedup 1.109x
40, opt runtime 1.086s, model runtime 1.086s, pg runtime 1.181s, speedup 1.088x
====================
best train speedup epoch: 36, train speedup 5.263, test speedup 5.498, val speedup 5.539
best test speedup epoch: 31, train speedup 5.253, test speedup 5.567, val speedup 5.637
best validation speedup epoch: 25, train speedup 5.179, test speedup 5.501, val speedup 5.679
last model at epoch 38, train speedup 5.151, test speedup 5.469, val speedup 5.516
execution cost 0:00:38.631999
==================================================
all print will write to path record/postgresql/TPCH/TCNN/slow_split/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/slow_split/point
seed: 42
shuffle_num: 1
slow: 1
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1d.sql' '10c.sql' '11c.sql' '12c.sql' '13d.sql' '14c.sql' '15d.sql'
 '16b.sql' '17a.sql' '18c.sql' '19d.sql' '2d.sql' '20c.sql' '21a.sql'
 '22c.sql' '23c.sql' '24a.sql' '25c.sql' '26c.sql' '27c.sql' '28c.sql'
 '29b.sql' '3c.sql' '30c.sql' '31c.sql' '32b.sql' '33c.sql' '4a.sql'
 '5c.sql' '6d.sql' '7c.sql' '8c.sql' '9d.sql']
load JOB succ
load TPCH...
[2, 3, 4, 5, 7, 9] [6, 8] [1, 0]
[0, 3, 4, 7, 8, 9] [5, 2] [6, 1]
[0, 4, 6, 7, 8, 9] [1, 3] [5, 2]
[0, 3, 4, 5, 7, 8] [1, 9] [2, 6]
[0, 3, 4, 6, 8, 9] [7, 2] [1, 5]
[1, 2, 3, 4, 6, 8] [5, 9] [7, 0]
[2, 3, 4, 5, 7, 8] [1, 6] [0, 9]
[1, 4, 6, 7, 8, 9] [0, 2] [5, 3]
[3, 4, 5, 7, 8, 9] [1, 0] [2, 6]
[0, 1, 2, 5, 7, 8] [3, 9] [4, 6]
[0, 2, 3, 5, 7, 9] [4, 6] [8, 1]
[0, 1, 2, 3, 5, 6] [9, 8] [7, 4]
[0, 3, 4, 5, 7, 9] [1, 2] [6, 8]
[2, 3, 4, 5, 6, 9] [0, 7] [1, 8]
[0, 1, 5, 6, 8, 9] [3, 2] [4, 7]
[0, 1, 4, 5, 6, 9] [8, 2] [7, 3]
[0, 2, 3, 6, 7, 9] [8, 5] [4, 1]
[0, 1, 2, 6, 7, 9] [5, 3] [4, 8]
[1, 2, 3, 4, 6, 8] [7, 9] [5, 0]
[0, 3, 5, 7, 8, 9] [2, 6] [1, 4]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.763437, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.048859| train set 2.499x speedup, test set 2.867x speedup, val set 2.708x speedup, step: 1
Epoch 1/300 |loss: 0.019860| train set 2.561x speedup, test set 2.910x speedup, val set 2.683x speedup, step: 2
Epoch 2/300 |loss: 0.010608| train set 2.916x speedup, test set 3.429x speedup, val set 3.089x speedup, step: 1
Epoch 3/300 |loss: 0.007167| train set 3.268x speedup, test set 3.788x speedup, val set 3.571x speedup, step: 1
Epoch 4/300 |loss: 0.005641| train set 3.347x speedup, test set 3.871x speedup, val set 3.638x speedup, step: 1
Epoch 5/300 |loss: 0.003803| train set 3.117x speedup, test set 3.660x speedup, val set 3.395x speedup, step: 2
Epoch 6/300 |loss: 0.003801| train set 3.904x speedup, test set 3.808x speedup, val set 3.920x speedup, step: 1
Epoch 7/300 |loss: 0.003142| train set 3.282x speedup, test set 3.599x speedup, val set 3.576x speedup, step: 2
Epoch 8/300 |loss: 0.002615| train set 3.995x speedup, test set 4.086x speedup, val set 4.315x speedup, step: 1
Epoch 9/300 |loss: 0.002423| train set 5.153x speedup, test set 4.046x speedup, val set 5.434x speedup, step: 1
Epoch 10/300 |loss: 0.002140| train set 3.709x speedup, test set 4.125x speedup, val set 4.017x speedup, step: 2
Epoch 11/300 |loss: 0.001975| train set 5.184x speedup, test set 4.053x speedup, val set 5.457x speedup, step: 1
Epoch 12/300 |loss: 0.002198| train set 5.170x speedup, test set 4.142x speedup, val set 5.336x speedup, step: 2
Epoch 13/300 |loss: 0.002953| train set 5.261x speedup, test set 4.098x speedup, val set 5.540x speedup, step: 1
Epoch 14/300 |loss: 0.001943| train set 3.409x speedup, test set 3.884x speedup, val set 3.826x speedup, step: 2
Epoch 15/300 |loss: 0.002008| train set 5.190x speedup, test set 4.056x speedup, val set 5.467x speedup, step: 3
Epoch 16/300 |loss: 0.001634| train set 5.190x speedup, test set 4.056x speedup, val set 5.467x speedup, step: 4
Epoch 17/300 |loss: 0.001598| train set 3.545x speedup, test set 3.880x speedup, val set 3.859x speedup, step: 5
Epoch 18/300 |loss: 0.001689| train set 5.254x speedup, test set 4.216x speedup, val set 5.615x speedup, step: 1
Epoch 19/300 |loss: 0.001517| train set 5.160x speedup, test set 4.042x speedup, val set 5.433x speedup, step: 2
Epoch 20/300 |loss: 0.001348| train set 5.176x speedup, test set 4.253x speedup, val set 5.681x speedup, step: 1
Epoch 21/300 |loss: 0.000929| train set 5.181x speedup, test set 5.434x speedup, val set 5.458x speedup, step: 2
Epoch 22/300 |loss: 0.002203| train set 5.233x speedup, test set 4.084x speedup, val set 5.507x speedup, step: 3
Epoch 23/300 |loss: 0.001721| train set 5.240x speedup, test set 5.539x speedup, val set 5.614x speedup, step: 4
Epoch 24/300 |loss: 0.000844| train set 4.300x speedup, test set 4.429x speedup, val set 4.391x speedup, step: 5
Epoch 25/300 |loss: 0.000765| train set 5.257x speedup, test set 5.493x speedup, val set 5.528x speedup, step: 6
Epoch 26/300 |loss: 0.000685| train set 5.175x speedup, test set 5.507x speedup, val set 5.679x speedup, step: 7
Epoch 27/300 |loss: 0.000705| train set 5.178x speedup, test set 5.500x speedup, val set 5.677x speedup, step: 8
Epoch 28/300 |loss: 0.000722| train set 5.263x speedup, test set 5.496x speedup, val set 5.539x speedup, step: 9
Epoch 29/300 |loss: 0.000804| train set 5.158x speedup, test set 5.416x speedup, val set 5.433x speedup, step: 10
Epoch 30/300 |loss: 0.000935| train set 5.259x speedup, test set 5.566x speedup, val set 5.639x speedup, step: 11
Epoch 31/300 |loss: 0.000710| train set 5.177x speedup, test set 5.509x speedup, val set 5.680x speedup, step: 12
Epoch 32/300 |loss: 0.000692| train set 5.262x speedup, test set 5.560x speedup, val set 5.637x speedup, step: 13
Epoch 33/300 |loss: 0.000808| train set 5.260x speedup, test set 5.559x speedup, val set 5.635x speedup, step: 14
Epoch 34/300 |loss: 0.000677| train set 5.179x speedup, test set 5.500x speedup, val set 5.678x speedup, step: 15
Epoch 35/300 |loss: 0.000679| train set 5.261x speedup, test set 5.506x speedup, val set 5.540x speedup, step: 16
Epoch 36/300 |loss: 0.000650| train set 5.262x speedup, test set 5.558x speedup, val set 5.637x speedup, step: 17
Epoch 37/300 |loss: 0.000804| train set 5.262x speedup, test set 5.558x speedup, val set 5.637x speedup, step: 18
Epoch 38/300 |loss: 0.000693| train set 5.262x speedup, test set 5.560x speedup, val set 5.637x speedup, step: 19
Epoch 39/300 |loss: 0.000723| train set 5.253x speedup, test set 5.562x speedup, val set 5.628x speedup, step: 20
Epoch 40/300 |loss: 0.000647| train set 5.149x speedup, test set 5.494x speedup, val set 5.644x speedup, step: 21
Epoch 41/300 |loss: 0.000697| train set 5.256x speedup, test set 5.554x speedup, val set 5.616x speedup, step: 22
Epoch 42/300 |loss: 0.000678| train set 5.259x speedup, test set 5.568x speedup, val set 5.638x speedup, step: 23
Epoch 43/300 |loss: 0.000641| train set 5.256x speedup, test set 5.553x speedup, val set 5.617x speedup, step: 24
Epoch 44/300 |loss: 0.002090| train set 5.267x speedup, test set 5.497x speedup, val set 5.637x speedup, step: 25
Epoch 45/300 |loss: 0.001209| train set 5.257x speedup, test set 5.501x speedup, val set 5.529x speedup, step: 26
early stopping at epoch 45
Training per epoch cost 0.404 s
Optimal speedup on test set is 5.720x
01, opt runtime 34.775s, model runtime 37.830s, pg runtime 37.830s, speedup 1.000x
02, opt runtime 31.109s, model runtime 31.109s, pg runtime 31.109s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 30.267s, model runtime 30.267s, pg runtime 100.885s, speedup 3.333x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.377s, model runtime 8.474s, pg runtime 28.655s, speedup 3.382x
09, opt runtime 5.543s, model runtime 5.543s, pg runtime 5.543s, speedup 1.000x
10, opt runtime 5.237s, model runtime 5.237s, pg runtime 5.237s, speedup 1.000x
11, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.258s, model runtime 3.312s, pg runtime 18.141s, speedup 5.478x
15, opt runtime 53.298s, model runtime 160.373s, pg runtime 148.707s, speedup 0.927x
16, opt runtime 53.440s, model runtime 152.237s, pg runtime 140.742s, speedup 0.924x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.347s, model runtime 1.347s, pg runtime 1.438s, speedup 1.067x
20, opt runtime 1.428s, model runtime 1.595s, pg runtime 1.428s, speedup 0.896x
21, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 6.250s, model runtime 6.250s, pg runtime 32.969s, speedup 5.275x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.642s, model runtime 1.752s, pg runtime 1.752s, speedup 1.000x
26, opt runtime 1.423s, model runtime 1.423s, pg runtime 1.423s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.197s, pg runtime 7.799s, speedup 1.084x
28, opt runtime 7.199s, model runtime 7.199s, pg runtime 7.619s, speedup 1.058x
29, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
30, opt runtime 5.539s, model runtime 5.539s, pg runtime 5.539s, speedup 1.000x
31, opt runtime 24.840s, model runtime 24.840s, pg runtime 626.529s, speedup 25.222x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
34, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
35, opt runtime 18.690s, model runtime 18.690s, pg runtime 651.942s, speedup 34.881x
36, opt runtime 16.280s, model runtime 16.280s, pg runtime 634.990s, speedup 39.005x
37, opt runtime 19.707s, model runtime 19.707s, pg runtime 19.707s, speedup 1.000x
38, opt runtime 18.262s, model runtime 18.262s, pg runtime 18.262s, speedup 1.000x
39, opt runtime 1.088s, model runtime 1.206s, pg runtime 1.206s, speedup 1.000x
40, opt runtime 1.086s, model runtime 1.181s, pg runtime 1.181s, speedup 1.000x
====================
best train speedup epoch: 44, train speedup 5.267, test speedup 5.497, val speedup 5.637
best test speedup epoch: 42, train speedup 5.259, test speedup 5.568, val speedup 5.638
best validation speedup epoch: 20, train speedup 5.176, test speedup 4.253, val speedup 5.681
last model at epoch 45, train speedup 5.257, test speedup 5.501, val speedup 5.529
execution cost 0:00:44.042653
==================================================
all print will write to path record/postgresql/TPCH/TCNN/slow_split/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/slow_split/point
seed: 42
shuffle_num: 1
slow: 1
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1d.sql' '10c.sql' '11c.sql' '12c.sql' '13d.sql' '14c.sql' '15d.sql'
 '16b.sql' '17a.sql' '18c.sql' '19d.sql' '2d.sql' '20c.sql' '21a.sql'
 '22c.sql' '23c.sql' '24a.sql' '25c.sql' '26c.sql' '27c.sql' '28c.sql'
 '29b.sql' '3c.sql' '30c.sql' '31c.sql' '32b.sql' '33c.sql' '4a.sql'
 '5c.sql' '6d.sql' '7c.sql' '8c.sql' '9d.sql']
load JOB succ
load TPCH...
[2, 3, 4, 5, 7, 9] [6, 8] [1, 0]
[0, 3, 4, 7, 8, 9] [5, 2] [6, 1]
[0, 4, 6, 7, 8, 9] [1, 3] [5, 2]
[0, 3, 4, 5, 7, 8] [1, 9] [2, 6]
[0, 3, 4, 6, 8, 9] [7, 2] [1, 5]
[1, 2, 3, 4, 6, 8] [5, 9] [7, 0]
[2, 3, 4, 5, 7, 8] [1, 6] [0, 9]
[1, 4, 6, 7, 8, 9] [0, 2] [5, 3]
[3, 4, 5, 7, 8, 9] [1, 0] [2, 6]
[0, 1, 2, 5, 7, 8] [3, 9] [4, 6]
[0, 2, 3, 5, 7, 9] [4, 6] [8, 1]
[0, 1, 2, 3, 5, 6] [9, 8] [7, 4]
[0, 3, 4, 5, 7, 9] [1, 2] [6, 8]
[2, 3, 4, 5, 6, 9] [0, 7] [1, 8]
[0, 1, 5, 6, 8, 9] [3, 2] [4, 7]
[0, 1, 4, 5, 6, 9] [8, 2] [7, 3]
[0, 2, 3, 6, 7, 9] [8, 5] [4, 1]
[0, 1, 2, 6, 7, 9] [5, 3] [4, 8]
[1, 2, 3, 4, 6, 8] [7, 9] [5, 0]
[0, 3, 5, 7, 8, 9] [2, 6] [1, 4]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.753503, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.048859| train set 2.499x speedup, test set 2.867x speedup, val set 2.708x speedup, step: 1
Epoch 1/300 |loss: 0.019868| train set 2.561x speedup, test set 2.910x speedup, val set 2.683x speedup, step: 2
Epoch 2/300 |loss: 0.010594| train set 3.168x speedup, test set 3.399x speedup, val set 3.408x speedup, step: 1
Epoch 3/300 |loss: 0.007201| train set 3.269x speedup, test set 3.785x speedup, val set 3.570x speedup, step: 1
Epoch 4/300 |loss: 0.005633| train set 3.878x speedup, test set 4.039x speedup, val set 4.179x speedup, step: 1
Epoch 5/300 |loss: 0.003817| train set 3.116x speedup, test set 3.659x speedup, val set 3.394x speedup, step: 2
Epoch 6/300 |loss: 0.003748| train set 3.646x speedup, test set 3.809x speedup, val set 3.919x speedup, step: 3
Epoch 7/300 |loss: 0.003091| train set 3.530x speedup, test set 3.804x speedup, val set 3.635x speedup, step: 4
Epoch 8/300 |loss: 0.002645| train set 3.672x speedup, test set 4.087x speedup, val set 3.979x speedup, step: 5
Epoch 9/300 |loss: 0.002319| train set 5.158x speedup, test set 4.046x speedup, val set 5.442x speedup, step: 1
Epoch 10/300 |loss: 0.002120| train set 3.618x speedup, test set 4.044x speedup, val set 3.986x speedup, step: 2
Epoch 11/300 |loss: 0.001935| train set 5.138x speedup, test set 4.031x speedup, val set 5.404x speedup, step: 3
Epoch 12/300 |loss: 0.002089| train set 5.237x speedup, test set 4.120x speedup, val set 5.614x speedup, step: 1
Epoch 13/300 |loss: 0.002509| train set 5.170x speedup, test set 4.141x speedup, val set 5.337x speedup, step: 2
Epoch 14/300 |loss: 0.002387| train set 3.353x speedup, test set 3.951x speedup, val set 3.710x speedup, step: 3
Epoch 15/300 |loss: 0.002445| train set 5.087x speedup, test set 4.046x speedup, val set 5.580x speedup, step: 4
Epoch 16/300 |loss: 0.001637| train set 5.158x speedup, test set 4.049x speedup, val set 5.557x speedup, step: 5
Epoch 17/300 |loss: 0.001420| train set 3.945x speedup, test set 4.375x speedup, val set 4.333x speedup, step: 6
Epoch 18/300 |loss: 0.001656| train set 5.160x speedup, test set 4.194x speedup, val set 5.432x speedup, step: 7
Epoch 19/300 |loss: 0.001564| train set 5.253x speedup, test set 4.285x speedup, val set 5.629x speedup, step: 1
Epoch 20/300 |loss: 0.001425| train set 4.298x speedup, test set 4.350x speedup, val set 4.384x speedup, step: 2
Epoch 21/300 |loss: 0.000989| train set 5.253x speedup, test set 4.943x speedup, val set 5.628x speedup, step: 3
Epoch 22/300 |loss: 0.001552| train set 5.180x speedup, test set 4.336x speedup, val set 5.541x speedup, step: 4
Epoch 23/300 |loss: 0.001116| train set 5.262x speedup, test set 5.559x speedup, val set 5.638x speedup, step: 1
Epoch 24/300 |loss: 0.000830| train set 4.302x speedup, test set 4.425x speedup, val set 4.391x speedup, step: 2
Epoch 25/300 |loss: 0.000850| train set 5.246x speedup, test set 5.498x speedup, val set 5.517x speedup, step: 3
Epoch 26/300 |loss: 0.000763| train set 5.177x speedup, test set 5.509x speedup, val set 5.680x speedup, step: 1
Epoch 27/300 |loss: 0.000761| train set 5.176x speedup, test set 5.495x speedup, val set 5.667x speedup, step: 2
Epoch 28/300 |loss: 0.000818| train set 5.151x speedup, test set 5.556x speedup, val set 5.314x speedup, step: 3
Epoch 29/300 |loss: 0.000891| train set 5.156x speedup, test set 5.475x speedup, val set 5.527x speedup, step: 4
Epoch 30/300 |loss: 0.000820| train set 5.256x speedup, test set 5.563x speedup, val set 5.626x speedup, step: 5
Epoch 31/300 |loss: 0.000811| train set 5.253x speedup, test set 5.568x speedup, val set 5.637x speedup, step: 6
Epoch 32/300 |loss: 0.000692| train set 5.263x speedup, test set 5.498x speedup, val set 5.539x speedup, step: 7
Epoch 33/300 |loss: 0.000666| train set 5.260x speedup, test set 5.505x speedup, val set 5.541x speedup, step: 8
Epoch 34/300 |loss: 0.000687| train set 5.256x speedup, test set 5.555x speedup, val set 5.627x speedup, step: 9
Epoch 35/300 |loss: 0.000707| train set 5.254x speedup, test set 5.564x speedup, val set 5.617x speedup, step: 10
Epoch 36/300 |loss: 0.000687| train set 5.262x speedup, test set 5.559x speedup, val set 5.638x speedup, step: 11
Epoch 37/300 |loss: 0.000717| train set 5.247x speedup, test set 5.557x speedup, val set 5.617x speedup, step: 12
Epoch 38/300 |loss: 0.000676| train set 5.256x speedup, test set 5.563x speedup, val set 5.615x speedup, step: 13
Epoch 39/300 |loss: 0.000675| train set 5.253x speedup, test set 5.563x speedup, val set 5.628x speedup, step: 14
Epoch 40/300 |loss: 0.000667| train set 5.258x speedup, test set 5.575x speedup, val set 5.623x speedup, step: 15
Epoch 41/300 |loss: 0.000690| train set 5.256x speedup, test set 5.555x speedup, val set 5.627x speedup, step: 16
Epoch 42/300 |loss: 0.000707| train set 5.239x speedup, test set 5.537x speedup, val set 5.613x speedup, step: 17
early stopping at epoch 42
Training per epoch cost 0.404 s
Optimal speedup on test set is 5.720x
01, opt runtime 34.775s, model runtime 37.830s, pg runtime 37.830s, speedup 1.000x
02, opt runtime 31.109s, model runtime 31.109s, pg runtime 31.109s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 30.267s, model runtime 30.267s, pg runtime 100.885s, speedup 3.333x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.377s, model runtime 8.474s, pg runtime 28.655s, speedup 3.382x
09, opt runtime 5.543s, model runtime 5.543s, pg runtime 5.543s, speedup 1.000x
10, opt runtime 5.237s, model runtime 5.237s, pg runtime 5.237s, speedup 1.000x
11, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.258s, model runtime 3.312s, pg runtime 18.141s, speedup 5.478x
15, opt runtime 53.298s, model runtime 53.298s, pg runtime 148.707s, speedup 2.790x
16, opt runtime 53.440s, model runtime 53.440s, pg runtime 140.742s, speedup 2.634x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.347s, model runtime 1.347s, pg runtime 1.438s, speedup 1.067x
20, opt runtime 1.428s, model runtime 1.595s, pg runtime 1.428s, speedup 0.896x
21, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 6.250s, model runtime 6.250s, pg runtime 32.969s, speedup 5.275x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.642s, model runtime 1.752s, pg runtime 1.752s, speedup 1.000x
26, opt runtime 1.423s, model runtime 1.423s, pg runtime 1.423s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.197s, pg runtime 7.799s, speedup 1.084x
28, opt runtime 7.199s, model runtime 7.199s, pg runtime 7.619s, speedup 1.058x
29, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
30, opt runtime 5.539s, model runtime 5.539s, pg runtime 5.539s, speedup 1.000x
31, opt runtime 24.840s, model runtime 24.840s, pg runtime 626.529s, speedup 25.222x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
34, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
35, opt runtime 18.690s, model runtime 18.690s, pg runtime 651.942s, speedup 34.881x
36, opt runtime 16.280s, model runtime 16.280s, pg runtime 634.990s, speedup 39.005x
37, opt runtime 19.707s, model runtime 19.707s, pg runtime 19.707s, speedup 1.000x
38, opt runtime 18.262s, model runtime 18.262s, pg runtime 18.262s, speedup 1.000x
39, opt runtime 1.088s, model runtime 1.088s, pg runtime 1.206s, speedup 1.109x
40, opt runtime 1.086s, model runtime 1.086s, pg runtime 1.181s, speedup 1.088x
====================
best train speedup epoch: 32, train speedup 5.263, test speedup 5.498, val speedup 5.539
best test speedup epoch: 40, train speedup 5.258, test speedup 5.575, val speedup 5.623
best validation speedup epoch: 26, train speedup 5.177, test speedup 5.509, val speedup 5.680
last model at epoch 42, train speedup 5.239, test speedup 5.537, val speedup 5.613
execution cost 0:00:41.779489
==================================================
all print will write to path record/postgresql/TPCH/TCNN/slow_split/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/slow_split/point
seed: 42
shuffle_num: 1
slow: 1
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1d.sql' '10c.sql' '11c.sql' '12c.sql' '13d.sql' '14c.sql' '15d.sql'
 '16b.sql' '17a.sql' '18c.sql' '19d.sql' '2d.sql' '20c.sql' '21a.sql'
 '22c.sql' '23c.sql' '24a.sql' '25c.sql' '26c.sql' '27c.sql' '28c.sql'
 '29b.sql' '3c.sql' '30c.sql' '31c.sql' '32b.sql' '33c.sql' '4a.sql'
 '5c.sql' '6d.sql' '7c.sql' '8c.sql' '9d.sql']
load JOB succ
load TPCH...
[2, 3, 4, 5, 7, 9] [6, 8] [1, 0]
[0, 3, 4, 7, 8, 9] [5, 2] [6, 1]
[0, 4, 6, 7, 8, 9] [1, 3] [5, 2]
[0, 3, 4, 5, 7, 8] [1, 9] [2, 6]
[0, 3, 4, 6, 8, 9] [7, 2] [1, 5]
[1, 2, 3, 4, 6, 8] [5, 9] [7, 0]
[2, 3, 4, 5, 7, 8] [1, 6] [0, 9]
[1, 4, 6, 7, 8, 9] [0, 2] [5, 3]
[3, 4, 5, 7, 8, 9] [1, 0] [2, 6]
[0, 1, 2, 5, 7, 8] [3, 9] [4, 6]
[0, 2, 3, 5, 7, 9] [4, 6] [8, 1]
[0, 1, 2, 3, 5, 6] [9, 8] [7, 4]
[0, 3, 4, 5, 7, 9] [1, 2] [6, 8]
[2, 3, 4, 5, 6, 9] [0, 7] [1, 8]
[0, 1, 5, 6, 8, 9] [3, 2] [4, 7]
[0, 1, 4, 5, 6, 9] [8, 2] [7, 3]
[0, 2, 3, 6, 7, 9] [8, 5] [4, 1]
[0, 1, 2, 6, 7, 9] [5, 3] [4, 8]
[1, 2, 3, 4, 6, 8] [7, 9] [5, 0]
[0, 3, 5, 7, 8, 9] [2, 6] [1, 4]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.754143, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.048859| train set 2.499x speedup, test set 2.867x speedup, val set 2.708x speedup, step: 1
Epoch 1/300 |loss: 0.019868| train set 2.561x speedup, test set 2.910x speedup, val set 2.683x speedup, step: 2
Epoch 2/300 |loss: 0.010594| train set 3.168x speedup, test set 3.399x speedup, val set 3.408x speedup, step: 1
Epoch 3/300 |loss: 0.007224| train set 3.347x speedup, test set 3.768x speedup, val set 3.596x speedup, step: 1
Epoch 4/300 |loss: 0.005668| train set 4.218x speedup, test set 4.034x speedup, val set 4.351x speedup, step: 1
Epoch 5/300 |loss: 0.003800| train set 3.117x speedup, test set 3.660x speedup, val set 3.395x speedup, step: 2
Epoch 6/300 |loss: 0.003716| train set 3.696x speedup, test set 3.851x speedup, val set 3.969x speedup, step: 3
Epoch 7/300 |loss: 0.003147| train set 3.967x speedup, test set 3.522x speedup, val set 4.248x speedup, step: 4
Epoch 8/300 |loss: 0.002667| train set 3.994x speedup, test set 4.052x speedup, val set 4.256x speedup, step: 5
Epoch 9/300 |loss: 0.002391| train set 5.146x speedup, test set 4.043x speedup, val set 5.422x speedup, step: 1
Epoch 10/300 |loss: 0.002136| train set 3.672x speedup, test set 4.087x speedup, val set 3.979x speedup, step: 2
Epoch 11/300 |loss: 0.002007| train set 5.160x speedup, test set 4.046x speedup, val set 5.435x speedup, step: 1
Epoch 12/300 |loss: 0.002413| train set 5.169x speedup, test set 4.141x speedup, val set 5.336x speedup, step: 2
Epoch 13/300 |loss: 0.002493| train set 5.254x speedup, test set 4.095x speedup, val set 5.530x speedup, step: 1
Epoch 14/300 |loss: 0.001935| train set 3.372x speedup, test set 3.831x speedup, val set 3.765x speedup, step: 2
Epoch 15/300 |loss: 0.002125| train set 5.188x speedup, test set 4.089x speedup, val set 5.563x speedup, step: 1
Epoch 16/300 |loss: 0.001604| train set 5.188x speedup, test set 4.056x speedup, val set 5.465x speedup, step: 2
Epoch 17/300 |loss: 0.001433| train set 3.929x speedup, test set 4.366x speedup, val set 4.320x speedup, step: 3
Epoch 18/300 |loss: 0.001633| train set 5.259x speedup, test set 4.131x speedup, val set 5.639x speedup, step: 1
Epoch 19/300 |loss: 0.001537| train set 5.241x speedup, test set 4.082x speedup, val set 5.515x speedup, step: 2
Epoch 20/300 |loss: 0.001309| train set 5.177x speedup, test set 4.099x speedup, val set 5.680x speedup, step: 1
Epoch 21/300 |loss: 0.001093| train set 5.254x speedup, test set 4.894x speedup, val set 5.530x speedup, step: 2
Epoch 22/300 |loss: 0.001865| train set 5.159x speedup, test set 4.076x speedup, val set 5.527x speedup, step: 3
Epoch 23/300 |loss: 0.001305| train set 5.259x speedup, test set 5.568x speedup, val set 5.638x speedup, step: 4
Epoch 24/300 |loss: 0.000853| train set 5.173x speedup, test set 4.427x speedup, val set 5.659x speedup, step: 5
Epoch 25/300 |loss: 0.000775| train set 5.252x speedup, test set 5.562x speedup, val set 5.615x speedup, step: 6
Epoch 26/300 |loss: 0.000779| train set 5.179x speedup, test set 5.500x speedup, val set 5.679x speedup, step: 7
Epoch 27/300 |loss: 0.000776| train set 5.178x speedup, test set 5.500x speedup, val set 5.677x speedup, step: 8
Epoch 28/300 |loss: 0.000787| train set 5.263x speedup, test set 5.498x speedup, val set 5.539x speedup, step: 9
Epoch 29/300 |loss: 0.000799| train set 5.156x speedup, test set 5.475x speedup, val set 5.527x speedup, step: 10
Epoch 30/300 |loss: 0.000941| train set 5.156x speedup, test set 5.474x speedup, val set 5.526x speedup, step: 11
Epoch 31/300 |loss: 0.000888| train set 5.255x speedup, test set 5.560x speedup, val set 5.627x speedup, step: 12
Epoch 32/300 |loss: 0.000689| train set 5.261x speedup, test set 5.557x speedup, val set 5.638x speedup, step: 13
Epoch 33/300 |loss: 0.000691| train set 5.262x speedup, test set 5.502x speedup, val set 5.540x speedup, step: 14
Epoch 34/300 |loss: 0.000686| train set 5.262x speedup, test set 5.558x speedup, val set 5.637x speedup, step: 15
Epoch 35/300 |loss: 0.000715| train set 5.259x speedup, test set 5.567x speedup, val set 5.627x speedup, step: 16
Epoch 36/300 |loss: 0.000756| train set 5.254x speedup, test set 5.500x speedup, val set 5.529x speedup, step: 17
Epoch 37/300 |loss: 0.000738| train set 5.252x speedup, test set 5.561x speedup, val set 5.627x speedup, step: 18
Epoch 38/300 |loss: 0.000671| train set 5.251x speedup, test set 5.559x speedup, val set 5.616x speedup, step: 19
Epoch 39/300 |loss: 0.000702| train set 5.253x speedup, test set 5.567x speedup, val set 5.637x speedup, step: 20
Epoch 40/300 |loss: 0.000650| train set 5.257x speedup, test set 5.574x speedup, val set 5.627x speedup, step: 21
Epoch 41/300 |loss: 0.000656| train set 5.258x speedup, test set 5.494x speedup, val set 5.529x speedup, step: 22
Epoch 42/300 |loss: 0.000637| train set 5.262x speedup, test set 5.559x speedup, val set 5.638x speedup, step: 23
Epoch 43/300 |loss: 0.000757| train set 5.256x speedup, test set 5.554x speedup, val set 5.628x speedup, step: 24
Epoch 44/300 |loss: 0.002358| train set 5.090x speedup, test set 5.423x speedup, val set 5.583x speedup, step: 25
early stopping at epoch 44
Training per epoch cost 0.403 s
Optimal speedup on test set is 5.720x
01, opt runtime 34.775s, model runtime 37.830s, pg runtime 37.830s, speedup 1.000x
02, opt runtime 31.109s, model runtime 31.109s, pg runtime 31.109s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 30.267s, model runtime 30.267s, pg runtime 100.885s, speedup 3.333x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.377s, model runtime 8.474s, pg runtime 28.655s, speedup 3.382x
09, opt runtime 5.543s, model runtime 5.543s, pg runtime 5.543s, speedup 1.000x
10, opt runtime 5.237s, model runtime 5.237s, pg runtime 5.237s, speedup 1.000x
11, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.258s, model runtime 3.312s, pg runtime 18.141s, speedup 5.478x
15, opt runtime 53.298s, model runtime 180.921s, pg runtime 148.707s, speedup 0.822x
16, opt runtime 53.440s, model runtime 165.749s, pg runtime 140.742s, speedup 0.849x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.347s, model runtime 1.347s, pg runtime 1.438s, speedup 1.067x
20, opt runtime 1.428s, model runtime 1.595s, pg runtime 1.428s, speedup 0.896x
21, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 6.250s, model runtime 6.250s, pg runtime 32.969s, speedup 5.275x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.642s, model runtime 1.752s, pg runtime 1.752s, speedup 1.000x
26, opt runtime 1.423s, model runtime 1.423s, pg runtime 1.423s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.197s, pg runtime 7.799s, speedup 1.084x
28, opt runtime 7.199s, model runtime 7.199s, pg runtime 7.619s, speedup 1.058x
29, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
30, opt runtime 5.539s, model runtime 5.539s, pg runtime 5.539s, speedup 1.000x
31, opt runtime 24.840s, model runtime 24.840s, pg runtime 626.529s, speedup 25.222x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
34, opt runtime 39.191s, model runtime 42.882s, pg runtime 75.984s, speedup 1.772x
35, opt runtime 18.690s, model runtime 18.690s, pg runtime 651.942s, speedup 34.881x
36, opt runtime 16.280s, model runtime 16.280s, pg runtime 634.990s, speedup 39.005x
37, opt runtime 19.707s, model runtime 19.707s, pg runtime 19.707s, speedup 1.000x
38, opt runtime 18.262s, model runtime 18.262s, pg runtime 18.262s, speedup 1.000x
39, opt runtime 1.088s, model runtime 1.088s, pg runtime 1.206s, speedup 1.109x
40, opt runtime 1.086s, model runtime 1.086s, pg runtime 1.181s, speedup 1.088x
====================
best train speedup epoch: 28, train speedup 5.263, test speedup 5.498, val speedup 5.539
best test speedup epoch: 40, train speedup 5.257, test speedup 5.574, val speedup 5.627
best validation speedup epoch: 20, train speedup 5.177, test speedup 4.099, val speedup 5.680
last model at epoch 44, train speedup 5.090, test speedup 5.423, val speedup 5.583
execution cost 0:00:43.054082
==================================================
all print will write to path record/postgresql/TPCH/TCNN/slow_split/point
==================================================
Model: <class 'src.models.TCNN.TCNN'>
NUM_HINT_SET: 49
app: point
batch_size: 128
candidate_list: 30
data_root_path: ./db_benchmark_datasets
dataset: TPCH
dbms: postgresql
epochs: 300
execute_sql: 0
expname: main_repeat
grain: repeat
lr: 0.001
meta_save_path: record/postgresql/TPCH/execute_sql
model: TCNN
npseed: 42
pairwise: False
parameter: 
pre_execute_all: 0
sample_num: 1000
sampling: -1
save_path: record/postgresql/TPCH/TCNN/slow_split/point
seed: 42
shuffle_num: 1
slow: 1
split_ratio: 0.1
src: JOB
tgt: TPCH
tolerance: 10
train: 1
weighted: False

Loaded number of JOB queries: 113
(113, 49)
(113, 49)
21a.sql
test query:  ['1d.sql' '10c.sql' '11c.sql' '12c.sql' '13d.sql' '14c.sql' '15d.sql'
 '16b.sql' '17a.sql' '18c.sql' '19d.sql' '2d.sql' '20c.sql' '21a.sql'
 '22c.sql' '23c.sql' '24a.sql' '25c.sql' '26c.sql' '27c.sql' '28c.sql'
 '29b.sql' '3c.sql' '30c.sql' '31c.sql' '32b.sql' '33c.sql' '4a.sql'
 '5c.sql' '6d.sql' '7c.sql' '8c.sql' '9d.sql']
load JOB succ
load TPCH...
[2, 3, 4, 5, 7, 9] [6, 8] [1, 0]
[0, 3, 4, 7, 8, 9] [5, 2] [6, 1]
[0, 4, 6, 7, 8, 9] [1, 3] [5, 2]
[0, 3, 4, 5, 7, 8] [1, 9] [2, 6]
[0, 3, 4, 6, 8, 9] [7, 2] [1, 5]
[1, 2, 3, 4, 6, 8] [5, 9] [7, 0]
[2, 3, 4, 5, 7, 8] [1, 6] [0, 9]
[1, 4, 6, 7, 8, 9] [0, 2] [5, 3]
[3, 4, 5, 7, 8, 9] [1, 0] [2, 6]
[0, 1, 2, 5, 7, 8] [3, 9] [4, 6]
[0, 2, 3, 5, 7, 9] [4, 6] [8, 1]
[0, 1, 2, 3, 5, 6] [9, 8] [7, 4]
[0, 3, 4, 5, 7, 9] [1, 2] [6, 8]
[2, 3, 4, 5, 6, 9] [0, 7] [1, 8]
[0, 1, 5, 6, 8, 9] [3, 2] [4, 7]
[0, 1, 4, 5, 6, 9] [8, 2] [7, 3]
[0, 2, 3, 6, 7, 9] [8, 5] [4, 1]
[0, 1, 2, 6, 7, 9] [5, 3] [4, 8]
[1, 2, 3, 4, 6, 8] [7, 9] [5, 0]
[0, 3, 5, 7, 8, 9] [2, 6] [1, 4]
load TPCH succ
train, test, validation (120, 49) (40, 49) (40, 49)
construct training samples cost 0:00:00.883158, and there are 5880 training samples
in channel 9
Epoch 0/300 |loss: 0.048859| train set 2.499x speedup, test set 2.867x speedup, val set 2.708x speedup, step: 1
Epoch 1/300 |loss: 0.019868| train set 2.561x speedup, test set 2.910x speedup, val set 2.683x speedup, step: 2
Epoch 2/300 |loss: 0.010594| train set 3.168x speedup, test set 3.399x speedup, val set 3.408x speedup, step: 1
Epoch 3/300 |loss: 0.007222| train set 3.269x speedup, test set 3.785x speedup, val set 3.570x speedup, step: 1
Epoch 4/300 |loss: 0.005666| train set 3.649x speedup, test set 4.034x speedup, val set 3.921x speedup, step: 1
Epoch 5/300 |loss: 0.003822| train set 3.117x speedup, test set 3.660x speedup, val set 3.395x speedup, step: 2
Epoch 6/300 |loss: 0.003741| train set 3.566x speedup, test set 3.896x speedup, val set 3.874x speedup, step: 3
Epoch 7/300 |loss: 0.003120| train set 3.060x speedup, test set 3.571x speedup, val set 3.307x speedup, step: 4
Epoch 8/300 |loss: 0.002630| train set 3.672x speedup, test set 4.087x speedup, val set 3.979x speedup, step: 1
Epoch 9/300 |loss: 0.002356| train set 5.075x speedup, test set 4.086x speedup, val set 5.247x speedup, step: 1
Epoch 10/300 |loss: 0.002104| train set 3.616x speedup, test set 4.045x speedup, val set 3.985x speedup, step: 2
Epoch 11/300 |loss: 0.001972| train set 5.162x speedup, test set 4.042x speedup, val set 5.434x speedup, step: 1
Epoch 12/300 |loss: 0.002196| train set 5.170x speedup, test set 4.142x speedup, val set 5.336x speedup, step: 2
Epoch 13/300 |loss: 0.002550| train set 5.169x speedup, test set 4.061x speedup, val set 5.567x speedup, step: 1
Epoch 14/300 |loss: 0.001982| train set 3.407x speedup, test set 3.964x speedup, val set 3.821x speedup, step: 2
Epoch 15/300 |loss: 0.002123| train set 5.188x speedup, test set 4.089x speedup, val set 5.563x speedup, step: 3
Epoch 16/300 |loss: 0.001605| train set 5.188x speedup, test set 4.089x speedup, val set 5.563x speedup, step: 4
Epoch 17/300 |loss: 0.001512| train set 3.947x speedup, test set 4.377x speedup, val set 4.340x speedup, step: 5
Epoch 18/300 |loss: 0.001595| train set 5.256x speedup, test set 4.281x speedup, val set 5.616x speedup, step: 1
Epoch 19/300 |loss: 0.001437| train set 5.167x speedup, test set 4.043x speedup, val set 5.444x speedup, step: 2
Epoch 20/300 |loss: 0.001365| train set 5.259x speedup, test set 4.132x speedup, val set 5.638x speedup, step: 1
Epoch 21/300 |loss: 0.000984| train set 5.254x speedup, test set 5.501x speedup, val set 5.530x speedup, step: 2
Epoch 22/300 |loss: 0.002903| train set 5.159x speedup, test set 5.403x speedup, val set 5.404x speedup, step: 3
Epoch 23/300 |loss: 0.002102| train set 5.234x speedup, test set 5.533x speedup, val set 5.602x speedup, step: 4
early stopping at epoch 23
Training per epoch cost 0.472 s
Optimal speedup on test set is 5.720x
01, opt runtime 34.775s, model runtime 37.830s, pg runtime 37.830s, speedup 1.000x
02, opt runtime 31.109s, model runtime 31.109s, pg runtime 31.109s, speedup 1.000x
03, opt runtime 29.502s, model runtime 29.502s, pg runtime 112.305s, speedup 3.807x
04, opt runtime 30.267s, model runtime 30.267s, pg runtime 100.885s, speedup 3.333x
05, opt runtime 23.961s, model runtime 32.278s, pg runtime 32.278s, speedup 1.000x
06, opt runtime 25.597s, model runtime 27.136s, pg runtime 27.136s, speedup 1.000x
07, opt runtime 6.284s, model runtime 6.284s, pg runtime 31.019s, speedup 4.937x
08, opt runtime 7.377s, model runtime 8.474s, pg runtime 28.655s, speedup 3.382x
09, opt runtime 5.543s, model runtime 5.543s, pg runtime 5.543s, speedup 1.000x
10, opt runtime 5.237s, model runtime 5.237s, pg runtime 5.237s, speedup 1.000x
11, opt runtime 23.205s, model runtime 23.205s, pg runtime 87.340s, speedup 3.764x
12, opt runtime 26.602s, model runtime 26.602s, pg runtime 85.447s, speedup 3.212x
13, opt runtime 3.332s, model runtime 4.140s, pg runtime 21.298s, speedup 5.144x
14, opt runtime 3.258s, model runtime 3.312s, pg runtime 18.141s, speedup 5.478x
15, opt runtime 53.298s, model runtime 180.921s, pg runtime 148.707s, speedup 0.822x
16, opt runtime 53.440s, model runtime 165.749s, pg runtime 140.742s, speedup 0.849x
17, opt runtime 10.788s, model runtime 10.788s, pg runtime 32.939s, speedup 3.053x
18, opt runtime 6.149s, model runtime 6.149s, pg runtime 30.760s, speedup 5.003x
19, opt runtime 1.347s, model runtime 1.438s, pg runtime 1.438s, speedup 1.000x
20, opt runtime 1.428s, model runtime 1.428s, pg runtime 1.428s, speedup 1.000x
21, opt runtime 25.034s, model runtime 25.034s, pg runtime 25.034s, speedup 1.000x
22, opt runtime 20.897s, model runtime 23.708s, pg runtime 23.708s, speedup 1.000x
23, opt runtime 6.250s, model runtime 6.250s, pg runtime 32.969s, speedup 5.275x
24, opt runtime 6.234s, model runtime 6.234s, pg runtime 32.540s, speedup 5.220x
25, opt runtime 1.642s, model runtime 1.752s, pg runtime 1.752s, speedup 1.000x
26, opt runtime 1.423s, model runtime 1.423s, pg runtime 1.423s, speedup 1.000x
27, opt runtime 6.789s, model runtime 7.197s, pg runtime 7.799s, speedup 1.084x
28, opt runtime 7.199s, model runtime 7.199s, pg runtime 7.619s, speedup 1.058x
29, opt runtime 5.572s, model runtime 5.572s, pg runtime 5.572s, speedup 1.000x
30, opt runtime 5.539s, model runtime 5.539s, pg runtime 5.539s, speedup 1.000x
31, opt runtime 24.840s, model runtime 24.840s, pg runtime 626.529s, speedup 25.222x
32, opt runtime 24.662s, model runtime 24.662s, pg runtime 613.999s, speedup 24.896x
33, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
34, opt runtime 39.191s, model runtime 39.191s, pg runtime 75.984s, speedup 1.939x
35, opt runtime 18.690s, model runtime 18.690s, pg runtime 651.942s, speedup 34.881x
36, opt runtime 16.280s, model runtime 16.280s, pg runtime 634.990s, speedup 39.005x
37, opt runtime 19.707s, model runtime 19.707s, pg runtime 19.707s, speedup 1.000x
38, opt runtime 18.262s, model runtime 18.262s, pg runtime 18.262s, speedup 1.000x
39, opt runtime 1.088s, model runtime 1.088s, pg runtime 1.206s, speedup 1.109x
40, opt runtime 1.086s, model runtime 1.086s, pg runtime 1.181s, speedup 1.088x
====================
best train speedup epoch: 20, train speedup 5.259, test speedup 4.132, val speedup 5.638
best test speedup epoch: 23, train speedup 5.234, test speedup 5.533, val speedup 5.602
best validation speedup epoch: 20, train speedup 5.259, test speedup 4.132, val speedup 5.638
last model at epoch 23, train speedup 5.234, test speedup 5.533, val speedup 5.602
execution cost 0:00:27.365772
==================================================
